#!/usr/bin/env node

/**
 * Test Vision QA Setup
 * Verifies API keys and Vision QA system configuration
 */

import MultimodalClient from '../lib/ai/multimodal-client';
import VisionQAAgent from '../lib/testing/vision-qa-agent';
import dotenv from 'dotenv';
dotenv.config();

console.log(`
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë        Vision QA System Setup Verification      ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
`);

async function testSetup() {
  let openaiStatus = '‚ùå';
  let anthropicStatus = '‚ùå';
  let databaseStatus = '‚ùå';
  
  // 1. Check environment variables
  console.log('üìã Checking Environment Variables...\n');
  
  if (process.env.OPENAI_API_KEY && process.env.OPENAI_API_KEY !== 'your-openai-api-key-here') {
    console.log('‚úÖ OpenAI API Key: Configured');
    console.log(`   Key prefix: ${process.env.OPENAI_API_KEY.substring(0, 10)}...`);
    openaiStatus = '‚úÖ';
  } else {
    console.log('‚ùå OpenAI API Key: Missing');
  }
  
  if (process.env.USE_LOCAL_LLM) {
    console.log('‚úÖ Local LLM: Configured (Ollama)');
    anthropicStatus = '‚úÖ';
  } else {
    console.log('‚ö†Ô∏è  Local LLM: Not configured (optional, set USE_LOCAL_LLM=true)');
    anthropicStatus = '‚ö†Ô∏è';
  }
  
  if (process.env.NEXT_PUBLIC_SUPABASE_URL && process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY) {
    console.log('‚úÖ Supabase: Configured');
    databaseStatus = '‚úÖ';
  } else {
    console.log('‚ùå Supabase: Missing configuration');
  }
  
  console.log('\nüìä Testing API Connections...\n');
  
  // 2. Test OpenAI connection
  if (openaiStatus === '‚úÖ') {
    try {
      console.log('Testing OpenAI connection...');
      const openaiClient = new MultimodalClient({
        provider: 'openai',
        model: 'gpt-4o-mini', // Use a cheaper model for testing
        apiKey: process.env.OPENAI_API_KEY
      });
      
      // Estimate cost for a simple test
      const costEstimate = openaiClient.estimateCost(10);
      console.log('‚úÖ OpenAI: Connection successful');
      console.log(`   Available models: ${openaiClient.getAvailableModels().join(', ')}`);
      console.log(`   Test cost estimate (10 iterations): $${costEstimate.estimatedTotal.toFixed(2)}`);
    } catch (_error) {
      console.log('‚ùå OpenAI: Connection failed');
      console.log(`   Error: ${error.message}`);
      openaiStatus = '‚ùå';
    }
  }
  
  // 3. Test Local LLM connection
  if (anthropicStatus === '‚úÖ') {
    try {
      console.log('\nTesting Local LLM connection...');
      console.log('‚úÖ Local LLM: Ollama configured');
      console.log(`   USE_LOCAL_LLM=${process.env.USE_LOCAL_LLM}`);
      console.log(`   Test cost estimate (10 iterations): $${costEstimate.estimatedTotal.toFixed(2)}`);
    } catch (_error) {
      console.log('‚ùå Anthropic: Connection failed');
      console.log(`   Error: ${error.message}`);
      anthropicStatus = '‚ùå';
    }
  }
  
  // 4. Test Vision QA Agent initialization
  console.log('\nü§ñ Testing Vision QA Agent...\n');
  
  try {
    const agent = new VisionQAAgent({
      maxIterations: 10,
      costLimit: 0.50,
      model: 'auto'
    });
    
    console.log('‚úÖ Vision QA Agent: Initialized successfully');
    console.log(`   Auto-selected model: ${agent.config.model}`);
    console.log(`   Provider: ${agent.config.provider || 'openai'}`);
    console.log(`   Max iterations: ${agent.config.maxIterations}`);
    console.log(`   Cost limit: $${agent.config.costLimit}`);
  } catch (_error) {
    console.log('‚ùå Vision QA Agent: Initialization failed');
    console.log(`   Error: ${error.message}`);
  }
  
  // 5. Model selection test
  console.log('\nüéØ Testing Automatic Model Selection...\n');
  
  const testScenarios = [
    { goal: 'Test payment checkout flow', expected: 'gpt-5' },
    { goal: 'Check accessibility compliance', expected: 'claude-sonnet-3.7' },
    { goal: 'Run basic smoke tests', expected: 'gpt-5-nano' },
    { goal: 'Test user registration form', expected: 'gpt-5-mini' }
  ];
  
  testScenarios.forEach(scenario => {
    const agent = new VisionQAAgent({ testGoal: scenario.goal });
    const selected = agent.config.model;
    const match = selected === scenario.expected ? '‚úÖ' : '‚ö†Ô∏è';
    console.log(`${match} "${scenario.goal}"`);
    console.log(`   Selected: ${selected} (Expected: ${scenario.expected})`);
  });
  
  // 6. Summary
  console.log('\n' + '='.repeat(50));
  console.log('SETUP VERIFICATION SUMMARY');
  console.log('='.repeat(50));
  console.log(`\nOpenAI API:     ${openaiStatus}`);
  console.log(`Anthropic API:  ${anthropicStatus}`);
  console.log(`Database:       ${databaseStatus}`);
  
  if (openaiStatus === '‚úÖ' || anthropicStatus === '‚úÖ') {
    console.log('\n‚úÖ Vision QA System is ready to use!');
    console.log('\nYou can now run Vision QA tests using:');
    console.log('  node lib/testing/vision-qa-agent.js --app-id "APP-001" --goal "Your test goal"');
    
    console.log('\nOr use the decision helper:');
    console.log('  node scripts/vision-qa-decision.js');
  } else {
    console.log('\n‚ùå Vision QA System is not fully configured.');
    console.log('At least one API key (OpenAI or Anthropic) is required.');
  }
  
  console.log('\nüìö Documentation:');
  console.log('  - Vision QA System: docs/vision-qa-system.md');
  console.log('  - LEO Integration: docs/03_protocols_and_standards/leo_vision_qa_integration.md');
  console.log('  - Agent Workflows: templates/agent-workflows/');
}

// Run the test
testSetup().catch(console.error);