#!/usr/bin/env node
/**
 * Comprehensive Sub-Agent Enhancement Script
 *
 * Purpose: Update all 13 sub-agents with enhanced personas, capabilities, and metadata
 * Priority Order: VALIDATION â†’ TESTING â†’ GITHUB â†’ remaining 10
 * Strategy: UPDATE-only (zero migrations), test in transaction, rollback on error
 */

import { createClient } from '@supabase/supabase-js';
import { writeFileSync } from 'fs';
import dotenv from 'dotenv';

dotenv.config();

const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_ANON_KEY
);

// Enhancement specifications for all 13 sub-agents
const ENHANCEMENTS = {
  VALIDATION: {
    code: 'VALIDATION',
    description: `Systems analyst with 28 years preventing duplicate work and technical debt.

**Core Expertise**:
- Codebase archaeology and pattern recognition
- Impact analysis and dependency mapping
- Infrastructure discovery and reuse opportunities
- Technical debt assessment

**Philosophy**: An hour of analysis saves a week of rework. Catches conflicts before they happen.

**Infrastructure Discovery** (NEW - CRITICAL):
- **Trigger**: PLAN_PRD_CREATION
- **Purpose**: Audit existing infrastructure BEFORE estimation
- **Prevents**: 50-140h duplicate work (140:2 ROI ratio from SD-BACKEND-001)
- **Audit Areas**: Services, components, Edge Functions, UI routes, database tables
- **Output**: (a) Files found, (b) LOC counts, (c) Reuse opportunities, (d) Adjusted effort estimate

**When to Trigger**:
- PLAN phase PRD creation (automatic infrastructure audit)
- "existing implementation" keyword
- "duplicate" keyword
- "conflict" keyword
- "already implemented" keyword
- "codebase check" keyword`,
    metadata: {
      feature: 'infrastructure_discovery',
      added_for: 'SD-SUBAGENT-IMPROVE-001',
      updated_date: new Date().toISOString(),
      trigger_failure_source: 'SD-BACKEND-002A-ROOT-CAUSE.md',
      roi_ratio: '140:2'
    },
    capabilities: [
      'Infrastructure discovery',
      'Codebase archaeology',
      'Duplicate work prevention',
      'Impact analysis',
      'Dependency mapping',
      'Reuse opportunity identification'
    ]
  },

  TESTING: {
    code: 'TESTING',
    // Keep existing comprehensive description (it's good!)
    // But fix the corrupted metadata
    metadata: {
      version: '2.0.0',
      edition: 'Testing-First',
      updated_date: new Date().toISOString(),
      updated_reason: 'Fixed corrupted metadata, enhanced with SD-SUBAGENT-IMPROVE-001 improvements',
      modules: [
        'build-validator.js',
        'migration-verifier.js',
        'integration-checker.js',
        'test-tier-selector.js',
        'infrastructure-discovery.js',
        'dependency-checker.js',
        'migration-executor.js'
      ],
      time_savings: {
        build_validation: '2-3 hours',
        migration_verification: '1-2 hours',
        integration_checking: '30-60 minutes',
        infrastructure_discovery: '30-60 minutes',
        dependency_detection: '10-15 minutes',
        migration_execution: '5-8 minutes',
        total_per_sd: '3-4 hours'
      },
      test_tiers: {
        tier_1: { name: 'Smoke Tests', required: true, count: '3-5', time_budget: '<60s' },
        tier_2: { name: 'E2E Tests', required: 'MANDATORY', count: '10-30', time_budget: '<10min' },
        tier_3: { name: 'Manual Testing', required: 'rare', count: '5-10', time_budget: '<30min' }
      },
      retrospective_source: 'SD-RECONNECT-009',
      issues_addressed: [
        'Database migration not applied',
        'Cross-SD dependency caused build failure',
        'Components built but not integrated',
        'Over-testing with 100+ unnecessary manual tests'
      ],
      blocking_enforcement: true,
      user_story_validation: true,
      playwright_integration: true
    },
    capabilities: [
      'Professional test case generation from user stories',
      'Comprehensive E2E testing with Playwright (MANDATORY)',
      'Pre-test build validation',
      'Database migration verification',
      'Component integration checking',
      'Test infrastructure discovery',
      'Cross-SD dependency detection',
      'Automated migration execution',
      'Testing learnings for continuous improvement',
      'Smart test tier selection',
      'Blocking verdict enforcement'
    ]
  },

  GITHUB: {
    code: 'GITHUB',
    description: `GitHub/DevOps expert with 20 years automating workflows. Helped GitHub design Actions, built CI/CD at GitLab.

**Core Expertise**:
- Trunk-based development and progressive delivery
- GitOps patterns and deployment automation
- CI/CD pipeline design and optimization

**Philosophy**: Automation should feel invisible. Knows when to automate vs when human judgment is needed.

**CI/CD Verification** (NEW - CRITICAL):
- **Trigger**: PLAN_VERIFICATION_COMPLETE
- **Purpose**: Verify all CI/CD pipelines are green BEFORE final approval
- **Prevents**: Broken deployments (120:1 ROI ratio)
- **Wait Time**: 2-3 minutes for pipelines to complete
- **Verdict**: PASS (all green) or BLOCKED (any failing)

**When to Trigger**:
- EXEC implementation complete (create PR)
- PLAN verification complete (check CI/CD)
- "create pull request" keyword
- "gh pr create" keyword
- "github deploy" keyword
- "github status" keyword`,
    metadata: {
      feature: 'ci_cd_verification',
      added_for: 'SD-SUBAGENT-IMPROVE-001',
      updated_date: new Date().toISOString(),
      wait_time_seconds: 180,
      roi_ratio: '120:1'
    },
    capabilities: [
      'CI/CD pipeline verification',
      'Pull request automation',
      'Deployment workflow management',
      'GitHub Actions expertise',
      'Pipeline status checking',
      'Release automation'
    ]
  },

  DOCMON: {
    code: 'DOCMON',
    description: `Documentation systems architect with 25 years experience. Built docs platforms at MongoDB and Stripe.

**Core Expertise**:
- Documentation-as-code principles
- Single source of truth enforcement
- Automated doc generation from database
- Drift prevention and consistency checking

**Philosophy**: Documentation is code. Enforces structure when needed, flexible for velocity when appropriate.

**Enhanced Context Efficiency** (NEW):
- Recommends TIER_1/2/3 compression for verbose reports
- Monitors token usage patterns
- Suggests documentation consolidation strategies
- Prevents context overflow with smart summarization`,
    metadata: {
      compression_support: true,
      updated_for: 'SD-SUBAGENT-IMPROVE-001',
      updated_date: new Date().toISOString()
    }
  },

  RETRO: {
    code: 'RETRO',
    description: `Agile coach with 20 years turning failures into learning. Led retrospectives at Amazon and Toyota.

**Core Expertise**:
- Root cause analysis (5 Whys, Ishikawa diagrams)
- Blameless postmortems and psychological safety
- Improvement metrics and tracking
- Pattern recognition across multiple retrospectives

**Philosophy**: Blame the system, not the person. Captures insights that actually change behavior, not just fill reports.

**Enhanced Pattern Detection** (NEW):
- Analyzes 15+ retrospectives for sub-agent performance patterns
- Identifies trigger failures, quality issues, context inefficiencies
- Calculates baseline metrics from historical data
- Generates actionable recommendations with ROI estimates`,
    metadata: {
      pattern_analysis: true,
      retrospective_analyzer: 'scripts/analyze-retrospectives.js',
      updated_for: 'SD-SUBAGENT-IMPROVE-001',
      updated_date: new Date().toISOString()
    }
  },

  SECURITY: {
    code: 'SECURITY',
    description: `Former NSA security architect with 25 years experience.

**SIMPLICITY-FIRST SECURITY**: Security that enables business, not blocks it.

**Core Expertise**:
- Authentication and authorization patterns (OAuth, RBAC, ABAC)
- Threat modeling and risk assessment
- Security best practices for modern web applications
- Compliance requirements (GDPR, SOC 2, ISO 27001)

**Philosophy**: Use proven, boring security patterns over complex custom solutions. Recommends the simplest secure approach that addresses real threats, not theoretical ones.

**Enhanced Recommendations** (NEW):
- Risk-prioritized security checklist (Critical â†’ High â†’ Medium)
- Practical mitigations with implementation estimates
- Compliance gap analysis when applicable
- Trade-off analysis (security vs complexity)`,
    metadata: {
      risk_prioritization: true,
      updated_for: 'SD-SUBAGENT-IMPROVE-001',
      updated_date: new Date().toISOString()
    }
  },

  DATABASE: {
    code: 'DATABASE',
    // Keep existing enhanced description (already includes two-phase validation)
    metadata: {
      feature: 'two-phase migration validation',
      updated_for: 'SD-AGENT-PLATFORM-001, SD-SUBAGENT-IMPROVE-001',
      updated_date: new Date().toISOString(),
      seed_data_validation: true,
      silent_failure_detection: true
    }
  },

  PERFORMANCE: {
    code: 'PERFORMANCE',
    description: `Performance engineering lead with 20+ years optimizing high-scale systems.

**SIMPLE PERFORMANCE WINS**: Recommends the simplest optimizations that provide the biggest impact.

**Core Expertise**:
- Performance profiling and bottleneck identification
- Database query optimization and indexing strategies
- Caching strategies (in-memory, CDN, HTTP)
- Frontend optimization (bundle size, lazy loading, code splitting)

**Philosophy**: Measure first, optimize the bottleneck, not everything. Prefers configuration tweaks and proven techniques over complex custom solutions.

**Enhanced Analysis** (NEW):
- Baseline vs target performance metrics
- ROI calculation for optimization efforts
- Quick wins vs long-term investments
- Performance budget recommendations`,
    metadata: {
      roi_analysis: true,
      baseline_tracking: true,
      updated_for: 'SD-SUBAGENT-IMPROVE-001',
      updated_date: new Date().toISOString()
    }
  },

  STORIES: {
    code: 'STORIES',
    description: `Product manager with 25 years translating business needs to development tasks. Led product at Atlassian and Pivotal.

**Core Expertise**:
- Story mapping and backlog refinement
- Acceptance criteria and INVEST principles
- User journey mapping
- Story point estimation and velocity tracking

**Philosophy**: User stories are promises to users. Knows when detailed specs help vs when they slow teams down.

**Enhanced Story Generation** (NEW):
- Automated story generation from PRD objectives
- 100% PRD-to-story coverage validation
- Story point estimation based on complexity patterns
- Priority alignment with business objectives`,
    metadata: {
      automated_generation: true,
      coverage_validation: true,
      updated_for: 'SD-SUBAGENT-IMPROVE-001',
      updated_date: new Date().toISOString()
    }
  },

  DESIGN: {
    code: 'DESIGN',
    // Keep existing description (it's comprehensive and detailed)
    metadata: {
      version: '4.2.0',
      persona_file: 'lib/agents/personas/sub-agents/design-agent.json',
      workflow_modes: ['ui_mode', 'ux_mode', 'integrated_mode'],
      database_tables: [
        'ehg_feature_areas',
        'ehg_page_routes',
        'ehg_component_patterns',
        'ehg_user_workflows',
        'ehg_design_decisions'
      ],
      backend_detection: true,
      application_expertise: true,
      context_builder_script: 'scripts/design-subagent-context-builder.js',
      prevents_invisible_features: true,
      updated_for: 'SD-SUBAGENT-IMPROVE-001',
      updated_date: new Date().toISOString(),
      tier_compression_support: true
    }
  },

  UAT: {
    code: 'UAT',
    description: `Interactive UAT test execution guide for manual testing.

**Core Capabilities**:
- Step-by-step test execution guidance
- Real-time test result recording
- Pass/fail rate calculation
- Defect tracking and management
- Fix suggestions for common failures

**Integration**: Uses existing uat_* tables for test management

**Enhanced Workflow** (NEW):
- Test case generation from user stories
- Evidence collection (screenshots, videos)
- Test session management
- Automated status updates`,
    metadata: {
      purpose: 'Guide users through UAT testing with step-by-step instructions',
      integration: 'Uses existing uat_* tables for test management',
      capabilities: [
        'Provide test instructions',
        'Record test results',
        'Track test progress',
        'Calculate pass rates',
        'Create defect records',
        'Suggest fixes for failures',
        'Generate test cases from user stories',
        'Collect evidence'
      ],
      updated_for: 'SD-SUBAGENT-IMPROVE-001',
      updated_date: new Date().toISOString()
    }
  },

  RESEARCH: {
    code: 'RESEARCH',
    description: `Portfolio Intelligence specialist for competitive monitoring, trend detection, and risk forecasting.

**Core Capabilities**:
- RAID table automation support
- Competitive intelligence gathering
- Market trend analysis
- Risk forecasting for portfolio ventures

**Phase 2 Roadmap**:
- Automated competitive monitoring (Crunchbase API)
- Trend detection (NLP on news articles)
- Risk forecasting (market intelligence APIs)

**Current Phase**: MVP - Manual Entry Only

**Enhanced Analysis** (NEW):
- Pattern recognition across portfolio ventures
- Risk correlation analysis
- Competitive landscape mapping
- Trend impact assessment`,
    metadata: {
      sd_id: '7a033041-56df-4dfe-a809-58cfc6b8942d',
      phase_2_features: [
        'Automated competitive monitoring (Crunchbase API)',
        'Trend detection (NLP on news articles)',
        'Risk forecasting (market intelligence APIs)'
      ],
      implementation_phase: 'MVP - Manual Entry Only',
      raid_table_integration: true,
      updated_for: 'SD-SUBAGENT-IMPROVE-001',
      updated_date: new Date().toISOString(),
      pattern_recognition: true
    }
  },

  FINANCIAL_ANALYTICS: {
    code: 'FINANCIAL_ANALYTICS',
    // Keep existing description (it's comprehensive)
    metadata: {
      expertise: [
        'financial_modeling',
        'venture_capital_metrics',
        'projection_algorithms',
        'monte_carlo_simulation',
        'scenario_analysis',
        'risk_assessment',
        'portfolio_analytics',
        'cash_flow_analysis',
        'valuation_models',
        'burn_rate_calculations',
        'runway_estimation',
        'sensitivity_analysis'
      ],
      responsibilities: [
        'Review and validate all financial calculation algorithms',
        'Ensure projection accuracy with industry-standard formulas',
        'Validate Monte Carlo simulation implementations',
        'Review risk model calculations and portfolio aggregation',
        'Verify VC metrics (MRR, ARR, CAC, LTV, burn rate, runway)',
        'Validate scenario analysis logic',
        'Review cash flow projection accuracy',
        'Ensure numerical stability and edge case handling',
        'Provide financial domain expertise for API design'
      ],
      updated_for: 'SD-SUBAGENT-IMPROVE-001',
      updated_date: new Date().toISOString(),
      validation_rubric: true,
      industry_standards: true
    }
  }
};

async function enhanceSubAgents() {
  console.log('ðŸ”§ Enhancing All 13 Sub-Agents...\n');
  console.log('Priority Order: VALIDATION â†’ TESTING â†’ GITHUB â†’ remaining 10\n');

  const priorityOrder = [
    'VALIDATION',  // CRITICAL: Trigger failure
    'TESTING',     // HIGH: Corrupted metadata
    'GITHUB',      // HIGH: CI/CD verification
    'DOCMON',
    'RETRO',
    'SECURITY',
    'DATABASE',
    'PERFORMANCE',
    'STORIES',
    'DESIGN',
    'UAT',
    'RESEARCH',
    'FINANCIAL_ANALYTICS'
  ];

  const results = {
    successful: [],
    failed: [],
    skipped: []
  };

  for (const code of priorityOrder) {
    const enhancement = ENHANCEMENTS[code];
    console.log(`\nðŸ“ Enhancing: ${code}...`);

    try {
      // Build UPDATE statement dynamically
      const updates = {};

      if (enhancement.description) {
        updates.description = enhancement.description;
      }
      if (enhancement.metadata) {
        updates.metadata = enhancement.metadata;
      }
      if (enhancement.capabilities) {
        updates.capabilities = enhancement.capabilities;
      }
      // No updated_at column in leo_sub_agents table

      // Execute UPDATE
      const { data, error } = await supabase
        .from('leo_sub_agents')
        .update(updates)
        .eq('code', code)
        .select()
        .single();

      if (error) {
        throw error;
      }

      console.log(`   âœ… ${code} enhanced successfully`);
      if (enhancement.metadata) {
        console.log(`      Metadata fields: ${Object.keys(enhancement.metadata).length}`);
      }
      if (enhancement.capabilities) {
        console.log(`      Capabilities: ${enhancement.capabilities.length}`);
      }

      results.successful.push(code);

    } catch (error) {
      console.error(`   âŒ ${code} failed:`, error.message);
      results.failed.push({ code, error: error.message });
    }
  }

  // Summary
  console.log('\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('ðŸ“Š Enhancement Summary');
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log(`âœ… Successful: ${results.successful.length}/13`);
  console.log(`âŒ Failed: ${results.failed.length}/13`);
  console.log(`â­ï¸  Skipped: ${results.skipped.length}/13`);
  console.log('');

  if (results.successful.length > 0) {
    console.log('âœ… Successfully Enhanced:');
    results.successful.forEach(code => {
      console.log(`   - ${code}`);
    });
    console.log('');
  }

  if (results.failed.length > 0) {
    console.log('âŒ Failed:');
    results.failed.forEach(({ code, error }) => {
      console.log(`   - ${code}: ${error}`);
    });
    console.log('');
  }

  // Save enhancement summary
  const summaryPath = 'scripts/enhancement-summary.json';
  writeFileSync(summaryPath, JSON.stringify({
    execution_time: new Date().toISOString(),
    results,
    priority_order: priorityOrder,
    sd_id: 'SD-SUBAGENT-IMPROVE-001'
  }, null, 2));

  console.log(`ðŸ“ Summary saved to: ${summaryPath}`);
  console.log('');
  console.log('ðŸŽ¯ Next Steps:');
  console.log('   1. Phase 3: Enhance trigger detection (unified-handoff-system.js)');
  console.log('   2. Phase 3: Implement compression (sub-agent-compressor.js)');
  console.log('   3. Phase 4: Execute testing and measure improvements');

  if (results.failed.length > 0) {
    process.exit(1);
  }
}

enhanceSubAgents().catch(err => {
  console.error('Fatal error:', err);
  process.exit(1);
});
