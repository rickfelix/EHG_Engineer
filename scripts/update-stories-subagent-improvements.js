#!/usr/bin/env node

/**
 * Update STORIES Sub-Agent with 5 Improvements from Key Learnings
 * Based on analysis of user story validation gaps, E2E test mapping issues, and quality patterns
 */

import { createClient } from '@supabase/supabase-js';
import dotenv from 'dotenv';

dotenv.config();

const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_ANON_KEY
);

async function updateStoriesSubAgent() {
  console.log('üîß Updating STORIES Sub-Agent with 5 Improvements...\n');

  const updatedDescription = `## User Story Context Engineering v2.0.0 - Key Learnings Edition

**üÜï NEW in v2.0.0**: 5 critical improvements from lessons learned and root cause analyses

**Mission**: Create hyper-detailed, testable, and automatically validated user stories that reduce EXEC confusion and ensure 100% E2E test coverage.

**Core Philosophy**: "A well-written user story with rich context is worth 10 hours of EXEC debugging."

---

## üö® IMPROVEMENT #1: AUTOMATED E2E TEST MAPPING (CRITICAL)

### The Mapping Gap (SD-VIF-INTEL-001)

**Problem**: All 26 user stories had \`e2e_test_path = NULL\` despite E2E tests existing and passing (93.5% pass rate). Tests followed US-XXX naming convention but weren't linked back to database.

**Root Cause**: Missing automated script to map actual E2E tests to user stories.

**Impact**:
- Handoff validation fails (unmapped stories = not validated)
- Progress calculation stuck (PLAN_verification at 0%)
- 100% coverage requirement not enforced
- Manual workaround required (risky)

### NEW: Automated E2E Test Mapping

**Tool**: \`scripts/map-e2e-tests-to-user-stories.js\` (to be created)

**Functionality**:
1. Scan all E2E test files (\`tests/e2e/**/*.spec.ts\`)
2. Extract US-XXX references from test names: \`test('US-001: ...')\`
3. Map each US-XXX to its file path
4. Update \`user_stories\` table:
   \`\`\`sql
   UPDATE user_stories
   SET
     e2e_test_path = 'tests/e2e/customer-intelligence.spec.ts',
     e2e_test_status = 'created'
   WHERE story_key = 'US-XXX';
   \`\`\`

**Integration**: Run automatically during EXEC‚ÜíPLAN handoff

**Enforcement**:
\`\`\`javascript
// In unified-handoff-system.js: executeExecToPlan()
const mappingResult = await mapE2ETestsToUserStories(sdId);

if (mappingResult.unmappedStories.length > 0) {
  return {
    success: false,
    rejected: true,
    reasonCode: 'INCOMPLETE_E2E_COVERAGE',
    message: \`\${mappingResult.unmappedStories.length} user stories have no E2E tests\`
  };
}
\`\`\`

**Expected Impact**:
- 100% E2E test coverage enforced automatically
- Zero unmapped user stories
- Accurate progress calculation
- Prevents manual validation workarounds

**Evidence**: ROOT_CAUSE_USER_STORY_MAPPING_GAP.md (339 lines), SD-VIF-INTEL-001

---

## ‚ö†Ô∏è IMPROVEMENT #2: AUTOMATIC VALIDATION ON EXEC COMPLETION (HIGH)

### The Validation Gap (SD-TEST-MOCK-001)

**Problem**: PLAN_verification showed 0% progress despite all deliverables complete. User stories were created during PLAN phase but never marked as \`validated\` after EXEC completion.

**Root Cause**: No automatic validation of user stories when deliverables are marked complete.

**Impact**:
- Progress stuck at 85% (should be 100%)
- PLAN_verification blocked
- 30+ minutes debugging
- \`can_complete: false\` prevents SD completion

### NEW: Auto-Validation on EXEC Completion

**Tool**: \`scripts/auto-validate-user-stories-on-exec-complete.js\`

**When it runs**:
- Triggered during EXEC‚ÜíPLAN handoff creation
- Before PLAN verification begins

**What it checks**:
1. Do user stories exist for this SD?
2. Are all deliverables marked complete?
3. Are any user stories still 'pending'?

**What it does**:
- Auto-validates user stories if deliverables complete
- Logs validation actions for audit trail
- Returns validation status to handoff system

**Integration**:
\`\`\`javascript
// In unified-handoff-system.js, EXEC‚ÜíPLAN flow
import { autoValidateUserStories } from './auto-validate-user-stories-on-exec-complete.js';

// After deliverables check, before PLAN handoff
const validationResult = await autoValidateUserStories(sdId);
if (!validationResult.validated) {
  console.warn('‚ö†Ô∏è  User stories not validated, may block PLAN_verification');
}
\`\`\`

**MANDATORY Step in EXEC‚ÜíPLAN Handoff**:
\`\`\`
EXEC‚ÜíPLAN Handoff Checklist:
‚úì 1. All deliverables marked complete
‚úì 2. Tests passed (unit + E2E)
‚úì 3. Git commit created with SD reference
‚úì 4. User stories auto-validated ‚Üê NEW
‚úì 5. E2E tests auto-mapped to stories ‚Üê NEW (Improvement #1)
‚úì 6. Create handoff in database
‚úì 7. Trigger PLAN_VERIFY sub-agents
\`\`\`

**Expected Impact**:
- Zero blocked handoffs due to validation status
- Progress calculation accurate (100% when complete)
- 15-20 minutes saved per SD (automatic validation)
- 100% prevention of similar issues

**Evidence**: user-story-validation-gap.md (156 lines), SD-TEST-MOCK-001

---

## üìã IMPROVEMENT #3: INVEST CRITERIA ENFORCEMENT (MEDIUM)

### The Quality Problem

**Current State**: User stories created without enforced quality standards

**INVEST Criteria** (Industry Standard):
- **I**ndependent - Story can be developed independently
- **N**egotiable - Details can be negotiated between team and stakeholder
- **V**aluable - Delivers value to end user
- **E**stimable - Can be estimated for effort
- **S**mall - Can be completed in one sprint/iteration
- **T**estable - Has clear acceptance criteria that can be tested

### NEW: INVEST Validation During Creation

**Automatic Checks**:
1. **Independent**: Check for dependencies on other stories
2. **Valuable**: Requires user persona and benefit statement
3. **Estimable**: Requires complexity field (S/M/L or story points)
4. **Small**: Warn if acceptance criteria > 5 (may need splitting)
5. **Testable**: Requires at least one acceptance criterion in Given-When-Then format

**Validation Script**:
\`\`\`javascript
function validateINVESTCriteria(userStory) {
  const issues = [];

  // Independent
  if (userStory.depends_on?.length > 2) {
    issues.push('Too many dependencies - consider merging or reordering');
  }

  // Valuable
  if (!userStory.user_persona || !userStory.benefit) {
    issues.push('Missing user persona or benefit statement');
  }

  // Estimable
  if (!userStory.complexity) {
    issues.push('Missing complexity/effort estimate');
  }

  // Small
  if (userStory.acceptance_criteria?.length > 5) {
    issues.push('Too many acceptance criteria (>5) - consider splitting story');
  }

  // Testable
  const hasGWT = userStory.acceptance_criteria?.some(ac =>
    ac.includes('Given') && ac.includes('When') && ac.includes('Then')
  );
  if (!hasGWT) {
    issues.push('No Given-When-Then format in acceptance criteria');
  }

  return {
    valid: issues.length === 0,
    issues,
    score: calculateINVESTScore(userStory)
  };
}
\`\`\`

**Integration**: Run during user story creation in PLAN phase

**Expected Impact**:
- Higher quality user stories
- Fewer EXEC clarification questions
- Better testability
- Standardized format across all SDs

**Evidence**: docs/02_api/14_development_preparation.md (RR-002: User story quality)

---

## üéØ IMPROVEMENT #4: ACCEPTANCE CRITERIA TEMPLATES (MEDIUM)

### The Clarity Problem

**Current State**: Acceptance criteria vary widely in format and completeness

**Problem Examples**:
- Vague criteria: "User can see the data"
- Missing edge cases: "Form submits successfully" (but what about validation errors?)
- No Given-When-Then format
- Incomplete coverage

### NEW: Structured Acceptance Criteria Templates

**Template Format**:
\`\`\`javascript
{
  story_key: 'US-001',
  acceptance_criteria: [
    {
      id: 'AC-001-1',
      scenario: 'Happy path - successful creation',
      given: 'User is on the Ventures page AND user is authenticated',
      when: 'User clicks "Create Venture" button AND fills all required fields AND clicks "Submit"',
      then: 'Venture is created in database AND user sees success message AND venture appears in list',
      test_data: {
        venture_name: 'Test Venture',
        category: 'Technology',
        description: 'Test description'
      }
    },
    {
      id: 'AC-001-2',
      scenario: 'Error path - validation failure',
      given: 'User is on the Create Venture form',
      when: 'User leaves required field empty AND clicks "Submit"',
      then: 'Form shows validation error AND venture NOT created AND user stays on form',
      expected_error: 'Venture name is required'
    },
    {
      id: 'AC-001-3',
      scenario: 'Edge case - duplicate name',
      given: 'A venture with name "Test Venture" already exists',
      when: 'User tries to create another venture with same name',
      then: 'System shows duplicate error AND suggests alternative name',
      expected_error: 'Venture name already exists'
    }
  ]
}
\`\`\`

**Coverage Requirements**:
- **Minimum**: 1 happy path + 1 error path per user story
- **Recommended**: Happy path + 2-3 error paths + 1-2 edge cases
- **Complete**: All user journeys covered (success, validation, errors, edge cases, security)

**Generation Tool**: \`scripts/generate-acceptance-criteria-template.js\`
- Analyzes user story title
- Suggests common scenarios (CRUD ‚Üí create success, validation errors, duplicates, etc.)
- Provides template for Given-When-Then format
- EXEC fills in specific details

**Expected Impact**:
- Clearer acceptance criteria
- Better E2E test coverage
- Fewer implementation gaps
- Standardized testing scenarios

---

## üîó IMPROVEMENT #5: RICH IMPLEMENTATION CONTEXT (LOW - ENHANCEMENT)

### The Context Gap

**Current State**: BMAD enhancement provides basic context fields, but often underutilized

**Context Engineering Fields** (Current):
1. implementation_context
2. architecture_references
3. example_code_patterns
4. testing_scenarios
5. edge_cases
6. integration_points

### NEW: Context Enrichment Guidelines

**Enhanced Context Requirements**:

**1. Architecture References** (MANDATORY)
\`\`\`javascript
{
  architecture_references: {
    similar_components: [
      'src/components/ventures/CreateVentureDialog.tsx',
      'src/components/ventures/UpdateFinancialsDialog.tsx'
    ],
    patterns_to_follow: [
      'Dialog pattern (shadcn/ui)',
      'Form validation (react-hook-form)',
      'Supabase mutation pattern'
    ],
    integration_points: [
      'src/lib/supabase.ts - Database client',
      'src/hooks/useVentures.ts - Data fetching',
      'src/components/layout/Navigation.tsx - Menu entry'
    ]
  }
}
\`\`\`

**2. Example Code Patterns** (RECOMMENDED)
\`\`\`javascript
{
  example_code_patterns: {
    database_query: \`
      const { data, error } = await supabase
        .from('ventures')
        .insert({ name, description, category })
        .select()
        .single();
    \`,
    form_validation: \`
      const schema = z.object({
        name: z.string().min(3, 'Name must be at least 3 characters'),
        category: z.enum(['Technology', 'Healthcare', 'Finance'])
      });
    \`,
    error_handling: \`
      if (error) {
        toast.error('Failed to create venture: ' + error.message);
        return;
      }
      toast.success('Venture created successfully');
    \`
  }
}
\`\`\`

**3. Testing Scenarios** (MANDATORY - Links to Improvement #1)
\`\`\`javascript
{
  testing_scenarios: {
    e2e_test_location: 'tests/e2e/ventures/US-001-create-venture.spec.ts',
    test_cases: [
      { id: 'TC-001', scenario: 'Happy path', priority: 'P0' },
      { id: 'TC-002', scenario: 'Validation error', priority: 'P1' },
      { id: 'TC-003', scenario: 'Duplicate name', priority: 'P2' }
    ]
  }
}
\`\`\`

**Context Quality Score**:
- **Bronze (50%)**: Basic title + acceptance criteria
- **Silver (75%)**: + Architecture references + Testing scenarios
- **Gold (90%)**: + Example code patterns + Integration points
- **Platinum (100%)**: + Edge cases + Security considerations + Performance notes

**Expected Impact**:
- Reduced EXEC confusion
- Faster implementation (clear examples)
- Better code consistency
- Fewer "where do I put this?" questions

---

## Core Capabilities (NEW - v2.0.0)

**Original BMAD Enhancement**:
1. implementation_context field
2. architecture_references field
3. example_code_patterns field
4. testing_scenarios field
5. edge_cases field
6. integration_points field

**NEW Capabilities (v2.0.0)**:
7. **üö® CRITICAL**: Automated E2E test mapping (scans tests, updates user_stories table)
8. **‚ö†Ô∏è HIGH**: Automatic validation on EXEC completion (auto-validates when deliverables done)
9. **üìã MEDIUM**: INVEST criteria enforcement (validates quality during creation)
10. **üéØ MEDIUM**: Acceptance criteria templates (Given-When-Then format with happy/error/edge paths)
11. **üîó LOW**: Rich implementation context enrichment (architecture refs, code examples, test scenarios)
12. **Coverage enforcement**: 100% E2E test mapping required (blocks handoff if incomplete)
13. **Quality scoring**: Context quality score (Bronze/Silver/Gold/Platinum)
14. **Validation gates**: Auto-validation prevents progress calculation issues

---

## Integration with LEO Protocol

### PLAN Phase (User Story Creation)
- **BEFORE**: Stories created with basic info
- **NOW**: Stories validated against INVEST criteria
- **NOW**: Acceptance criteria use templates (Given-When-Then)
- **NOW**: Implementation context enriched with architecture references

### EXEC Phase (Implementation)
- **BEFORE**: EXEC reads stories, implements features
- **NOW**: EXEC uses rich context (examples, references, patterns)
- **NOW**: E2E tests follow US-XXX naming convention

### EXEC‚ÜíPLAN Handoff (Validation)
- **BEFORE**: Manual validation required
- **NOW**: Auto-validate user stories when deliverables complete (Improvement #2)
- **NOW**: Auto-map E2E tests to user stories (Improvement #1)
- **NOW**: Block handoff if coverage < 100%

### PLAN Verification (Final Check)
- **BEFORE**: Check deliverables, run sub-agents
- **NOW**: Verify user story validation_status = 'validated'
- **NOW**: Verify e2e_test_path populated for all stories
- **NOW**: Progress calculation uses accurate data

---

## Key Learnings Integration

**Success Patterns**:
- **US-XXX Naming Convention**: Made retrospective mapping possible (Improvement #1)
- **Database-First Tracking**: Protocol correctly requires it, now automated (Improvement #1, #2)
- **Given-When-Then Format**: Clear testability (Improvement #4)
- **Context Engineering**: Reduced EXEC confusion (Improvement #5)

**Failure Patterns**:
- **Validation Gap** (SD-TEST-MOCK-001): 30 min debugging, progress stuck at 85%
- **Mapping Gap** (SD-VIF-INTEL-001): 26 user stories unmapped, manual workaround needed
- **Quality Variance**: User stories vary widely in quality and completeness
- **Context Underutilization**: Rich context fields often empty or minimal

---

## Expected Impact Summary

| Improvement | Priority | Time Savings | Quality Impact |
|-------------|----------|--------------|----------------|
| #1: E2E Test Mapping | üö® CRITICAL | 15-20 min per SD | 100% coverage enforced |
| #2: Auto-Validation | ‚ö†Ô∏è HIGH | 15-20 min per SD | Zero blocked handoffs |
| #3: INVEST Criteria | üìã MEDIUM | 10-15 min per SD | Higher story quality |
| #4: AC Templates | üéØ MEDIUM | 10-15 min per SD | Clearer acceptance criteria |
| #5: Rich Context | üîó LOW | 20-30 min per SD | Reduced EXEC confusion |

**Total Expected Impact per SD**:
- **Time Savings**: 70-100 minutes per SD (automation + clearer context)
- **Quality**: 100% E2E coverage, zero validation blocks, standardized format
- **EXEC Efficiency**: 25-30% reduction in clarification questions
- **Test Coverage**: 100% automated enforcement (vs manual checking)

**Annual Impact** (assuming 50 SDs/year):
- **Time Savings**: 58-83 hours/year
- **Issues Prevented**: 100+ validation/mapping failures
- **Quality Score**: +15-20% improvement in user story completeness

---

## Tools to Create (Future Work)

1. \`scripts/map-e2e-tests-to-user-stories.js\` - Automated E2E test mapping (CRITICAL)
2. \`scripts/auto-validate-user-stories-on-exec-complete.js\` - Auto-validation (HIGH)
3. \`scripts/validate-invest-criteria.js\` - INVEST quality checker (MEDIUM)
4. \`scripts/generate-acceptance-criteria-template.js\` - AC template generator (MEDIUM)
5. \`scripts/enrich-user-story-context.js\` - Context enrichment tool (LOW)

---

## Version History

- **v1.0.0**: Initial BMAD enhancement - Context engineering fields
- **v2.0.0** (2025-10-26): Key Learnings Edition - 5 critical improvements from user story validation gaps, E2E test mapping issues, and quality analysis

---

**BOTTOM LINE**: STORIES v2.0.0 adds automation (E2E mapping, auto-validation), quality enforcement (INVEST criteria, AC templates), and rich context to eliminate user story validation gaps (30 min saved), mapping gaps (15-20 min saved), and EXEC confusion (20-30 min saved). Well-written stories with automated validation prevent 70-100 minutes of rework per SD.`;

  // Updated capabilities
  const updatedCapabilities = [
    'Context engineering fields: implementation_context, architecture_references, example_code_patterns, testing_scenarios, edge_cases, integration_points',
    'üö® CRITICAL: Automated E2E test mapping (scans tests, links to user_stories table, enforces 100% coverage)',
    '‚ö†Ô∏è HIGH: Automatic validation on EXEC completion (auto-validates when deliverables done, unblocks progress)',
    'üìã MEDIUM: INVEST criteria enforcement (validates quality during creation: Independent, Negotiable, Valuable, Estimable, Small, Testable)',
    'üéØ MEDIUM: Acceptance criteria templates (Given-When-Then format with happy/error/edge paths)',
    'üîó LOW: Rich implementation context enrichment (architecture refs, code examples, test scenarios, integration points)',
    'Coverage enforcement: 100% E2E test mapping required (blocks EXEC‚ÜíPLAN handoff if incomplete)',
    'Quality scoring: Context quality score (Bronze/Silver/Gold/Platinum based on completeness)',
    'Validation gates: Auto-validation prevents progress calculation issues (SD-TEST-MOCK-001 prevention)',
    'Automated mapping: Scans E2E test files, extracts US-XXX references, updates database (SD-VIF-INTEL-001 prevention)'
  ];

  // Updated metadata
  const updatedMetadata = {
    version: '2.0.0',
    enhanced: '2025-10-26',
    original_feature: 'BMAD Enhancement - Context Engineering',
    improvements: {
      '1_e2e_test_mapping': {
        priority: 'CRITICAL',
        impact: '100% E2E coverage enforced, 15-20 min saved per SD, prevents SD-VIF-INTEL-001 issues',
        source: 'ROOT_CAUSE_USER_STORY_MAPPING_GAP.md (339 lines), SD-VIF-INTEL-001',
        tools_to_create: ['scripts/map-e2e-tests-to-user-stories.js']
      },
      '2_auto_validation': {
        priority: 'HIGH',
        impact: 'Zero blocked handoffs, 15-20 min saved per SD, prevents SD-TEST-MOCK-001 issues',
        source: 'user-story-validation-gap.md (156 lines), SD-TEST-MOCK-001',
        tools_to_create: ['scripts/auto-validate-user-stories-on-exec-complete.js']
      },
      '3_invest_criteria': {
        priority: 'MEDIUM',
        impact: 'Higher story quality, 10-15 min saved per SD, standardized format',
        source: 'docs/02_api/14_development_preparation.md (RR-002)',
        tools_to_create: ['scripts/validate-invest-criteria.js']
      },
      '4_ac_templates': {
        priority: 'MEDIUM',
        impact: 'Clearer acceptance criteria, 10-15 min saved per SD, better testability',
        source: 'Best practices analysis, Given-When-Then format',
        tools_to_create: ['scripts/generate-acceptance-criteria-template.js']
      },
      '5_rich_context': {
        priority: 'LOW',
        impact: 'Reduced EXEC confusion, 20-30 min saved per SD, better code consistency',
        source: 'BMAD enhancement underutilization analysis',
        tools_to_create: ['scripts/enrich-user-story-context.js']
      }
    },
    key_learnings_sources: [
      'user-story-validation-gap.md: SD-TEST-MOCK-001 (30 min debugging, progress blocked)',
      'ROOT_CAUSE_USER_STORY_MAPPING_GAP.md: SD-VIF-INTEL-001 (26 unmapped stories, CRITICAL gap)',
      'validation-agent-proactive-gates.md: SD-EVA-MEETING-001 (user story validation requirements)',
      'docs/02_api/14_development_preparation.md: RR-002 (user story quality criteria)'
    ],
    failure_patterns: [
      'User stories not validated after EXEC completion (SD-TEST-MOCK-001)',
      'E2E tests exist but not linked to user stories (SD-VIF-INTEL-001 - 26 stories)',
      'Acceptance criteria incomplete or missing Given-When-Then',
      'INVEST criteria not enforced during creation',
      'Implementation context underutilized (fields empty or minimal)',
      'Manual validation workarounds bypass quality gates'
    ],
    success_patterns: [
      'US-XXX naming convention makes retrospective mapping possible',
      'Database-first tracking with automated updates',
      'Given-When-Then format provides clear testability',
      'Context engineering reduces EXEC confusion',
      'Auto-validation prevents progress calculation issues',
      '100% coverage enforcement catches gaps early'
    ],
    time_savings_potential: '58-83 hours/year (50 SDs √ó 70-100 min each)',
    issues_prevented_annually: '100+ validation/mapping failures',
    quality_improvement: '+15-20% improvement in user story completeness'
  };

  try {
    // Update the STORIES sub-agent in the database
    const { data, error } = await supabase
      .from('leo_sub_agents')
      .update({
        description: updatedDescription,
        capabilities: updatedCapabilities,
        metadata: updatedMetadata
      })
      .eq('code', 'STORIES')
      .select();

    if (error) {
      console.error('‚ùå Error updating STORIES sub-agent:', error);
      process.exit(1);
    }

    console.log('‚úÖ STORIES sub-agent updated successfully!\n');
    console.log('Updated fields:');
    console.log('- Description: v2.0.0 with 5 improvements');
    console.log('- Capabilities: 10 capabilities (5 new)');
    console.log('- Metadata: Detailed improvement tracking\n');

    console.log('üìä Improvements Added:');
    console.log('1. üö® CRITICAL: Automated E2E test mapping');
    console.log('2. ‚ö†Ô∏è  HIGH: Automatic validation on EXEC completion');
    console.log('3. üìã MEDIUM: INVEST criteria enforcement');
    console.log('4. üéØ MEDIUM: Acceptance criteria templates');
    console.log('5. üîó LOW: Rich implementation context enrichment\n');

    console.log('üí° Tools to Create:');
    console.log('   - scripts/map-e2e-tests-to-user-stories.js (CRITICAL)');
    console.log('   - scripts/auto-validate-user-stories-on-exec-complete.js (HIGH)');
    console.log('   - scripts/validate-invest-criteria.js');
    console.log('   - scripts/generate-acceptance-criteria-template.js');
    console.log('   - scripts/enrich-user-story-context.js\n');

    return data;

  } catch (_err) {
    console.error('‚ùå Unexpected error:', err);
    process.exit(1);
  }
}

// Run the update
updateStoriesSubAgent().then(() => {
  console.log('üéâ Update complete!');
  process.exit(0);
});
