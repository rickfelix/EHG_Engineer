name: Backlog Integrity - Staging Read-Only

on:
  schedule:
    - cron: '0 4 * * *'  # Daily at 4 AM UTC
  workflow_dispatch:
    inputs:
      dry_run:
        description: 'Skip actual DB queries (test mode)'
        type: boolean
        default: false

jobs:
  staging-integrity-check:
    runs-on: ubuntu-latest
    if: vars.ENABLE_STAGING_CHECKS == 'true'  # Repository variable guard
    
    permissions:
      contents: read
      pull-requests: write
      actions: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup PostgreSQL client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client
      
      - name: Run staging integrity queries
        if: ${{ !inputs.dry_run }}
        env:
          DATABASE_URL: ${{ secrets.SUPABASE_POOLER_URL }}
        run: |
          set -e
          
          echo "ðŸ” Running backlog integrity checks against staging..."
          mkdir -p reports
          
          # Execute the staging SQL file
          psql "$DATABASE_URL" -f ops/checks/backlog_integrity_staging.sql
          
          # Move generated CSVs to reports/
          mv *.csv reports/ 2>/dev/null || true
          
          echo "âœ… Staging checks complete"

      - name: Generate dry-run placeholder
        if: ${{ inputs.dry_run }}
        run: |
          mkdir -p reports
          echo "timestamp,check,status" > reports/dry_run_placeholder.csv
          echo "$(date -u +%Y-%m-%dT%H:%M:%SZ),dry_run,skipped" >> reports/dry_run_placeholder.csv

      - name: Record baseline counts
        if: ${{ !inputs.dry_run }}
        run: |
          count() { [ -f "$1" ] && echo $(( $(wc -l < "$1") - 1 )) || echo 0; }
          SD=$(count reports/sd_metadata_gaps.csv)
          PRD=$(count reports/prd_contract_gaps.csv)
          BL=$(count reports/backlog_shape_issues.csv)
          TR=$(count reports/traceability_gaps.csv)
          DEP=$(count reports/gap_dependencies.csv)
          ORPH=$(count reports/orphans.csv)
          {
            echo "BASE_SD=${SD}"
            echo "BASE_PRD=${PRD}"
            echo "BASE_BL=${BL}"
            echo "BASE_TR=${TR}"
            echo "BASE_DEP=${DEP}"
            echo "BASE_ORPH=${ORPH}"
          } > reports/_baseline.env

      - name: Generate summary
        if: always()
        run: |
          echo "## Backlog Integrity Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Gap Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f reports/sd_metadata_gaps.csv ]; then
            count=$(tail -n +2 reports/sd_metadata_gaps.csv | wc -l)
            echo "- **SD Metadata Gaps**: $count issues" >> $GITHUB_STEP_SUMMARY
          fi

          if [ -f reports/prd_contract_gaps.csv ]; then
            count=$(tail -n +2 reports/prd_contract_gaps.csv | wc -l)
            echo "- **PRD Contract Gaps**: $count issues" >> $GITHUB_STEP_SUMMARY
          fi

          if [ -f reports/backlog_shape_issues.csv ]; then
            count=$(tail -n +2 reports/backlog_shape_issues.csv | wc -l)
            echo "- **Backlog Shape Issues**: $count items" >> $GITHUB_STEP_SUMMARY
          fi

          if [ -f reports/traceability_gaps.csv ]; then
            count=$(tail -n +2 reports/traceability_gaps.csv | wc -l)
            echo "- **Traceability Gaps**: $count orphans" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **Traceability**: âš ï¸ View not available (expected)" >> $GITHUB_STEP_SUMMARY
          fi

          if [ -f reports/gap_dependencies.csv ]; then
            count=$(tail -n +2 reports/gap_dependencies.csv | wc -l)
            echo "- **Dependency Issues**: $count problems" >> $GITHUB_STEP_SUMMARY
          fi

          if [ -f reports/orphans.csv ]; then
            count=$(tail -n +2 reports/orphans.csv | wc -l)
            echo "- **Orphan Backlog Items**: $count items" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“Š Reports available as workflow artifacts" >> $GITHUB_STEP_SUMMARY

      - name: Backlog integrity â€“ asserts (critical only)
        if: ${{ vars.ENABLE_BACKLOG_ASSERTS == '1' }}
        env:
          DATABASE_URL: ${{ secrets.SUPABASE_POOLER_URL }}
        run: |
          # Defaults to 0 if not set
          ORPHAN_MAX="${{ vars.ORPHAN_MAX || 0 }}"
          PRD_MAX="${{ vars.PRD_MAX || 0 }}"
          psql "$DATABASE_URL" \
               -v ON_ERROR_STOP=1 \
               -v ORPHAN_MAX="${ORPHAN_MAX}" \
               -v PRD_MAX="${PRD_MAX}" \
               -f ops/checks/backlog_assert_critical.sql

      - name: Backlog integrity â€“ dependency cycle asserts (staging)
        if: ${{ vars.ENABLE_DEP_ASSERTS == '1' }}
        env:
          DATABASE_URL: ${{ secrets.SUPABASE_POOLER_URL }}
        run: |
          DEP_CYCLES_MAX="${{ vars.DEP_CYCLES_MAX || 0 }}"
          psql "$DATABASE_URL" \
               -v ON_ERROR_STOP=1 \
               -v DEP_CYCLES_MAX="${DEP_CYCLES_MAX}" \
               -f ops/checks/backlog_assert_cycles.sql

      - name: Apply backlog normalizations (staging, guarded)
        if: ${{ vars.APPLY_BACKLOG_FIXES == '1' && vars.STAGING_WRITE_OK == '1' }}
        env:
          DATABASE_URL: ${{ secrets.SUPABASE_POOLER_URL }}
        run: |
          # Set DRY_RUN=1 for a safe preview; set to 0 to commit.
          DRY_RUN="${{ vars.DRY_RUN || '1' }}"
          psql "$DATABASE_URL" \
               -v ON_ERROR_STOP=1 \
               -v DRY_RUN="${DRY_RUN}" \
               -f ops/jobs/backlog_apply_fixes_staging.sql

          # Re-export CSVs after a committed run so the summary reflects changes
          if [ "$DRY_RUN" = "0" ]; then
            psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -f ops/checks/backlog_integrity_staging.sql
            # Move regenerated CSVs to reports/
            mv *.csv reports/ 2>/dev/null || true
          fi

      - name: Apply orphan link mappings (staging, guarded)
        if: ${{ vars.APPLY_ORPHAN_LINKS == '1' && vars.STAGING_WRITE_OK == '1' }}
        env:
          DATABASE_URL: ${{ secrets.SUPABASE_POOLER_URL }}
        run: |
          set -euo pipefail
          if [ ! -f ops/inbox/orphan_links.csv ]; then
            echo "No ops/inbox/orphan_links.csv found; skipping apply."
            exit 0
          fi
          DRY_RUN="${{ vars.DRY_RUN || '1' }}"
          psql "$DATABASE_URL" \
               -v ON_ERROR_STOP=1 \
               -v DRY_RUN="${DRY_RUN}" \
               -f ops/jobs/orphan_apply_links_staging.sql
          # If committed, refresh exports so counts reflect the change
          if [ "$DRY_RUN" = "0" ]; then
            psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -f ops/checks/backlog_integrity_staging.sql
            # Move regenerated CSVs to reports/
            mv *.csv reports/ 2>/dev/null || true
          fi

      - name: Summarize deltas (post-apply)
        if: ${{ (vars.APPLY_BACKLOG_FIXES == '1' || vars.APPLY_ORPHAN_LINKS == '1') && vars.STAGING_WRITE_OK == '1' && vars.DRY_RUN == '0' }}
        run: |
          count() { [ -f "$1" ] && echo $(( $(wc -l < "$1") - 1 )) || echo 0; }
          . reports/_baseline.env 2>/dev/null || true

          SD=$(count reports/sd_metadata_gaps.csv)
          PRD=$(count reports/prd_contract_gaps.csv)
          BL=$(count reports/backlog_shape_issues.csv)
          TR=$(count reports/traceability_gaps.csv)
          DEP=$(count reports/gap_dependencies.csv)
          ORPH=$(count reports/orphans.csv)

          d() {
            local delta=$(( $2 - $1 ))
            if [ $delta -lt 0 ]; then
              echo "$delta"
            elif [ $delta -gt 0 ]; then
              echo "+$delta"
            else
              echo "0"
            fi
          }

          {
            echo ""
            echo "### ðŸ“Š Backlog Integrity â€” Deltas (Applied)"
            echo ""
            echo "| Category | Before | After | Change |"
            echo "|----------|--------|-------|--------|"
            echo "| SD Metadata | ${BASE_SD:-0} | ${SD} | $(d ${BASE_SD:-0} ${SD}) |"
            echo "| PRD Contract | ${BASE_PRD:-0} | ${PRD} | $(d ${BASE_PRD:-0} ${PRD}) |"
            echo "| Backlog Shape | ${BASE_BL:-0} | ${BL} | $(d ${BASE_BL:-0} ${BL}) |"
            echo "| Traceability | ${BASE_TR:-0} | ${TR} | $(d ${BASE_TR:-0} ${TR}) |"
            echo "| Dependencies | ${BASE_DEP:-0} | ${DEP} | $(d ${BASE_DEP:-0} ${DEP}) |"
            echo "| Orphans | ${BASE_ORPH:-0} | ${ORPH} | $(d ${BASE_ORPH:-0} ${ORPH}) |"
            echo ""
            echo "âœ… Fixes applied successfully"
          } >> $GITHUB_STEP_SUMMARY

      - name: Upload reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backlog-integrity-reports-${{ github.run_id }}
          path: reports/
          retention-days: 30
      
      - name: Handle failure gracefully
        if: failure()
        run: |
          echo "::warning::Backlog integrity check encountered issues. This is non-blocking."
          echo "Check the artifacts for any partial reports generated."
          exit 0  # Don't fail the workflow