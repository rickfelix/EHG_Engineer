# CLAUDE.md - LEO Protocol Workflow Guide for AI Agents

## ‚ö†Ô∏è DO NOT EDIT THIS FILE DIRECTLY

**This file is AUTO-GENERATED from the database.**

## To Make Changes:
1. **For dynamic content** (agents, sub-agents, triggers): Update database tables directly
2. **For static sections** (guides, examples, instructions): Add/update in `leo_protocol_sections` table
3. **Regenerate file**: Run `node scripts/generate-claude-md-from-db.js`

**Any direct edits to this file will be lost on next regeneration!**

See documentation for table structure: `database/schema/007_leo_protocol_schema_fixed.sql`


## Session Prologue (Short)

1. **Follow LEAD‚ÜíPLAN‚ÜíEXEC** - Target ‚â•85% gate pass rate
2. **Use sub-agents** - Architect, QA, Reviewer - summarize outputs
3. **Database-first** - No markdown files as source of truth
4. **USE PROCESS SCRIPTS** - ‚ö†Ô∏è NEVER bypass add-prd-to-database.js, unified-handoff-system.js ‚ö†Ô∏è
5. **Small PRs** - Target ‚â§100 lines, max 400 with justification
6. **Priority-first** - Use `npm run prio:top3` to justify work

*For copy-paste version: see `templates/session-prologue.md` (generate via `npm run session:prologue`)*


## üèóÔ∏è Application Architecture - CRITICAL CONTEXT

### Two Distinct Applications:
1. **EHG_Engineer** (Management Dashboard) - WHERE YOU ARE NOW
   - **Path**: `/mnt/c/_EHG/EHG_Engineer/`
   - **Purpose**: LEO Protocol dashboard for managing Strategic Directives & PRDs
   - **Database**: dedlbzhpgkmetvhbkyzq (Supabase)
   - **GitHub**: https://github.com/rickfelix/EHG_Engineer.git
   - **Port**: 3000-3001
   - **Role**: MANAGEMENT TOOL ONLY - no customer features here!

2. **EHG** (Business Application) - IMPLEMENTATION TARGET
   - **Path**: `/mnt/c/_EHG/ehg/`
   - **Purpose**: The actual customer-facing business application
   - **Database**: liapbndqlqxdcgpwntbv (Supabase)
   - **GitHub**: https://github.com/rickfelix/ehg.git
   - **Built with**: Vite + React + Shadcn + TypeScript
   - **Role**: WHERE ALL FEATURES GET IMPLEMENTED

### ‚ö†Ô∏è CRITICAL: During EXEC Phase Implementation
1. **Read PRD** from EHG_Engineer database
2. **Navigate** to `/mnt/c/_EHG/ehg/` for implementation
3. **Make code changes** in EHG application (NOT in EHG_Engineer!)
4. **Push changes** to EHG's GitHub repo: `rickfelix/ehg.git`
5. **Track progress** in EHG_Engineer dashboard

### üîÑ Workflow Relationship
```
EHG_Engineer (Management)          EHG App (Implementation)
‚îú‚îÄ‚îÄ Strategic Directives     ‚Üí     Features implemented here
‚îú‚îÄ‚îÄ PRDs                     ‚Üí     Code changes made here
‚îú‚îÄ‚îÄ Progress Tracking        ‚Üê     Results verified from here
‚îî‚îÄ‚îÄ Dashboard Views          ‚Üê     No changes here!
```


## ‚ö†Ô∏è DYNAMICALLY GENERATED FROM DATABASE
**Last Generated**: 2025-10-29 10:14:10 PM
**Source**: Supabase Database (not files)
**Auto-Update**: Run `node scripts/generate-claude-md-from-db.js` anytime

## üü¢ CURRENT LEO PROTOCOL VERSION: vv4.2.0_story_gates

**CRITICAL**: This is the ACTIVE version from database
**ID**: leo-v4-2-0-story-gates
**Status**: ACTIVE
**Title**: LEO Protocol v4.2.0 - Story Gates & Automated Release Control

### üìÖ Protocol Management

**Database-First Architecture**:
- Protocol stored in `leo_protocols` table
- Sub-agents in `leo_sub_agents` table
- Handoffs in `leo_handoff_templates` table
- Single source of truth - no file conflicts

**To update protocol version**:
```sql
-- Only via database operations
UPDATE leo_protocols SET status = 'active' WHERE version = 'new_version';
UPDATE leo_protocols SET status = 'superseded' WHERE version != 'new_version';
```

## Agent Responsibilities

| Agent | Code | Responsibilities | % Split |
|-------|------|------------------|----------|

**Legend**: P=Planning, I=Implementation, V=Verification, A=Approval
**Total**: EXEC (30%) + LEAD (35%) + PLAN (35%) = 100%

## üö® EXEC Agent Implementation Requirements

### MANDATORY Pre-Implementation Verification
Before writing ANY code, EXEC MUST:

0. **AMBIGUITY RESOLUTION** üîç CRITICAL FIRST STEP
   - Review PRD for unclear requirements, missing details, or conflicting specifications
   - Do NOT proceed with implementation if ANY ambiguity exists
   - Use 3-tier escalation to resolve:
     1. **Re-read PRD**: Check acceptance_criteria, functional_requirements, test_scenarios
     2. **Query database context**: Check user stories, implementation_context, SD strategic_objectives
     3. **Ask user**: Use AskUserQuestion tool with specific, focused questions
   - Document resolution: "Ambiguity in [area] resolved via [method]: [resolution]"
   - **If still unclear after escalation**: BLOCK implementation and await user clarification

**Common Ambiguities to Watch For**:
- Vague feature descriptions ("improve UX", "make it better")
- Missing edge case handling ("what if user inputs invalid data?")
- Unclear success criteria ("should be fast", "should look good")
- Conflicting requirements between PRD sections
- Undefined behavior for error states

**Example Ambiguity Resolution**:
```
‚ùå BAD: Guess at implementation based on similar feature
‚úÖ GOOD:
  - Tier 1: Re-read PRD section 3.2 ‚Üí Still unclear on validation rules
  - Tier 2: Query user_stories table ‚Üí Found implementation_context with validation spec
  - Resolution: "Email validation will use regex pattern from US-002 context"
```

1. **APPLICATION CHECK** ‚ö†Ô∏è CRITICAL
   - Confirm target app: `/mnt/c/_EHG/ehg/` (NOT EHG_Engineer!)
   - Verify: `cd /mnt/c/_EHG/ehg && pwd` should show `/mnt/c/_EHG/ehg`
   - Check GitHub: `git remote -v` should show `rickfelix/ehg.git`
   - If you're in EHG_Engineer, you're in the WRONG place for implementation!

2. **URL Verification** ‚úÖ
   - Navigate to the EXACT URL specified in the PRD
   - Confirm the page loads and is accessible
   - Take a screenshot for evidence
   - Document: "Verified: [URL] is accessible"

3. **Component Identification** üéØ
   - Identify the exact file path of the target component
   - Confirm component exists at specified location
   - Document: "Target component: [full/path/to/component.tsx]"

4. **Application Context** üìÅ
   - Verify correct application directory
   - Confirm port number matches PRD
   - Document: "Application: [/path/to/app] on port [XXXX]"

5. **Visual Confirmation** üì∏
   - Screenshot current state BEFORE changes
   - Identify exact location for new features
   - Document: "Current state captured, changes will go at [location]"

### Implementation Checklist Template
```markdown
## EXEC Pre-Implementation Checklist
- [ ] **Ambiguity Check**: All requirements clear and unambiguous
- [ ] **Ambiguity Resolution**: [NONE FOUND | Resolved via Tier X: description]
- [ ] **Application verified**: [/mnt/c/_EHG/ehg/ confirmed]
- [ ] **URL verified**: [exact URL from PRD]
- [ ] **Page accessible**: [YES/NO]
- [ ] **Component identified**: [path/to/component]
- [ ] **Port confirmed**: [port number]
- [ ] **Screenshot taken**: [timestamp]
- [ ] **Target location confirmed**: [where changes go]
```

### Common Mistakes to AVOID
- ‚ùå Assuming component location based on naming similarity
- ‚ùå Implementing without navigating to the URL first
- ‚ùå Ignoring port numbers in URLs
- ‚ùå Pattern matching without verification
- ‚ùå Starting to code before completing checklist
- ‚ùå Not restarting dev servers after changes
- ‚ùå **CRITICAL**: Creating files for PRDs, handoffs, or documentation
- ‚ùå **CRITICAL**: Proceeding with implementation when requirements are ambiguous


## üîÑ Git Commit Guidelines

**Git Commit Guidelines**: `<type>(<SD-ID>): <subject>` format MANDATORY

**Required**: Type (feat/fix/docs/etc), SD-ID scope, imperative subject, AI attribution in footer
**Timing**: After checklist items, before context switches, at logical breakpoints
**Branch Strategy**: `eng/` prefix for EHG_Engineer, standard prefixes for EHG app features
**Size**: <100 lines ideal, <200 max

**Full Guidelines**: See `docs/03_protocols_and_standards/leo_git_commit_guidelines_v4.2.0.md`


## PR Size Guidelines

**Philosophy**: Balance AI capability with human review capacity. Modern AI can handle larger changes, but humans still need to review them.

**Three Tiers**:

1. **‚â§100 lines (Sweet Spot)** - No justification needed
   - Simple bug fixes
   - Single feature additions
   - Configuration changes
   - Documentation updates

2. **101-200 lines (Acceptable)** - Brief justification in PR description
   - Multi-component features
   - Refactoring with tests
   - Database migrations with updates
   - Example: "Adds authentication UI (3 components) + tests"

3. **201-400 lines (Requires Strong Justification)** - Detailed rationale required
   - Complex features that cannot be reasonably split
   - Large refactorings with extensive test coverage
   - Third-party integrations with configuration
   - Must explain why splitting would create more risk/complexity
   - Example: "OAuth integration requires provider config, UI flows, session management, and error handling as atomic unit"

**Over 400 lines**: Generally prohibited. Split into multiple PRs unless exceptional circumstances (emergency hotfix, external dependency forcing bundled changes).

**Key Principle**: If you can split it without creating incomplete/broken intermediate states, you should split it.


## üìä Communication & Context

### Communication Style

**Brief by Default**: Responses should be concise and action-oriented unless the user explicitly requests detailed explanations.

**When to be Brief** (default):
- Status updates and progress reports
- Acknowledging commands or requests
- Confirming successful operations
- Error messages (summary + fix)
- Tool invocation descriptions

**When to be Verbose** (only if requested):
- User asks "explain in detail"
- User requests "comprehensive" or "thorough" analysis
- Teaching or knowledge transfer scenarios
- Complex debugging requiring full context
- Documentation generation

**Examples**:

| Context | ‚ùå Verbose (unnecessary) | ‚úÖ Brief (preferred) |
|---------|------------------------|---------------------|
| File created | "I have successfully created the file at the specified path with all the requested content..." | "File created: path/to/file.md" |
| Test passed | "The test suite has been executed and all tests have passed successfully with 100% coverage..." | "‚úÖ Tests passed (100% coverage)" |
| Next step | "Now I will proceed to the next step which involves updating the database schema..." | "Updating database schema..." |

### Context Economy Rules

**Core Principles**:
- **Response Budget**: ‚â§500 tokens default (unless complexity requires more)
- **Summarize > Paste**: Reference paths/links instead of full content
- **Fetch-on-Demand**: Name files first, retrieve only needed parts
- **Running Summaries**: Keep condensed handoff/PR descriptions

### Best Practices

**Efficient Context Usage**:
- **Quote selectively**: Show only relevant lines with context
- **Use file:line references**: `src/component.js:42-58` instead of full file
- **Batch related reads**: Minimize round-trips when exploring
- **Archive verbosity**: Move details to handoffs/database, not conversation

### Examples

| ‚ùå Inefficient | ‚úÖ Efficient |
|----------------|--------------|
| Paste entire 500-line file | Quote lines 42-58 with `...` markers |
| Read file multiple times | Batch read relevant sections once |
| Repeat full error in response | Summarize error + reference line |
| Include all test output | Show failed tests + counts only |

### üîÑ MANDATORY: Server Restart Protocol
After ANY code changes:
1. **Kill the dev server**: `kill [PID]` or Ctrl+C
2. **Restart the server**: `npm run dev` or appropriate command
3. **Wait for ready message**: Confirm server is fully started
4. **Hard refresh browser**: Ctrl+Shift+R / Cmd+Shift+R
5. **Verify changes are live**: Test the new functionality

**WHY**: Dev servers may cache components, especially new files. Hot reload is NOT always reliable.


## Parallel Execution

**When to Use**: Modern AI supports parallel tool execution for independent operations. Use conservatively.

**Safe for Parallel Execution**:
- ‚úÖ Reading multiple independent files for analysis
- ‚úÖ Running multiple independent database queries
- ‚úÖ Executing multiple read-only Git commands (status, log, diff)
- ‚úÖ Multiple WebFetch calls to different URLs
- ‚úÖ Batch file searches (multiple Glob operations)

**NOT Safe for Parallel Execution**:
- ‚ùå Write operations (Edit, Write tools)
- ‚ùå Database mutations (INSERT, UPDATE, DELETE)
- ‚ùå Any operations where order matters
- ‚ùå Operations that depend on each other's results
- ‚ùå Git operations that modify state (commit, push, merge)

**Critical Constraint**: Context sharing between parallel operations is limited. Each operation receives the same initial context but cannot see other parallel operations' results until they all complete.

**Example Use Case**:
```
"Read the following 3 files for analysis:"
- Read src/component.tsx
- Read src/types.ts
- Read tests/component.test.tsx
```

**Anti-Pattern**:
```
"Read file A, then based on what you find, read file B"
(Must be sequential - second read depends on first)
```


## Progress Calculation

```
Total =  = 100%
```

## üéØ LEAD Agent Operations

**LEAD Agent Operations**: Strategic planning, business objectives, final approval.

**Finding Active SDs**: `node scripts/query-active-sds.js` or query `strategic_directives_v2` table directly

**Decision Matrix**:
- Draft ‚Üí Review & approve
- Pending Approval ‚Üí Final review  
- Active ‚Üí Create LEAD‚ÜíPLAN handoff
- In Progress ‚Üí Monitor execution

**Key Responsibilities**: Strategic direction, priority setting (CRITICAL: 90+, HIGH: 70-89, MEDIUM: 50-69, LOW: 30-49), handoff creation, progress monitoring

**Complete Guide**: See `docs/reference/lead-operations.md`


## üìã Directive Submission Review Process

**Directive Submission Review**: Review submissions before creating SDs.

**Quick Review**:
```bash
node scripts/lead-review-submissions.js
```

**Review Checklist**:
- Chairman input (original intent)
- Intent clarity & strategic alignment
- Priority assessment & scope validation
- Duplicate check & gate progression

**Decision Matrix**:
- Completed + No SD ‚Üí Create SD
- Completed + SD exists ‚Üí Verify & handoff
- Pending ‚Üí Monitor
- Failed ‚Üí Archive/remediate

**Complete Process**: See `docs/reference/directive-submission-review.md`




## Context Router & Loading Strategy

# CLAUDE.md - LEO Protocol Context Router

‚ö†Ô∏è **THIS IS A ROUTER FILE** - Read additional files based on task context

## üìã Loading Strategy (Follow These Steps)

**Step 1: ALWAYS read CLAUDE_CORE.md first** (15k chars)
- Essential workflow, application architecture, git guidelines
- Required for ALL sessions
- Contains: session prologue, execution philosophy, quick reference

**Step 2: Detect user's phase and load appropriate file**

| User Keywords | Load File | Size | Contents |
|--------------|-----------|------|----------|
| "approve SD", "LEAD", "over-engineering", "directive review", "simplicity" | CLAUDE_LEAD.md | 25k | LEAD operations, directive submission, simplicity enforcement |
| "create PRD", "PLAN", "schema validation", "pre-EXEC", "verification" | CLAUDE_PLAN.md | 30k | PRD creation, validation gates, testing strategy |
| "implement", "EXEC", "write code", "component", "test", "build" | CLAUDE_EXEC.md | 20k | Implementation requirements, dual testing, server restart |

**Step 3: Load reference docs ONLY when specific issues arise**

| Issue Type | Load File | Size |
|------------|-----------|------|
| Database errors, schema issues, RLS problems | docs/reference/database-agent-patterns.md | 15k |
| Validation failures, gate blocking | docs/reference/validation-enforcement.md | 14k |
| Test timeouts, E2E issues, Playwright | docs/reference/qa-director-guide.md | 8k |
| Context high (>70%) | docs/reference/context-monitoring.md | 5k |
| Sub-agent compression | docs/reference/sub-agent-compression.md | 6k |
| Handoff creation issues | docs/reference/unified-handoff-system.md | 7k |
| Database migration errors | docs/reference/database-migration-validation.md | 5k |

## üîç Quick Decision Tree

```
START
  ‚Üì
Read CLAUDE_CORE.md (always)
  ‚Üì
User request contains:
  - "approve" OR "LEAD" OR "directive"? ‚Üí Read CLAUDE_LEAD.md
  - "PRD" OR "PLAN" OR "validation"? ‚Üí Read CLAUDE_PLAN.md
  - "implement" OR "EXEC" OR "code"? ‚Üí Read CLAUDE_EXEC.md
  - Specific error/issue? ‚Üí Read relevant docs/reference/*.md
  - General question? ‚Üí CLAUDE_CORE.md is sufficient
  ‚Üì
Proceed with task
```

## üìä Context Budget Tracking

After loading files, you'll have consumed:
- **Router + Core**: 3k + 15k = 18k chars (9% of 200k budget) ‚úÖ HEALTHY
- **Router + Core + Phase**: 18k + 25k avg = 43k chars (22% of budget) ‚úÖ HEALTHY
- **With reference doc**: 43k + 15k avg = 58k chars (29% of budget) ‚úÖ HEALTHY
- **Old CLAUDE.md**: 123k chars (62% of budget) ‚ùå INEFFICIENT

## üìö All Available Context Files

### Core Files (Generated from Database)
1. **CLAUDE_CORE.md** (15k) - Always read first
   - Session prologue
   - Application architecture (EHG vs EHG_Engineer)
   - Execution philosophy
   - Git commit guidelines
   - Communication & context best practices
   - Quick reference commands
   - Development workflow
   - Database operations overview
   - Parallel execution patterns

2. **CLAUDE_LEAD.md** (25k) - LEAD phase operations
   - LEAD agent responsibilities
   - Directive submission review process
   - Over-engineering evaluation rubric
   - Simplicity-first enforcement
   - Strategic validation gate (6 questions)
   - Code review requirements for UI/UX SDs
   - SD evaluation 6-step checklist
   - Phase 4 verification (stubbed code detection)

3. **CLAUDE_PLAN.md** (30k) - PLAN phase operations
   - PLAN pre-EXEC checklist
   - Testing tier strategy
   - CI/CD pipeline verification
   - Component sizing guidelines (300-600 LOC sweet spot)
   - BMAD enhancements (6 improvements)
   - Multi-application testing architecture
   - QA Engineering Director v2.0 guide
   - PR size guidelines
   - Database migration validation
   - Context management proactive monitoring

4. **CLAUDE_EXEC.md** (20k) - EXEC phase operations
   - EXEC implementation requirements
   - Dual test requirement (unit + E2E MANDATORY)
   - TODO comment standard
   - Strategic directive execution protocol
   - 5-phase workflow (EXEC portions)
   - Testing tier strategy (updated)
   - Playwright MCP integration
   - Sub-agent parallel execution

### Reference Documentation (Load on Demand)
5. **docs/reference/database-agent-patterns.md** (15k)
   - Error-triggered invocation patterns
   - Database workaround anti-patterns
   - First-responder checklist
   - Integration requirements

6. **docs/reference/validation-enforcement.md** (14k)
   - Intelligent validation framework (4 gates)
   - Adaptive thresholds (70-100%) based on risk/performance/maturity
   - Phase-aware weighting and non-negotiable blockers
   - Hybrid validation logic (Phase 1 blockers + Phase 2 scoring)
   - Pattern tracking for maturity bonuses
   - Testing guide, debugging, and troubleshooting

7. **docs/reference/qa-director-guide.md** (8k)
   - Enhanced QA Engineering Director v2.0
   - 5-phase workflow
   - Pre-test build validation
   - E2E testing requirements

8. **docs/reference/context-monitoring.md** (5k)
   - Token budget thresholds
   - Proactive monitoring requirements
   - Compaction strategies

9. **docs/reference/sub-agent-compression.md** (6k)
   - 3-tier compression system
   - TIER 1/2/3 patterns
   - When to use each tier

10. **docs/reference/unified-handoff-system.md** (7k)
    - 7-element handoff structure
    - Database-first handoff creation
    - RLS bypass patterns

[Additional reference docs listed with descriptions...]

## üß† Smart Loading Examples

### Example 1: LEAD Approval Request
```
User: "Review and approve SD-EXPORT-001"
AI thinking: Keywords "approve" detected ‚Üí LEAD phase
Actions:
  1. Read CLAUDE_CORE.md (15k)
  2. Read CLAUDE_LEAD.md (25k)
Total context: 40k chars (20% of budget)
Proceed with: LEAD pre-approval process, strategic validation gate
```

### Example 2: Database Error
```
User: "I'm getting 'column does not exist' error when running migration"
AI thinking: Database error detected ‚Üí Need database agent patterns
Actions:
  1. Read CLAUDE_CORE.md (15k)
  2. Read docs/reference/database-agent-patterns.md (15k)
Total context: 30k chars (15% of budget)
Proceed with: Database agent error-triggered invocation
```

### Example 3: Implementation Task
```
User: "Implement the user settings component according to PRD-SETTINGS-001"
AI thinking: Keywords "implement" detected ‚Üí EXEC phase
Actions:
  1. Read CLAUDE_CORE.md (15k)
  2. Read CLAUDE_EXEC.md (20k)
Total context: 35k chars (18% of budget)
Proceed with: EXEC pre-implementation checklist, dual testing
```

## üìè Context Efficiency Rules

**This router system achieves**:
- **85% reduction** on session start (123k ‚Üí 18k chars)
- **65% reduction** with phase loaded (123k ‚Üí 43k avg)
- **On-demand reference loading** (saves 30-50k chars per session)

**Old approach**:
- Loaded full 123k chars immediately
- Consumed 62% of context budget before any work
- Wasted tokens on irrelevant sections

**New approach**:
- Load only what you need
- Start with 9% of budget (18k chars)
- Add phase-specific context as needed (22-24% total)
- Load reference docs selectively (29% max)

## ‚ö†Ô∏è Critical Reminder

**DO NOT** attempt to load old CLAUDE.md (deprecated)
**DO** follow this router's loading strategy
**DO** track context consumption after loading files
**DO** report context health in handoffs

---

*Router generated from database: leo_protocol_sections*
*Last updated: 2025-10-13*
*Part of LEO Protocol v4.2.0 performance optimization*

## Strategic Directive Execution Protocol

# STRATEGIC DIRECTIVE EXECUTION PROTOCOL

**When executing a Strategic Directive, follow this structured 5-phase workflow.**

## Target Application Selection

**CRITICAL FIRST STEP**: Determine which application this SD targets:

- **EHG** (`/mnt/c/_EHG/ehg/`) - Customer-facing features (MOST IMPLEMENTATIONS)
  - Database: liapbndqlqxdcgpwntbv (Supabase)
  - GitHub: rickfelix/ehg.git
  - Stack: Vite + React + Shadcn + TypeScript

- **EHG_Engineer** (`/mnt/c/_EHG/EHG_Engineer/`) - LEO Protocol dashboard/tooling ONLY
  - Database: dedlbzhpgkmetvhbkyzq (Supabase)
  - GitHub: rickfelix/EHG_Engineer.git
  - Role: Management tool, no customer features

## Priority Tiers

- **CRITICAL** (90+): Business-critical, immediate action required
- **HIGH** (70-89): Important features, near-term priority
- **MEDIUM** (50-69): Standard enhancements, planned work
- **LOW** (30-49): Nice-to-have improvements

## Workflow Overview

Execute in order: **LEAD PRE-APPROVAL ‚Üí PLAN PRD ‚Üí EXEC IMPLEMENTATION ‚Üí PLAN VERIFICATION ‚Üí LEAD FINAL APPROVAL**

Each phase has:
- Assigned agent (LEAD/PLAN/EXEC)
- Percentage allocation
- Required sub-agents
- Exit criteria
- Mandatory handoff

See detailed phase sections below.

## Execution Philosophy

## üß† EXECUTION PHILOSOPHY (Read First!)

These principles override default behavior and must be internalized before starting work:

### Quality-First (PARAMOUNT)
**Get it right, not fast.** Correctness and completeness are MORE IMPORTANT than speed.
- Take the time needed to understand requirements fully
- Verify BEFORE implementing, test BEFORE claiming completion
- 2-4 hours of careful implementation beats 6-12 hours of rework
- If rushing leads to mistakes, you haven't saved time - you've wasted it
- "Done right" > "Done fast" - ALWAYS

### Testing-First (MANDATORY)
**Build confidence through comprehensive testing.**
- E2E testing is MANDATORY, not optional
- 30-60 minute investment saves 4-6 hours of rework
- 100% user story coverage required
- Both unit tests AND E2E tests must pass
- Tests are not overhead - they ARE the work

### Database-First (REQUIRED)
**Zero markdown files.** Database tables are single source of truth.
- SDs ‚Üí `strategic_directives_v2`
- PRDs ‚Üí `product_requirements_v2`
- Handoffs ‚Üí `sd_phase_handoffs`
- Retrospectives ‚Üí `retrospectives`
- Sub-agent results ‚Üí `sub_agent_execution_results`

### Validation-First (GATEKEEPING)
**Thorough validation BEFORE approval, full commitment AFTER.**
- LEAD validates: Real problem? Feasible solution? Resources available?
- After LEAD approval: SCOPE LOCK - deliver what was approved
- Exception: Critical blocker + human approval + new SD for deferred work

### Context-Aware (PROACTIVE)
**Monitor token usage proactively throughout execution.**
- Report context health in EVERY handoff
- HEALTHY (<70%), WARNING (70-90%), CRITICAL (90-95%), EMERGENCY (>95%)
- Use `/context-compact` when approaching WARNING threshold

### Application-Aware (VERIFICATION)
**Verify directory BEFORE writing ANY code.**
- `cd /mnt/c/_EHG/ehg && pwd` for customer features
- `git remote -v` to confirm correct repository
- Wrong directory = STOP immediately

### Evidence-Based (PROOF REQUIRED)
**Screenshot, test, verify. Claims without evidence are rejected.**
- Screenshot BEFORE and AFTER changes
- Test results with pass/fail counts
- CI/CD pipeline status (green checks required)
- Sub-agent verification results in database

**REMEMBER**: The goal is NOT to complete SDs quickly. The goal is to complete SDs CORRECTLY. A properly implemented SD that takes 8 hours is infinitely better than a rushed implementation that takes 4 hours but requires 6 hours of fixes.


## 5-Phase Strategic Directive Workflow

## üéØ 5-PHASE STRATEGIC DIRECTIVE WORKFLOW

Total: 100% = LEAD (35%) + PLAN (35%) + EXEC (30%)

---

### PHASE 1: LEAD PRE-APPROVAL (20% of LEAD allocation)

**Agent**: Strategic Leadership Agent (LEAD)
**Purpose**: Strategic validation, business alignment, feasibility assessment
**Duration**: 1-2 hours

**Mandatory Sub-Agents**:
- Principal Systems Analyst (duplicate check, existing implementation)
- Principal Database Architect (if database keywords in scope)
- Chief Security Architect (if security keywords in scope)
- Senior Design Sub-Agent (if UI/UX keywords in scope)

**Execution**: Run in parallel to save time
```bash
# Parallel execution
node scripts/systems-analyst-codebase-audit.js <SD-ID> &
node scripts/database-architect-schema-review.js <SD-ID> &
node scripts/security-architect-assessment.js <SD-ID> &
node scripts/design-subagent-evaluation.js <SD-ID> &
wait
```

**Deliverables**:
- SD approved or rejected with feedback
- Strategic Validation gate passed
- Over-engineering rubric applied (if needed)
- LEAD‚ÜíPLAN handoff created

**Exit Criteria**:
- SD status = 'active'
- Strategic Validation gate passed (6 questions answered)
- No critical blockers identified
- Handoff stored in `sd_phase_handoffs`

---

### PHASE 2: PLAN PRD CREATION (20% of PLAN allocation)

**Agent**: Technical Planning Agent (PLAN)
**Purpose**: Technical design, PRD creation, test planning
**Duration**: 2-4 hours

**Mandatory Sub-Agents**:
- Principal Database Architect (MANDATORY for ALL SDs - database validation)
- Product Requirements Expert (auto-generates user stories)

**Execution**: Sequential (each informs next)
```bash
# Step 1: Database validation
node scripts/database-architect-schema-review.js <SD-ID>

# Step 2: User story generation (automatic)
# Triggered by PRD creation, stores in user_stories table

# Step 3: Component sizing (if UI/UX SD)
node scripts/design-subagent-evaluation.js <SD-ID>
```

**Deliverables**:
- PRD created in `product_requirements_v2` table
- User stories in `user_stories` table (100% mapped to E2E tests)
- Component architecture defined (300-600 LOC per component)
- Database migrations planned (if needed)
- PLAN‚ÜíEXEC handoff created

**Exit Criteria**:
- PRD exists with comprehensive test plan
- User stories generated and validated
- Database dependencies resolved or escalated
- Handoff stored in `sd_phase_handoffs`

---

### PHASE 3: EXEC IMPLEMENTATION (30% of EXEC allocation)

**Agent**: Implementation Agent (EXEC)
**Purpose**: Code implementation, testing, delivery
**Duration**: 4-8 hours

**Mandatory Sub-Agents**:
- None (EXEC does the work directly)

**Pre-Implementation Checklist**:
```markdown
## EXEC Pre-Implementation Checklist
- [ ] Application: [EHG or EHG_Engineer - VERIFIED via pwd]
- [ ] GitHub remote: [verified via git remote -v]
- [ ] URL: [exact URL from PRD - accessible: YES/NO]
- [ ] Component: [path/to/component]
- [ ] Screenshot: [BEFORE state captured]
```

**Post-Implementation Requirements**:
1. **Server Restart** (MANDATORY for UI changes)
   ```bash
   pkill -f "node server.js"
   npm run build:client  # If UI changes
   PORT=3000 node server.js
   # Hard refresh: Ctrl+Shift+R
   ```

2. **Git Commit** (Conventional Commits with SD-ID)
   ```bash
   git commit -m "feat(<SD-ID>): Brief description

   Detailed explanation.

   ü§ñ Generated with [Claude Code](https://claude.com/claude-code)

   Co-Authored-By: Claude <noreply@anthropic.com>"
   ```

3. **Dual Test Execution** (MANDATORY - BOTH types)
   ```bash
   npm run test:unit      # Business logic
   npm run test:e2e       # User flows
   ```

4. **Wait for CI/CD** (2-3 minutes)
   ```bash
   gh run list --limit 5  # All green ‚úÖ
   ```

**Deliverables**:
- Implementation complete
- Unit tests pass
- E2E tests pass (100% user story coverage)
- CI/CD pipelines green
- Documentation generated
- EXEC‚ÜíPLAN handoff created

**Exit Criteria**:
- All PRD requirements implemented
- Both test types passing
- CI/CD green
- Documentation exists in `generated_docs`
- Handoff stored in `sd_phase_handoffs`

---

### PHASE 4: PLAN SUPERVISOR VERIFICATION (15% of PLAN allocation)

**Agent**: Technical Planning Agent (PLAN) in supervisor mode
**Purpose**: Verification, quality assurance, sub-agent orchestration
**Duration**: 1-2 hours

**Mandatory Sub-Agents**:
- QA Engineering Director (CRITICAL - E2E testing)
- DevOps Platform Architect (CRITICAL - CI/CD verification)
- Principal Database Architect (if database changes)
- Chief Security Architect (if security features)
- Performance Engineering Lead (if performance-critical)
- Senior Design Sub-Agent (if UI components)

**Automated Orchestration**:
```bash
# Orchestrator runs automatically when creating EXEC‚ÜíPLAN handoff
# All required sub-agents execute in parallel
# Results stored in sub_agent_execution_results table
# Handoff BLOCKED if CRITICAL sub-agents fail
```

**Manual Verification** (if needed):
```bash
# QA Director
node scripts/qa-engineering-director-enhanced.js <SD-ID> --full-e2e

# GitHub Actions
gh run list --limit 5
gh run view [run-id]

# Database verification
node scripts/database-architect-schema-review.js <SD-ID>
```

**Deliverables**:
- All sub-agents executed
- E2E tests passed (100% user stories)
- CI/CD pipelines verified green
- Integration verification complete
- PLAN‚ÜíLEAD handoff created

**Exit Criteria**:
- Verdict: PASS or CONDITIONAL_PASS (‚â•85% confidence)
- All CRITICAL sub-agents passed
- E2E test evidence documented
- Handoff stored in `sd_phase_handoffs`

---

### PHASE 5: LEAD FINAL APPROVAL (15% of LEAD allocation)

**Agent**: Strategic Leadership Agent (LEAD)
**Purpose**: Final approval, retrospective, completion
**Duration**: 30-60 minutes

**Mandatory Sub-Agents**:
- Continuous Improvement Coach (RETRO - retrospective generation)

**Automated Orchestration**:
```bash
# Orchestrator runs automatically when creating PLAN‚ÜíLEAD handoff
# RETRO sub-agent executes if not already run
# Handoff BLOCKED if retrospective missing
```

**Approval Checklist**:
- [ ] PLAN‚ÜíLEAD handoff reviewed
- [ ] Verification verdict acceptable (PASS or CONDITIONAL_PASS)
- [ ] All PRD requirements met (SCOPE LOCK validation)
- [ ] CI/CD pipelines green
- [ ] E2E test evidence sufficient (100% user stories)
- [ ] Retrospective generated
- [ ] Sub-agent validation script passed
- [ ] Human approval (if required)

**Deliverables**:
- SD marked as 'completed'
- Progress = 100%
- Retrospective in `retrospectives` table
- All handoffs complete
- Dashboard updated

**Exit Criteria**:
- SD status = 'completed'
- progress_percentage = 100
- completed_at timestamp set
- Retrospective exists with quality_score ‚â• 70


## Context Management Throughout Execution

## üß† CONTEXT MANAGEMENT (Throughout Execution)

**Token Budget**: 200,000 tokens

### Status Thresholds

| Status | Range | Percentage | Action |
|--------|-------|------------|--------|
| üü¢ HEALTHY | 0-140K | 0-70% | Continue normally |
| üü° WARNING | 140K-180K | 70-90% | Consider `/context-compact` |
| üî¥ CRITICAL | 180K-190K | 90-95% | MUST compact before handoff |
| üö® EMERGENCY | >190K | >95% | BLOCKED - force handoff |

### Report in EVERY Handoff

**Mandatory section in all handoffs**:
```markdown
## Context Health
**Current Usage**: X tokens (Y% of 200K budget)
**Status**: HEALTHY/WARNING/CRITICAL
**Recommendation**: [action if needed]
**Compaction Needed**: YES/NO
```

### Efficiency Rules

**Always apply these practices**:

1. **Select specific columns** (not `SELECT *`)
   ```javascript
   // ‚ùå Bad
   .select('*')

   // ‚úÖ Good
   .select('id, title, status, priority')
   ```

2. **Limit results** for large datasets
   ```javascript
   .limit(5)  // For summaries
   .limit(50) // For dashboards
   ```

3. **Summarize, don't dump**
   ```javascript
   // ‚ùå Bad: Full JSON dump
   console.log(results);

   // ‚úÖ Good: Summary
   console.log(`Found ${results.length} tests: ${passed} passed, ${failed} failed`);
   ```

4. **Use Read tool with offset/limit** for large files
   ```javascript
   Read('file.js', { offset: 100, limit: 50 })
   ```

5. **Compress sub-agent reports** (3-tier system)
   - TIER 1 (CRITICAL): Full detail for blockers
   - TIER 2 (IMPORTANT): Structured summary for warnings
   - TIER 3 (INFORMATIONAL): One-line for passing checks

### Expected Impact

Applying these rules: **90-98% token reduction per query**

### Compaction Command

When WARNING or CRITICAL:
```bash
/context-compact [focus area]
```

Example:
```bash
/context-compact database-schema
```

## Deferred Work Management


## Deferred Work Management

**Purpose**: Prevent losing track of work when reducing SD scope

**Root Cause** (SD-VENTURE-BACKEND-002 Lesson):
When SD-VENTURE-IDEATION-MVP-001's backend scope was deferred, no child SD was created immediately. Work was completed 6 months later but without tracking, requiring extensive backfill to restore LEO Protocol compliance.

**The Problem**:
- LEAD approves SD with 100 story points
- During PLAN, team realizes 40 points should be deferred
- PRD created with 60 points, work proceeds
- Deferred 40 points forgotten ‚Üí completed later without tracking ‚Üí backfill nightmare

---

### MANDATORY PROCESS: Create Child SD Immediately

**WHEN**: During PLAN phase, if any work is removed/deferred from approved scope

**REQUIRED ACTION**:
1. **Create child SD BEFORE finalizing PRD**
2. **Transfer user stories** to child SD
3. **Document relationship** in both SDs
4. **Set priority** based on criticality
5. **Link PRDs** (parent PRD references child SD)

---

### Example Workflow

**Scenario**: SD-VENTURE-MVP-001 approved for 10 user stories (100 points)

**PLAN discovers**: Stories 6-10 (40 points) are backend-only, can be deferred

**CORRECT Process** ‚úÖ:

```bash
# 1. Create child SD immediately
INSERT INTO strategic_directives_v2 (
  id, title, description, priority, status,
  parent_directive_id, relationship_type
) VALUES (
  'SD-VENTURE-BACKEND-001',
  'Venture Backend Implementation',
  'Deferred backend work from SD-VENTURE-MVP-001',
  'high',           -- Set based on business need
  'approved',       -- Already approved via parent
  'SD-VENTURE-MVP-001',
  'deferred_scope'
);

# 2. Transfer user stories to child SD
UPDATE user_stories
SET sd_id = 'SD-VENTURE-BACKEND-001'
WHERE sd_id = 'SD-VENTURE-MVP-001'
AND id IN ('US-006', 'US-007', 'US-008', 'US-009', 'US-010');

# 3. Update parent PRD to document deferral
UPDATE product_requirements_v2
SET metadata = metadata || jsonb_build_object(
  'scope_reductions', jsonb_build_array(
    jsonb_build_object(
      'deferred_to', 'SD-VENTURE-BACKEND-001',
      'user_stories', ARRAY['US-006', 'US-007', 'US-008', 'US-009', 'US-010'],
      'story_points', 40,
      'reason', 'Backend implementation deferred to separate sprint',
      'deferred_at', NOW()
    )
  )
)
WHERE id = 'PRD-VENTURE-MVP-001';

# 4. Create child PRD immediately (or mark as TODO)
-- Option A: Create minimal PRD now
INSERT INTO product_requirements_v2 (
  id, sd_uuid, title, status, progress,
  deferred_from
) VALUES (
  'PRD-VENTURE-BACKEND-001',
  (SELECT uuid_id FROM strategic_directives_v2 WHERE id = 'SD-VENTURE-BACKEND-001'),
  'Venture Backend Implementation',
  'planning',  -- Will be worked on later
  0,
  'PRD-VENTURE-MVP-001'
);

-- Option B: Add TODO to parent SD notes
-- "TODO: Create PRD-VENTURE-BACKEND-001 when ready to start backend work"
```

---

### Backfill Process (If Child SD Was Not Created)

**Scenario**: Work completed without tracking (like SD-VENTURE-BACKEND-002)

**Required Steps**:

1. **Create SD record**
   - Use historical commit data for dates
   - Set status: 'completed'

2. **Create PRD**
   - Set status: 'implemented' (not 'planning')
   - Set progress: 100

3. **Create user stories**
   - Extract from git commits
   - Set verification_status: 'passing' or 'validated'
   - Put in BOTH user_stories AND sd_backlog_map tables

4. **Create deliverables**
   - Extract from git history
   - Map to valid deliverable_types: api, test, documentation, migration
   - Mark all as completion_status: 'completed'

5. **Create handoffs**
   - EXEC‚ÜíPLAN: Implementation summary
   - PLAN‚ÜíLEAD: Verification summary
   - Use manual creation (validation gates not suitable for backfill)

6. **Create retrospective**
   - Document lessons learned
   - Note: "Tracking backfilled retroactively"

7. **Mark SD complete**
   - Fix any blocking issues first
   - Ensure all progress gates pass

**Backfill Scripts Created**: See /scripts/create-*-venture-backend-002-*.mjs

---

### Checklist: Scope Reduction Decision Point

Use this during PLAN phase when considering scope changes:

- [ ] **Identify deferred work**: Which user stories/deliverables are being removed?
- [ ] **Assess criticality**: Is this work needed eventually? (If yes ‚Üí child SD required)
- [ ] **Create child SD**: Don't defer this step! Create the SD now.
- [ ] **Transfer user stories**: Move them to child SD immediately
- [ ] **Set priority**: high/medium/low based on business need
- [ ] **Document relationship**: Update parent PRD metadata
- [ ] **Create child PRD** (minimal) OR add TODO to parent notes
- [ ] **Notify LEAD**: "Scope reduced, child SD created: SD-XXX"

---

### Red Flags (Lessons from SD-VENTURE-BACKEND-002)

‚ùå **"We'll create the SD later when we work on it"**
   - Result: Work gets forgotten or done without tracking

‚ùå **"Let's just note it in the parent PRD description"**
   - Result: No tracking, no progress visibility, no reminders

‚ùå **"It's only 3 user stories, not worth a separate SD"**
   - Result: Those 3 stories = 25 deliverables, 4 commits, 2 handoffs to backfill

‚úÖ **"Scope changed, creating child SD now"**
   - Result: Work tracked from day 1, no backfill needed

---

### Documentation Updates

This section added to LEO Protocol based on:
- **Incident**: SD-VENTURE-BACKEND-002 backfill (Oct 19, 2025)
- **Root Cause**: Child SD not created when backend scope deferred
- **Solution**: Mandatory child SD creation at scope reduction point
- **Prevention**: PLAN checklist enforcement, LEAD verification

**Related Sections**:
- Phase 2 (PLAN Pre-EXEC Checklist): Added scope reduction check
- Phase 4 (LEAD Verification): Verify child SDs created for deferrals
- Retrospective Templates: Include "Deferred work management" assessment

---

### Integration with Existing Workflow

**PLAN Agent** must now:
1. Check for scope reductions during PRD creation
2. Create child SDs for any deferred work
3. Document relationship in metadata
4. Report to LEAD in PLAN‚ÜíLEAD handoff

**LEAD Agent** must verify:
- Any scope reduction has corresponding child SD
- Child SD has appropriate priority
- Parent-child relationship documented
- User stories transferred correctly

**Progress Tracking**:
- Parent SD progress: Based on reduced scope (60 points)
- Child SD progress: Tracked independently (40 points)
- Portfolio view: Shows both SDs with relationship

---

### FAQ

**Q: What if we're not sure the deferred work will ever be done?**
A: Create the child SD with priority: 'low'. Better to have it and not need it than lose track of potential work.

**Q: Can we combine multiple deferrals into one child SD?**
A: Yes, if they're related. Example: "SD-VENTURE-FUTURE-ENHANCEMENTS" for all nice-to-have features.

**Q: What if the deferred work changes significantly later?**
A: Update the child SD's PRD when you start working on it. The SD serves as a placeholder until then.

**Q: Do we need a full PRD for the child SD immediately?**
A: Minimal PRD is acceptable. At minimum: title, description, deferred_from reference. Full PRD created when work begins.

**Q: What section_type for database?**
A: Use 'PHASE_2_PLANNING' (belongs in PLAN phase guidance)



## Database Operations - One Table at a Time

### REQUIRED: Database Operations Only

**‚ö†Ô∏è CRITICAL: One Table at a Time**
- When manipulating Supabase tables, **ALWAYS operate on ONE table at a time**
- Batch operations across multiple tables often fail or cause inconsistencies
- Complete each table operation fully before moving to the next table
- Verify success after each table operation before proceeding

**Strategic Directives**:
- ‚úÖ Create in `strategic_directives_v2` table
- ‚úÖ Use `scripts/create-strategic-directive.js` or dashboard
- ‚úÖ ALL SD data must be in database, not files
- ‚úÖ **One SD insertion at a time** - verify before next

**PRDs (Product Requirements)**:
- ‚úÖ Create in `product_requirements_v2` table
- ‚úÖ Use `scripts/add-prd-to-database.js`
- ‚úÖ Link to SD via `strategic_directive_id` foreign key
- ‚úÖ **One PRD insertion at a time** - verify before next

**Retrospectives**:
- ‚úÖ Create in `retrospectives` table
- ‚úÖ Use `scripts/generate-comprehensive-retrospective.js`
- ‚úÖ Trigger: Continuous Improvement Coach sub-agent
- ‚úÖ Link to SD via `sd_id` foreign key
- ‚úÖ **One retrospective at a time** - verify before next

**Handoffs**:
- ‚úÖ Store in handoff tracking tables
- ‚úÖ 7-element structure required
- ‚úÖ Link to SD and phase
- ‚úÖ **One handoff at a time** - verify before next

**Progress & Verification**:
- ‚úÖ Update database fields directly
- ‚úÖ Store verification results in database
- ‚úÖ Track in real-time via dashboard
- ‚úÖ **One record update at a time** - verify before next

## ‚ö†Ô∏è Mandatory Process Scripts

**CRITICAL**: Bypassing these scripts will cause handoff failures and data quality issues.

### Required Scripts by Phase

**PLAN Phase - PRD Creation**:
```bash
# ALWAYS use this script to create PRDs
node scripts/add-prd-to-database.js <SD-ID> [PRD-Title]

# Example:
node scripts/add-prd-to-database.js SD-EXPORT-001 "Export Feature PRD"
```

**Why mandatory:**
- Auto-triggers Product Requirements Expert (STORIES sub-agent)
- Generates user stories WITH implementation context
- Validates PRD schema and completeness
- Creates proper audit trail

**If you bypass:** PLAN‚ÜíEXEC handoff will fail due to missing implementation context.

---

**All Phases - Handoff Creation**:
```bash
# ALWAYS use unified handoff system
node scripts/unified-handoff-system.js execute <TYPE> <SD-ID>

# Types: LEAD-to-PLAN, PLAN-to-EXEC, EXEC-to-PLAN, PLAN-to-LEAD
```

**Why mandatory:**
- Runs validation gates (BMAD, Git branch enforcement)
- Triggers required sub-agents automatically
- Ensures 7-element handoff structure
- Enforces quality standards

**If you bypass:** Phase transitions will be blocked by database constraints.

---

### ‚ùå NEVER Do This

```javascript
// ‚ùå WRONG: Direct database insert
const { data, error } = await supabase
  .from('product_requirements_v2')
  .insert({ title: 'My PRD', ... });

// ‚ùå WRONG: Manual user story creation
const { data, error } = await supabase
  .from('user_stories')
  .insert({ title: 'My Story', ... });
```

**Why this fails:**
- Bypasses STORIES sub-agent (no implementation context)
- Bypasses validation gates
- Missing required structured data
- Breaks audit trail
- **Database constraints will block invalid inserts**

---

### ‚úÖ Always Do This

```bash
# ‚úÖ CORRECT: Use process scripts
node scripts/add-prd-to-database.js SD-XXX "PRD Title"
# ‚Üí Auto-triggers STORIES sub-agent
# ‚Üí Generates user stories with context
# ‚Üí Validates all required fields

node scripts/unified-handoff-system.js execute PLAN-to-EXEC SD-XXX
# ‚Üí Runs BMAD validation
# ‚Üí Enforces git branch
# ‚Üí Triggers required sub-agents
```

---

### Database Enforcement

The following constraints enforce process compliance:

- `product_requirements_v2.functional_requirements` must have ‚â•3 items
- `product_requirements_v2.test_scenarios` must have ‚â•1 item  
- `product_requirements_v2.acceptance_criteria` must have ‚â•1 item
- `user_stories.implementation_context` must be populated (not NULL, not empty)

**Attempting to bypass scripts will result in database constraint violations.**

## Stubbed/Mocked Code Detection


**CRITICAL: Stubbed/Mocked Code Detection** (MANDATORY):

Before PLAN‚ÜíLEAD handoff, MUST verify NO stubbed/mocked code in production files:

**Check For** (BLOCKING if found):
```bash
# 1. TEST_MODE flags in production code
grep -r "TEST_MODE.*true\|NODE_ENV.*test" lib/ src/ --exclude-dir=test

# 2. Mock/stub patterns
grep -r "MOCK:\|STUB:\|TODO:\|PLACEHOLDER:\|DUMMY:" lib/ src/ --exclude-dir=test

# 3. Commented-out implementations
grep -r "// REAL IMPLEMENTATION\|// TODO: Implement" lib/ src/ --exclude-dir=test

# 4. Mock return values without logic
grep -r "return.*mock.*result\|return.*dummy" lib/ src/ --exclude-dir=test
```

**Acceptable Patterns** ‚úÖ:
- `TEST_MODE` in test files (`tests/`, `*.test.js`, `*.spec.js`)
- TODO comments with SD references for future work: `// TODO (SD-XXX): Implement caching`
- Feature flags with proper configuration: `if (config.enableFeature)`

**BLOCKING Patterns** ‚ùå:
- `const TEST_MODE = process.env.TEST_MODE === 'true'` in production code
- `return { verdict: 'PASS' }` without actual logic
- `console.log('MOCK: Using dummy data')`
- Empty function bodies: `function execute() { /* TODO */ }`
- Commented-out real implementations

**Verification Script**:
```bash
# Create verification script
node scripts/detect-stubbed-code.js <SD-ID>
```

**Manual Code Review**:
- Read all modified files from git diff
- Verify implementations are complete
- Check for placeholder comments
- Validate TEST_MODE usage is test-only

**Exit Requirement**: Zero stubbed code in production files, OR documented in "Known Issues" with follow-up SD created.


## üìö Automated PRD Enrichment (MANDATORY)

**SD-LEO-LEARN-001: Proactive Learning Integration**

**CRITICAL**: Run BEFORE writing PRD to incorporate historical lessons.

## Step 0: Knowledge Preflight Check

**Run this command before creating PRD**:

```bash
node scripts/phase-preflight.js --phase PLAN --sd-id <SD_UUID>
node scripts/enrich-prd-with-research.js <SD_UUID>  # If available
```

## What This Does

Automatically:
1. Queries retrospectives for similar SDs
2. Extracts proven technical approaches
3. Identifies common pitfalls ‚Üí adds to "Risks & Mitigations"
4. Suggests prevention measures ‚Üí adds to acceptance criteria
5. Updates user_stories.implementation_context

## How to Use Results

### In PRD "Technical Approach" Section
- Include proven solutions from high-success patterns
- Reference historical approaches that worked well
- Example: "Based on PAT-001 (100% success), we'll verify schema types before..."

### In PRD "Risks & Mitigations" Section
- Document known pitfalls from retrospectives
- Add prevention measures from historical failures
- Example: "Risk: Test path errors after refactor (PAT-002). Mitigation: Verify all imports."

### In PRD "Acceptance Criteria"
- Include prevention checklist items
- Add validation steps from proven patterns
- Example: "[ ] Schema types verified against database (prevents PAT-001)"

## Verification

Verify enrichment appears in PRD's "Reference Materials" section:

```markdown
## Reference Materials

### Historical Patterns Consulted
- PAT-001: Schema mismatch TypeScript/Supabase (Success: 100%)
- SD-SIMILAR-001 Retrospective: Database validation prevented 3 rework cycles

### Prevention Measures Applied
- Schema verification before implementation
- Test path validation in acceptance criteria
```

## Why This Matters

- **Better PRDs**: Incorporate lessons before design, not after errors
- **Prevents design flaws**: Known pitfalls addressed in planning
- **Faster implementation**: EXEC has clear prevention guidance
- **Higher quality**: Proven approaches baked into requirements

## Quick Reference

```bash
# Before creating PRD (MANDATORY)
node scripts/phase-preflight.js --phase PLAN --sd-id <SD_UUID>

# Enrich PRD with research (if script exists)
node scripts/enrich-prd-with-research.js <SD_UUID>

# View category-specific lessons
cat docs/summaries/lessons/<category>-lessons.md
```

**Time Investment**: 1-2 minutes
**Time Saved**: 30-90 minutes of EXEC rework

## Multi-Application Testing Architecture

**Multi-App Testing**: Two independent test suites (EHG_Engineer + EHG app).

**CRITICAL**: Determine target app from SD context before running tests
- **EHG_Engineer**: Vitest + Jest (50% coverage)
- **EHG**: Vitest (unit) + Playwright (E2E)

**Full Guide**: See `docs/reference/multi-app-testing.md`

## 6-Step SD Evaluation Checklist

**6-Step SD Evaluation Checklist (MANDATORY for LEAD & PLAN)**:

1. Query `strategic_directives_v2` for SD metadata
2. Query `product_requirements_v2` for existing PRD
3. **Query `sd_backlog_map` for linked backlog items** ‚Üê CRITICAL
4. Search codebase for existing infrastructure
5. Identify gaps between backlog requirements and existing code
6. **Execute QA smoke tests** ‚Üê NEW (verify tests run before approval)

**Backlog Review Requirements**: Review backlog_title, item_description, extras.Description_1 for each item

**Complete Checklist**: See `docs/reference/sd-evaluation-checklist.md`

## Quick Reference

## üìã QUICK REFERENCE

### Component Sizing

| Lines of Code | Action | Rationale |
|---------------|--------|-----------|
| <200 | Consider combining | Too granular |
| **300-600** | ‚úÖ **OPTIMAL** | Sweet spot for testing & maintenance |
| >800 | **MUST split** | Too complex, hard to test |

### Git Commits (Conventional Commits)

**Format**: `<type>(<SD-ID>): <subject>`

```bash
git commit -m "feat(SD-XXX): Brief description

Detailed explanation of changes.

ü§ñ Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>"
```

**Types**: feat, fix, docs, refactor, test, chore, perf

### Server Restart (After ANY Changes)

```bash
# Kill
pkill -f "node server.js"

# Build (if UI changes)
npm run build:client

# Restart
PORT=3000 node server.js

# Hard refresh browser
# Ctrl+Shift+R (Windows) / Cmd+Shift+R (Mac)
```

### Parallel Execution (Save Time)

**When Safe**:
- ‚úÖ Multiple independent file reads
- ‚úÖ Multiple database queries (read-only)
- ‚úÖ Sub-agent execution (different domains)

**NOT Safe**:
- ‚ùå Write operations
- ‚ùå Database mutations
- ‚ùå Sequential dependencies

**Example**:
```bash
# LEAD Pre-Approval: 4 sub-agents in parallel
node scripts/systems-analyst-codebase-audit.js <SD-ID> &
node scripts/database-architect-schema-review.js <SD-ID> &
node scripts/security-architect-assessment.js <SD-ID> &
node scripts/design-subagent-evaluation.js <SD-ID> &
wait

# Reduces time from 2 minutes sequential to 30 seconds parallel
```

### Context Efficiency Patterns

```javascript
// ‚ùå Inefficient
const { data } = await supabase.from('table').select('*');
console.log(data); // Dumps full JSON

// ‚úÖ Efficient
const { data } = await supabase
  .from('table')
  .select('id, title, status')
  .limit(5);
console.log(`Found ${data.length} items`);
```

### Database Operations (One at a Time)

**CRITICAL**: When manipulating Supabase tables, operate on ONE table at a time.

```javascript
// ‚ùå Bad: Batch across tables
await Promise.all([
  supabase.from('table1').insert(data1),
  supabase.from('table2').insert(data2)
]);

// ‚úÖ Good: Sequential, one table at a time
await supabase.from('table1').insert(data1);
// Verify success
await supabase.from('table2').insert(data2);
// Verify success
```

### Sub-Agent Orchestration

**Automated** (preferred):
```bash
# Orchestrator runs all required sub-agents for phase
node scripts/orchestrate-phase-subagents.js <PHASE> <SD-ID>

# Phases: LEAD_PRE_APPROVAL, PLAN_PRD, EXEC_IMPL, PLAN_VERIFY, LEAD_FINAL
```

**Manual** (if needed):
```bash
# QA Director
node scripts/qa-engineering-director-enhanced.js <SD-ID> --full-e2e

# GitHub Actions
node scripts/github-actions-verifier.js <SD-ID>

# Database Architect
node scripts/database-architect-schema-review.js <SD-ID>
```

### Testing Commands

```bash
# Unit tests (business logic)
npm run test:unit

# E2E tests (user flows)
npm run test:e2e

# Both (MANDATORY before EXEC‚ÜíPLAN handoff)
npm run test:unit && npm run test:e2e
```

### Handoff Creation

```bash
# Unified handoff system (with auto sub-agent orchestration)
node scripts/unified-handoff-system.js execute <TYPE> <SD-ID>

# Types:
# - LEAD-to-PLAN
# - PLAN-to-EXEC
# - EXEC-to-PLAN (auto-runs PLAN_VERIFY sub-agents)
# - PLAN-to-LEAD (auto-runs LEAD_FINAL sub-agents)
```

### Progress Verification

```bash
# Check progress breakdown
node -e "
const { createClient } = require('@supabase/supabase-js');
const supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_ANON_KEY);
(async () => {
  const { data } = await supabase.rpc('get_progress_breakdown', { sd_id_param: 'SD-XXX' });
  console.log(JSON.stringify(data, null, 2));
})();
"
```

## LEAD Over-Engineering Evaluation Process

### üõ°Ô∏è LEAD Over-Engineering Evaluation Process

**MANDATORY**: LEAD agents MUST use the standardized rubric before making any SD status/priority changes.

#### Step-by-Step Evaluation Process

1. **Execute Rubric Evaluation**:
   ```bash
   node scripts/lead-over-engineering-rubric.js --sd-id [SD_ID]
   ```

2. **Review 6-Dimension Scores** (1-5 scale each):
   - **Technical Complexity vs Business Value**: Complexity-to-value ratio
   - **Resource Intensity vs Urgency**: Development effort vs business urgency  
   - **Strategic Priority Alignment**: Alignment with Stage 1/EVA/GTM priorities
   - **Market Timing & Opportunity Window**: Market opportunity timing
   - **Implementation & Business Risk**: Risk vs reward assessment
   - **Return on Investment Projection**: Expected ROI evaluation

3. **Check Over-Engineering Thresholds**:
   - Total Score ‚â§15/30 = Over-engineered
   - Complexity ‚â§2 = Problematic
   - Strategic Alignment ‚â§2 = Concerning  
   - Risk Assessment ‚â§2 = Dangerous

4. **Present Findings to Human**:
   ```bash
   node scripts/lead-human-approval-system.js --sd-id [SD_ID] --evaluation [RESULTS]
   ```

5. **Request Explicit Approval**: Show scores, reasoning, and consequences

6. **Execute Only After Approval**: NEVER make autonomous changes

#### Available Scripts for LEAD Agents
- `scripts/lead-over-engineering-rubric.js` - Standardized 6-dimension evaluation
- `scripts/lead-human-approval-system.js` - Human approval workflow
- `scripts/enhanced-priority-rubric.js` - Priority rebalancing tools

#### Prohibited Actions
- ‚ùå Autonomous SD status/priority changes  
- ‚ùå Overriding user selections without permission
- ‚ùå Subjective over-engineering calls without rubric
- ‚ùå Making changes before human approval

## Enhanced QA Engineering Director v2.0 - Testing-First Edition

**Enhanced QA Engineering Director v2.0**: Mission-critical testing automation with comprehensive E2E validation.

**Core Capabilities:**
1. Professional test case generation from user stories
2. Pre-test build validation (saves 2-3 hours)
3. Database migration verification (prevents 1-2 hours debugging)
4. **Mandatory E2E testing via Playwright** (REQUIRED for approval)
5. Test infrastructure discovery and reuse

**5-Phase Workflow**: Pre-flight checks ‚Üí Test generation ‚Üí E2E execution ‚Üí Evidence collection ‚Üí Verdict & learnings

**Activation**: Auto-triggers on `EXEC_IMPLEMENTATION_COMPLETE`, coverage keywords, testing evidence requests

**Full Guide**: See `docs/reference/qa-director-guide.md`

## üîç Pre-Implementation Knowledge Retrieval (MANDATORY)

**SD-LEO-LEARN-001: Proactive Learning Integration**

**CRITICAL**: Run BEFORE starting implementation to retrieve relevant historical lessons.

## Step 0: Knowledge Preflight Check

**Run this command before writing any code**:

```bash
node scripts/phase-preflight.js --phase EXEC --sd-id <SD_UUID>
```

## What This Does

Queries historical knowledge base for:
- **Issue patterns** relevant to your SD category
- **Retrospectives** from similar past work
- **Proven solutions** with success rates >85%
- **Common pitfalls** to avoid (success rate <50%)
- **Prevention checklists** for proactive measures

## How to Use Results

1. **High Success Patterns (‚úÖ ‚â•85%)**:
   - Apply proven solutions preemptively
   - Add to implementation plan before encountering issues
   - Example: "PAT-004 shows server restart needed after changes ‚Üí add to workflow"

2. **Moderate Patterns (‚ö†Ô∏è 50-85%)**:
   - Be aware, prepare contingencies
   - Document why you chose alternative approach
   - Example: "PAT-002 test path errors ‚Üí verify imports carefully"

3. **Low Success Patterns (‚ùå <50%)**:
   - Known failure modes, avoid these approaches
   - Flag in handoff if you must use similar approach
   - Example: "PAT-007 sub-agent not triggering ‚Üí use manual invocation"

## Handoff Documentation (MANDATORY)

Add "Patterns Consulted" section to your handoff:

```markdown
## Patterns Consulted

- PAT-001: Schema mismatch TypeScript/Supabase (Success: 100%, Applied: Yes)
- PAT-004: Server restart needed for changes (Success: 100%, Applied: Yes)
- PAT-002: Test path errors after refactor (Success: 100%, Not encountered)
```

## Why This Matters

- **Prevents repeated mistakes**: 60%+ of issues have been seen before
- **Saves time**: Apply proven solutions immediately (avg 15-20 min saved)
- **Builds institutional memory**: Every SD benefits from prior learnings
- **Reduces rework**: Proactive prevention vs reactive debugging

## Quick Reference

```bash
# Before starting implementation (MANDATORY)
node scripts/phase-preflight.js --phase EXEC --sd-id <SD_UUID>

# View detailed pattern info
node scripts/search-prior-issues.js "<issue description>"

# View knowledge summaries (updated weekly)
ls docs/summaries/lessons/*.md
```

**Time Investment**: 30 seconds to run, 2-3 minutes to review
**Time Saved**: 15-60 minutes of debugging/rework

## Quality Validation Examples

**Evidence from Retrospectives**: Thorough validation saves 4-6 hours per SD by catching issues early.

### LEAD Pre-Approval Validation Examples

#### Example 1: Verify Claims Against Reality

**Case** (SD-UAT-002): Code review revealed 3/5 claimed issues didn't exist ‚Üí saved 3-4 hours of unnecessary work

**Lesson**: Always verify claims with actual code inspection, don't trust assumptions

#### Example 2: Leverage Existing Infrastructure

**Case** (SD-UAT-020): Used existing Supabase Auth instead of custom solution ‚Üí saved 8-10 hours

**Lesson**: Check what already exists before approving new development

#### Example 3: Document Blockers Instead of Building Around Them

**Case** (SD-UAT-003): Database blocker identified early ‚Üí documented constraint instead of workaround ‚Üí saved 4-6 hours

**Lesson**: Identify true blockers during approval phase, not during implementation

#### Example 4: Question Necessity vs. Nicety

**Lesson**: Distinguish between "must have" (core requirements) and "nice to have" (future enhancements) during validation

### Quality Gate Benefits

Thorough LEAD pre-approval validation:
- Catches false assumptions early
- Identifies existing solutions
- Documents blockers before implementation starts
- Ensures resource allocation matches real requirements

**Total Time Saved from Examples**: 15-20 hours across validated SDs


## Database Schema Documentation

### Database Schema Documentation

Auto-generated schema docs provide quick reference without database queries:

**Paths**:
- EHG_Engineer: `docs/reference/schema/engineer/database-schema-overview.md`
- EHG App: `docs/reference/schema/ehg/database-schema-overview.md`

**Update**: `npm run schema:docs:engineer` or `npm run schema:docs:ehg`

**PRD Integration**: PRDs stored in `product_requirements_v2` table (NOT markdown).
Use `add-prd-to-database.js` to create PRDs with schema review prompts.


## PLAN Pre-EXEC Checklist

## PLAN Agent Pre-EXEC Checklist (MANDATORY)

**Evidence from Retrospectives**: Database verification issues appeared in SD-UAT-003, SD-UAT-020, and SD-008. Early verification saves 2-3 hours per blocker.

Before creating PLAN‚ÜíEXEC handoff, PLAN agent MUST verify:

### Database Dependencies ‚úÖ
- [ ] **Identify all data dependencies** in PRD
- [ ] **Run schema verification script** for data-dependent SDs
- [ ] **Verify tables/columns exist** OR create migration
- [ ] **Document verification results** in PLAN‚ÜíEXEC handoff
- [ ] If tables missing: **Escalate to LEAD** with options

**Success Pattern** (SD-UAT-003):
> "Database Architect verification provided evidence for LEAD decision. Documented instead of implementing ‚Üí saved 4-6 hours"

### Architecture Planning ‚úÖ
- [ ] **Component sizing estimated** (target 300-600 lines per component)
- [ ] **Existing infrastructure identified** (don't rebuild what exists)
- [ ] **Third-party libraries considered** before custom code

**Success Pattern** (SD-UAT-020):
> "Leveraged existing Supabase Auth instead of building custom ‚Üí saved 8-10 hours"

### Testing Strategy ‚úÖ
- [ ] **Smoke tests defined** (3-5 tests minimum)
- [ ] **Test scenarios documented** in PRD

### Quality Validation ‚úÖ
- [ ] **Verified claims with code review** (if UI/UX SD)
- [ ] **Assessed technical feasibility**
- [ ] **Identified potential blockers**

**Success Pattern** (SD-UAT-002):
> "LEAD code review rejected 3/5 false claims ‚Üí saved hours of unnecessary work"


## Testing Tier Strategy

## Testing Requirements - Clear Thresholds

**Evidence from Retrospectives**: Testing confusion appeared in SD-UAT-002, SD-UAT-020, SD-008.

### Three-Tier Testing Strategy

#### Tier 1: Smoke Tests (MANDATORY) ‚úÖ
- **Requirement**: 3-5 tests, <60 seconds execution
- **Approval**: **SUFFICIENT for PLAN‚ÜíLEAD approval**

#### Tier 2: Comprehensive E2E (RECOMMENDED) üìã
- **Requirement**: 30-50 tests covering user flows
- **Approval**: Nice to have, **NOT blocking for LEAD approval**
- **Timing**: Can be refined post-deployment

#### Tier 3: Manual Testing (SITUATIONAL) üîç
- **UI changes**: Single smoke test recommended (+5 min)
- **Logic changes <5 lines**: Optional
- **Logic changes >10 lines**: Required

### Anti-Pattern to Avoid ‚ùå

**DO NOT** create 100+ manual test checklists unless specifically required.

**From SD-UAT-020**:
> "Created 100+ test checklist but didn't execute manually. Time spent on unused documentation."

## Component Sizing Guidelines

**Evidence from Retrospectives**: Proven pattern in SD-UAT-020 and SD-008.

### Optimal Component Size: 300-600 Lines

**Success Pattern** (SD-UAT-020):
> "Split settings into three focused components. Each ~500 lines. Easy to test and maintain."

### Sizing Rules

| Lines of Code | Action | Rationale |
|---------------|--------|-----------|
| **<200** | Consider combining | Too granular |
| **300-600** | ‚úÖ **OPTIMAL** | Sweet spot |
| **>800** | **MUST split** | Too complex |

## TODO Comment Standard

## TODO Comment Standard (When Deferring Work)

**Evidence from Retrospectives**: Proven pattern in SD-UAT-003 saved 4-6 hours.

### Standard TODO Format

```typescript
// TODO (SD-ID): Action required
// Requires: Dependencies, prerequisites
// Estimated effort: X-Y hours
// Current state: Mock/temporary/placeholder
```

**Success Pattern** (SD-UAT-003):
> "Comprehensive TODO comments provided clear future work path. Saved 4-6 hours."

## üî¨ BMAD Method Enhancements

**BMAD** (Build-Measure-Adapt-Document) Method principles integrated into LEO Protocol to reduce context consumption, improve implementation quality, and enable early error detection.

### Core Principles

1. **Dev Agents Must Be Lean**: Minimize context consumption throughout workflow
2. **Natural Language First**: Reduce code-heavy implementation guidance
3. **Context-Engineered Stories**: Front-load implementation details to reduce EXEC confusion
4. **Risk Assessment**: Multi-domain analysis during LEAD_PRE_APPROVAL
5. **Mid-Development Quality Gates**: Checkpoint pattern for large SDs
6. **Early Validation**: Catch issues at gates, not during final testing

---

### Six BMAD Enhancements

**1. Risk Assessment Sub-Agent (RISK)**
- **Phase**: LEAD_PRE_APPROVAL (mandatory for all SDs)
- **Purpose**: Multi-domain risk scoring before approval
- **Domains**: Technical Complexity (1-10), Security Risk (1-10), Performance Risk (1-10), Integration Risk (1-10), Data Migration Risk (1-10), UI/UX Risk (1-10)
- **Storage**: risk_assessments table
- **Script**: node lib/sub-agent-executor.js RISK SD-ID
- **Benefit**: Early risk identification prevents 4-6 hours rework per SD

**2. User Story Context Engineering (STORIES)**
- **Phase**: PLAN_PRD (after PRD creation, before EXEC)
- **Purpose**: Hyper-detailed implementation context for each user story
- **Fields Added**: implementation_context, architecture_references, example_code_patterns, testing_scenarios
- **Storage**: user_stories table columns
- **Script**: node lib/sub-agent-executor.js STORIES SD-ID
- **Benefit**: Reduces EXEC confusion by 30-40% through front-loaded guidance
- **Validation**: PLAN‚ÜíEXEC handoff checks for ‚â•80% coverage

**3. Retrospective Review for LEAD**
- **Phase**: LEAD_PRE_APPROVAL (before approving new SDs)
- **Purpose**: Learn from similar completed SDs
- **Analysis**: Success patterns, failure patterns, effort adjustments, risk mitigations
- **Storage**: Queries retrospectives table
- **Script**: node scripts/retrospective-review-for-lead.js SD-ID
- **Benefit**: Informed decision-making based on historical data

**4. Checkpoint Pattern Generator**
- **Phase**: PLAN_PRD (for SDs with >8 user stories)
- **Purpose**: Break large SDs into 3-4 manageable checkpoints
- **Benefits**: 30-40% context reduction, 50% faster debugging, early error detection
- **Storage**: strategic_directives_v2.checkpoint_plan (JSONB)
- **Script**: node scripts/generate-checkpoint-plan.js SD-ID
- **Validation**: PLAN‚ÜíEXEC handoff requires checkpoint plan for large SDs

**5. Test Architecture Phase Enhancement**
- **Phase**: PLAN_PRD and PLAN_VERIFY (QA Director integration)
- **Purpose**: Structured test planning with 4 strategies
- **Strategies**: Unit (business logic), E2E (user flows), Integration (APIs/DB), Performance (benchmarks)
- **Storage**: test_plans table
- **Script**: QA Director auto-generates during PLAN phase
- **Benefit**: 100% user story ‚Üí E2E test mapping enforced
- **Validation**: EXEC‚ÜíPLAN handoff checks test plan existence and coverage

**6. Lean EXEC_CONTEXT.md**
- **Phase**: EXEC_IMPLEMENTATION (context optimization)
- **Purpose**: Reduced CLAUDE.md for EXEC agents (~500 lines vs 5000+)
- **Content**: EXEC-specific guidance only (no LEAD/PLAN operations)
- **Location**: docs/EXEC_CONTEXT.md
- **Benefit**: 90% context reduction during EXEC phase

---

### Validation Gates Integration

**PLAN‚ÜíEXEC Handoff**:
- ‚úÖ User story context engineering (‚â•80% coverage)
- ‚úÖ Checkpoint plan (if SD has >8 stories)
- ‚úÖ Risk assessment exists

**EXEC‚ÜíPLAN Handoff**:
- ‚úÖ Test plan generated (unit + E2E strategies)
- ‚úÖ User story ‚Üí E2E mapping (100% requirement)
- ‚úÖ Test plan stored in database

**Validation Script**: scripts/modules/bmad-validation.js
**Integration**: Automatic via unified-handoff-system.js

---

### Quick Reference: BMAD Scripts

```bash
# 1. Risk Assessment (LEAD_PRE_APPROVAL)
node lib/sub-agent-executor.js RISK SD-ID

# 2. User Story Context Engineering (PLAN_PRD)
node lib/sub-agent-executor.js STORIES SD-ID

# 3. Retrospective Review (LEAD_PRE_APPROVAL)
node scripts/retrospective-review-for-lead.js SD-ID

# 4. Checkpoint Plan (PLAN_PRD, if >8 stories)
node scripts/generate-checkpoint-plan.js SD-ID

# 5. Test Architecture (PLAN_VERIFY, automatic)
node scripts/qa-engineering-director-enhanced.js SD-ID

# 6. Lean EXEC Context (reference during EXEC)
cat docs/EXEC_CONTEXT.md
```

---

### Expected Impact

**Context Consumption**:
- User story context engineering: 30-40% reduction in EXEC confusion
- Checkpoint pattern: 30-40% reduction in total context per large SD
- Lean EXEC_CONTEXT.md: 90% reduction during EXEC phase

**Time Savings**:
- Risk assessment: 4-6 hours saved per SD (early issue detection)
- Test architecture: 2-3 hours saved per SD (structured planning)
- Retrospective review: Informed decisions prevent 3-4 hours unnecessary work

**Quality Improvements**:
- Early validation gates catch issues before late-stage rework
- Structured test planning ensures 100% user story coverage
- Context engineering reduces implementation ambiguity

---

### Database Schema Additions

**New Tables**:
- risk_assessments: Risk scoring across 6 domains
- test_plans: Structured test strategies (4 types)

**Enhanced Tables**:
- user_stories: Added implementation_context, architecture_references, example_code_patterns, testing_scenarios
- strategic_directives_v2: Added checkpoint_plan (JSONB)

**Sub-Agents**:
- leo_sub_agents: Added RISK (code: 'RISK', priority: 8)
- leo_sub_agents: Added STORIES (code: 'STORIES', priority: 50)

---

### Further Reading

- **BMAD Principles**: See retrospectives from SD-UAT-002, SD-UAT-020, SD-EXPORT-001
- **Implementation Guide**: docs/bmad-implementation-guide.md
- **Validation Gates**: docs/reference/handoff-validation.md

*Last Updated: 2025-10-12*
*BMAD Method: Build-Measure-Adapt-Document*


## DESIGN‚ÜíDATABASE Validation Gates

The LEO Protocol enforces the DESIGN‚ÜíDATABASE workflow pattern through 4 mandatory validation gates that ensure:
1. Sub-agent execution completeness (PLAN‚ÜíEXEC)
2. Implementation fidelity to recommendations (EXEC‚ÜíPLAN)
3. End-to-end traceability (PLAN‚ÜíLEAD)
4. Workflow ROI and pattern effectiveness (LEAD Final)

**Passing Score**: ‚â•80 points (out of 100) required for each gate

---

### Gate 1: PLAN‚ÜíEXEC Handoff (Pre-Implementation)

**When**: After PRD creation, before EXEC starts implementation
**Purpose**: Verify planning is complete and recommendations exist
**Script**: `scripts/modules/design-database-gates-validation.js`
**Integration Point**: `unified-handoff-system.js` line ~271 (after BMAD validation)

**9 Validation Checks** (11 points each + 1 buffer = 100 points):

1. **DESIGN Sub-Agent Executed** (11 points)
   - Queries: `sub_agent_execution_results` table
   - Checks: `sub_agent_name = 'DESIGN'` AND `status = 'SUCCESS'`

2. **DATABASE Sub-Agent Executed** (11 points)
   - Queries: `sub_agent_execution_results` table
   - Checks: `sub_agent_name = 'DATABASE'` AND `status = 'SUCCESS'`

3. **DATABASE Informed by DESIGN** (11 points)
   - Queries: `product_requirements_v2.metadata.database_analysis.design_informed`
   - Checks: `design_informed = true`

4. **STORIES Sub-Agent Executed** (11 points)
   - Queries: `sub_agent_execution_results` table
   - Checks: `sub_agent_name = 'STORIES'` AND `status = 'SUCCESS'`

5. **Schema Documentation Consulted** (11 points)
   - Analyzes: `database_analysis.analysis` text
   - Checks: References to `docs/reference/schema/`

6. **PRD Metadata Complete** (11 points)
   - Checks: Both `design_analysis` AND `database_analysis` exist in PRD metadata

7. **Sub-Agent Execution Order** (11 points)
   - Validates: DESIGN timestamp < DATABASE timestamp < STORIES timestamp

8. **PRD Created Via Script** (11 points)
   - Detects: `add-prd-to-database.js` metadata signature

9. **User Stories Context Coverage** (12 points)
   - Calculates: % of stories with `implementation_context`
   - Threshold: ‚â•80% coverage required

**Conditional Execution**:
- Only validates SDs with BOTH `design` AND `database` categories
- OR scope contains both "UI" AND "database" keywords
- Use: `shouldValidateDesignDatabase(sd)` helper function

---

### Gate 2: EXEC‚ÜíPLAN Handoff (Post-Implementation)

**When**: After EXEC completes implementation, before PLAN verification
**Purpose**: Verify EXEC actually implemented DESIGN/DATABASE recommendations
**Script**: `scripts/modules/implementation-fidelity-validation.js`
**Integration Point**: `unified-handoff-system.js` line ~486 (after BMAD validation)

**4 Validation Sections** (25 points each = 100 points):

#### A. Design Implementation Fidelity (25 points)

- **A1: UI Components** (10 points)
  - Git analysis: `git log --all --grep="SD-XXX" --name-only`
  - Checks: Component files (.tsx, .jsx) committed

- **A2: Workflows** (10 points)
  - Queries: EXEC‚ÜíPLAN handoff deliverables
  - Checks: Workflow implementation mentioned

- **A3: User Actions** (5 points)
  - Git analysis: `git log --all --grep="SD-XXX" --patch`
  - Checks: CRUD operations in code changes

#### B. Database Implementation Fidelity (25 points)

- **B1: Migrations** (15 points)
  - Scans: `database/migrations`, `supabase/migrations`
  - Checks: Migration files exist for SD

- **B2: RLS Policies** (5 points)
  - Git analysis: Checks for CREATE POLICY statements

- **B3: Migration Complexity** (5 points)
  - Reads: Migration file line count
  - Compares: To DATABASE analysis estimate (optional)

#### C. Data Flow Alignment (25 points)

- **C1: Database Queries** (10 points)
  - Git analysis: Checks for .select(), .insert(), .update(), .from()

- **C2: Form/UI Integration** (10 points)
  - Git analysis: Checks for useState, useForm, onSubmit, <form>, Input, Button

- **C3: Data Validation** (5 points)
  - Git analysis: Checks for zod, validate, schema, .required()

#### D. Enhanced Testing (25 points)

- **D1: E2E Tests** (15 points)
  - Scans: `tests/e2e`, `tests/integration`, `playwright/tests`
  - Checks: Test files exist for SD

- **D2: Migration Tests** (5 points)
  - Git analysis: Checks for migration + test file mentions

- **D3: Coverage Documentation** (5 points)
  - Queries: EXEC‚ÜíPLAN handoff metadata
  - Checks: Test coverage documented

**Why This Gate Matters**:
This is the MOST CRITICAL gate - ensures recommendations weren't just generated but actually implemented. Without this, EXEC could ignore all recommendations.

---

### Gate 3: PLAN‚ÜíLEAD Handoff (Pre-Final Approval)

**When**: After PLAN verification, before LEAD final approval
**Purpose**: Verify end-to-end alignment from design through implementation
**Script**: `scripts/modules/traceability-validation.js`
**Integration Point**: `unified-handoff-system.js` line ~726 (PLAN‚ÜíLEAD validation)

**5 Validation Sections** (20 points each = 100 points):

#### A. Recommendation Adherence (20 points)

- **A1: Design Adherence** (10 points)
  - Calculates: (Gate 2 design_fidelity / 25) √ó 100%
  - Thresholds: ‚â•80% = 10pts, ‚â•60% = 7pts, <60% = 4pts

- **A2: Database Adherence** (10 points)
  - Calculates: (Gate 2 database_fidelity / 25) √ó 100%
  - Thresholds: ‚â•80% = 10pts, ‚â•60% = 7pts, <60% = 4pts

#### B. Implementation Quality (20 points)

- **B1: Gate 2 Score** (10 points)
  - Checks: Overall Gate 2 validation score
  - Thresholds: ‚â•90 = 10pts, ‚â•80 = 8pts, ‚â•70 = 6pts

- **B2: Test Coverage** (10 points)
  - Queries: EXEC‚ÜíPLAN handoff metadata
  - Checks: Test coverage documented

#### C. Traceability Mapping (20 points)

- **C1: PRD ‚Üí Implementation** (7 points)
  - Git analysis: Commits referencing SD ID

- **C2: Design ‚Üí Code** (7 points)
  - Queries: Deliverables mention design/UI/components

- **C3: Database ‚Üí Schema** (6 points)
  - Queries: Deliverables mention database/migration/schema/table

#### D. Sub-Agent Effectiveness (20 points)

- **D1: Execution Metrics** (10 points)
  - Queries: `sub_agent_execution_results`
  - Checks: All 3 sub-agents (DESIGN, DATABASE, STORIES) executed

- **D2: Recommendation Quality** (10 points)
  - Checks: Sub-agent results have substantial output (>500 chars)

#### E. Lessons Captured (20 points)

- **E1: Retrospective Prep** (10 points)
  - Queries: PLAN‚ÜíLEAD handoff metadata
  - Checks: Mentions "lesson", "retrospective", "improvement"

- **E2: Workflow Effectiveness** (10 points)
  - Queries: EXEC‚ÜíPLAN handoff metadata
  - Checks: Mentions "workflow", "process", "pattern"

---

### Gate 4: LEAD Final Approval (Pre-Completion)

**When**: Before marking SD as complete
**Purpose**: Executive oversight of design-to-implementation alignment
**Script**: `scripts/modules/workflow-roi-validation.js`
**Integration Point**: `unified-handoff-system.js` (LEAD final approval)

**4 Validation Sections** (25 points each = 100 points):

#### A. Process Adherence (25 points)

- **A1: PRD Created Via Script** (5 points)
  - Checks: `metadata.created_via_script` OR sub-agent analyses exist

- **A2: Design Analysis Completed** (5 points)
  - Checks: `metadata.design_analysis` exists

- **A3: Database Analysis Completed** (5 points)
  - Checks: `metadata.database_analysis` exists

- **A4: Design-Informed Database** (5 points)
  - Checks: `metadata.database_analysis.design_informed = true`

- **A5: Proper Workflow Order** (5 points)
  - Checks: Gate 1 validated execution order (DESIGN‚ÜíDATABASE‚ÜíSTORIES)

#### B. Value Delivered (25 points)

- **B1: Time Efficiency** (10 points)
  - Checks: Sub-agent execution time from Gate 3
  - Thresholds: <15min = 10pts, <30min = 7pts, ‚â•30min = 5pts

- **B2: Recommendation Quality** (10 points)
  - Checks: Gate 3 validated substantial recommendations

- **B3: Implementation Fidelity** (5 points)
  - Checks: Gate 2 score ‚â•80 = 5pts, ‚â•70 = 3pts, <70 = 2pts

#### C. Pattern Effectiveness (25 points)

- **C1: Gate 1 Performance** (6 points)
  - Thresholds: ‚â•90 = 6pts, ‚â•80 = 5pts, <80 = 3pts

- **C2: Gate 2 Performance** (6 points)
  - Thresholds: ‚â•90 = 6pts, ‚â•80 = 5pts, <80 = 3pts

- **C3: Gate 3 Performance** (6 points)
  - Thresholds: ‚â•90 = 6pts, ‚â•80 = 5pts, <80 = 3pts

- **C4: Overall Pattern ROI** (7 points)
  - Calculates: Average of Gate 1-3 scores
  - Thresholds: ‚â•90 = 7pts ("EXCELLENT - Continue pattern"), ‚â•80 = 6pts ("GOOD - Continue"), ‚â•70 = 4pts ("ACCEPTABLE - Monitor")

#### D. Executive Validation (25 points)

- **D1: All Gates Passed** (10 points)
  - Checks: Gate 1, 2, 3 all passed (score ‚â•80)
  - Scoring: 3/3 = 10pts, 2/3 = 6pts, 1/3 = 3pts, 0/3 = 0pts

- **D2: Quality Thresholds** (10 points)
  - Queries: `sd_retrospectives` table
  - Checks: Retrospective exists

- **D3: Pattern Recommendation** (5 points)
  - Based on avg gate score:
    - ‚â•80: "CONTINUE - Pattern is effective"
    - ‚â•70: "MONITOR - Pattern needs improvement"
    - <70: "REVIEW - Pattern may need adjustment"

---

### Integration with Unified Handoff System

**File**: `scripts/unified-handoff-system.js`

#### Integration Points:

1. **Gate 1 (PLAN‚ÜíEXEC)** - After line 271
   ```javascript
   // After BMAD validation
   if (shouldValidateDesignDatabase(sd)) {
     const gate1 = await validateGate1PlanToExec(sd.id, supabase);
     handoff.metadata.gate1_validation = gate1;

     if (!gate1.passed) {
       throw new Error(`Gate 1 validation failed: ${gate1.score}/100 points`);
     }
   }
   ```

2. **Gate 2 (EXEC‚ÜíPLAN)** - After line 486
   ```javascript
   // After BMAD validation
   if (shouldValidateDesignDatabase(sd)) {
     const gate2 = await validateGate2ExecToPlan(sd.id, supabase);
     handoff.metadata.gate2_validation = gate2;

     if (!gate2.passed) {
       throw new Error(`Gate 2 validation failed: ${gate2.score}/100 points`);
     }
   }
   ```

3. **Gate 3 (PLAN‚ÜíLEAD)** - After line 726
   ```javascript
   // During PLAN‚ÜíLEAD handoff
   if (shouldValidateDesignDatabase(sd)) {
     const gate3 = await validateGate3PlanToLead(sd.id, supabase, gate2Results);
     handoff.metadata.gate3_validation = gate3;

     if (!gate3.passed) {
       throw new Error(`Gate 3 validation failed: ${gate3.score}/100 points`);
     }
   }
   ```

4. **Gate 4 (LEAD Final)** - Before final approval
   ```javascript
   // Before marking SD complete
   if (shouldValidateDesignDatabase(sd)) {
     const allGates = { gate1, gate2, gate3 };
     const gate4 = await validateGate4LeadFinal(sd.id, supabase, allGates);

     if (!gate4.passed) {
       throw new Error(`Gate 4 validation failed: ${gate4.score}/100 points`);
     }
   }
   ```

---

### Validation Flow Diagram

```
PRD Creation (add-prd-to-database.js)
    ‚Üì
    ‚îú‚îÄ DESIGN sub-agent ‚Üí analysis
    ‚îú‚îÄ DATABASE sub-agent ‚Üí analysis (informed by DESIGN)
    ‚îî‚îÄ STORIES sub-agent ‚Üí user stories
    ‚Üì
üö™ GATE 1: PLAN‚ÜíEXEC Handoff
    ‚îú‚îÄ ‚úÖ All sub-agents executed?
    ‚îú‚îÄ ‚úÖ Execution order correct?
    ‚îú‚îÄ ‚úÖ Schema docs consulted?
    ‚îî‚îÄ ‚úÖ PRD metadata complete?
    ‚Üì
EXEC Implementation
    ‚îú‚îÄ Implement UI components (per DESIGN)
    ‚îú‚îÄ Create migrations (per DATABASE)
    ‚îú‚îÄ Write E2E tests
    ‚îî‚îÄ Commit with SD ID
    ‚Üì
üö™ GATE 2: EXEC‚ÜíPLAN Handoff
    ‚îú‚îÄ ‚úÖ Components match DESIGN?
    ‚îú‚îÄ ‚úÖ Migrations match DATABASE?
    ‚îú‚îÄ ‚úÖ Data flow aligned?
    ‚îî‚îÄ ‚úÖ Tests comprehensive?
    ‚Üì
PLAN Verification
    ‚Üì
üö™ GATE 3: PLAN‚ÜíLEAD Handoff
    ‚îú‚îÄ ‚úÖ Recommendations followed?
    ‚îú‚îÄ ‚úÖ Implementation quality high?
    ‚îú‚îÄ ‚úÖ End-to-end traceability?
    ‚îî‚îÄ ‚úÖ Lessons captured?
    ‚Üì
üö™ GATE 4: LEAD Final Approval
    ‚îú‚îÄ ‚úÖ All gates passed?
    ‚îú‚îÄ ‚úÖ Value delivered?
    ‚îú‚îÄ ‚úÖ Pattern effective?
    ‚îî‚îÄ ‚úÖ Quality thresholds met?
    ‚Üì
SD Complete ‚úÖ
```

---

### Standalone Validation Scripts

For manual validation outside handoff flow:

```bash
# Validate Gate 1 (PLAN‚ÜíEXEC)
node scripts/validate-gate1.js --sd=SD-XXX-001

# Validate Gate 2 (EXEC‚ÜíPLAN)
node scripts/validate-gate2.js --sd=SD-XXX-001

# Validate Gate 3 (PLAN‚ÜíLEAD)
node scripts/validate-gate3.js --sd=SD-XXX-001

# Validate Gate 4 (LEAD Final)
node scripts/validate-gate4.js --sd=SD-XXX-001

# Validate all gates
node scripts/validate-all-gates.js --sd=SD-XXX-001
```

---

### When Gates Don't Apply

**Conditional Execution Helper**:
```javascript
export function shouldValidateDesignDatabase(sd) {
  const hasDesignCategory = sd.category?.includes('design');
  const hasDatabaseCategory = sd.category?.includes('database');

  const hasUIKeywords = (sd.scope || '').toLowerCase().includes('ui');
  const hasDatabaseKeywords = (sd.scope || '').toLowerCase().includes('database');

  return (hasDesignCategory && hasDatabaseCategory) ||
         (hasUIKeywords && hasDatabaseKeywords);
}
```

**Behavior**:
- If validation doesn't apply: Returns `{ passed: true, score: 100, warnings: ['Not applicable'] }`
- If validation applies but fails: Returns `{ passed: false, score: <score>, issues: [...] }`
- If validation applies and passes: Returns `{ passed: true, score: ‚â•80, details: {...} }`

---

### Gate Results Storage

All gate results are stored in handoff metadata:

```javascript
{
  handoff_type: "PLAN-TO-EXEC",
  metadata: {
    gate1_validation: {
      passed: true,
      score: 92,
      max_score: 100,
      issues: [],
      warnings: [],
      details: { ... },
      gate_scores: { ... }
    }
  }
}
```

This enables:
1. **Traceability**: Full audit trail of validation results
2. **Retrospectives**: Quality analysis for continuous improvement
3. **Cascading**: Gate 3 uses Gate 2 results, Gate 4 uses all previous results
4. **Debugging**: Detailed failure information for each gate

## EXEC Dual Test Requirement

### ‚ö†Ô∏è MANDATORY: Dual Test Execution

**CRITICAL**: "Smoke tests" means BOTH test types, not just one!

**Evidence**: SD-EXPORT-001 - Tests existed but weren't executed. 30-minute gap between "complete" and validation. SD-EVA-MEETING-002 - 67% E2E failure rate when finally run.

Before creating EXEC‚ÜíPLAN handoff, EXEC MUST run:

#### 1. Unit Tests (Business Logic Validation)
```bash
cd /mnt/c/_EHG/ehg
npm run test:unit
```
- **What it validates**: Service layer, business logic, data transformations
- **Failure means**: Core functionality is broken
- **Required for**: EXEC‚ÜíPLAN handoff
- **Framework**: Vitest

#### 2. E2E Tests (UI/Integration Validation)
```bash
cd /mnt/c/_EHG/ehg
npm run test:e2e
```
- **What it validates**: User flows, component rendering, integration
- **Failure means**: User-facing features don't work
- **Required for**: EXEC‚ÜíPLAN handoff
- **Framework**: Playwright

#### Verification Checklist
- [ ] Unit tests executed: `npm run test:unit`
- [ ] Unit tests passed: [X/X tests]
- [ ] E2E tests executed: `npm run test:e2e`
- [ ] E2E tests passed: [X/X tests]
- [ ] Both test types documented in EXEC‚ÜíPLAN handoff
- [ ] Screenshots captured for E2E test evidence
- [ ] Test results included in handoff "Deliverables Manifest"

**‚ùå BLOCKING**: Cannot create EXEC‚ÜíPLAN handoff without BOTH test types passing.

**Common Mistakes** (from SD-EXPORT-001):
- ‚ùå "Tests exist" ‚â† "Tests passed"
- ‚ùå Running only E2E tests and claiming "all tests passed"
- ‚ùå Marking SD complete before running any tests
- ‚ùå Creating handoff without test evidence documentation
- ‚úÖ Run BOTH unit AND E2E tests explicitly
- ‚úÖ Document pass/fail counts in handoff
- ‚úÖ Include screenshots for visual evidence

### Why This Matters
- **SD-EXPORT-001**: 30-minute gap between marking "complete" and discovering tests weren't run
- **SD-EVA-MEETING-002**: 67% E2E failure rate revealed only when tests finally executed
- **Impact**: Testing enforcement prevents claiming "done" without proof

## CI/CD Pipeline Verification

## CI/CD Pipeline Verification (MANDATORY)

**Evidence from Retrospectives**: Gap identified in SD-UAT-002 and SD-LEO-002.

### Verification Process

**After EXEC implementation complete, BEFORE PLAN‚ÜíLEAD handoff**:

1. Wait 2-3 minutes for GitHub Actions to complete
2. Trigger DevOps sub-agent to verify pipeline status
3. Document CI/CD status in PLAN‚ÜíLEAD handoff
4. PLAN‚ÜíLEAD handoff is **BLOCKED** if pipelines failing

## Sub-Agent Auto-Trigger Enforcement (MANDATORY)

**Sub-Agent Auto-Trigger Enforcement**: Sub-agents MUST trigger automatically, not manually.

**EXEC‚ÜíPLAN Handoff Verification**:
```javascript
// MANDATORY: Check for QA execution
const { data: qaResults } = await supabase
  .from('sub_agent_execution_results')
  .select('*')
  .eq('sd_id', sd_id)
  .eq('sub_agent_code', 'TESTING')
  .order('created_at', { ascending: false })
  .limit(1);

if (!qaResults || qaResults.verdict === 'BLOCKED') {
  // BLOCK handoff
  process.exit(1);
}
```

**Complete Pattern**: See `docs/reference/sub-agent-automation.md`

## User Story E2E Test Mapping (MANDATORY)

**User Story E2E Test Mapping (MANDATORY)**: E2E tests MUST map to user stories explicitly.

**Naming Convention**: Every test must reference a user story:
```typescript
test('US-001: User can create new venture', async ({ page }) => {
  // Test implementation
});
```

**Coverage Formula**: (E2E Tests with US-XXX / Total User Stories) √ó 100
**Minimum Requirement**: 100% coverage (every user story MUST have ‚â•1 E2E test)

**QA Director Verification**: Automatically blocks handoff if coverage < 100%

**Examples & Patterns**: See `docs/reference/user-story-e2e-mapping.md`

## LEAD Code Review for UI/UX SDs

## LEAD Code Review Requirement (For UI/UX SDs)

**Evidence from Retrospectives**: Critical pattern from SD-UAT-002 saved hours.

### When Code Review is MANDATORY

**For SDs claiming** UI/UX issues or improvements.

### Why Code Review First?

**Success Story** (SD-UAT-002):
> "LEAD challenged 5 claimed issues, validated only 2. Saved 3-4 hours of unnecessary work."

### Process:
1. Receive SD with UI/UX claims
2. Read actual source code (don't trust claims)
3. Verify each claim against implementation
4. Reject false claims, document findings
5. Update SD scope and priority

## üìö Documentation Platform Integration

**Documentation Platform**: AI Documentation Generation System integrated into LEO Protocol.

**Auto-Triggers**: SD completion, EXEC‚ÜíPLAN handoff, retrospective creation
**EXEC Requirement**: Generate docs before handoff: `node scripts/generate-workflow-docs.js --sd-id <SD-ID>`
**Dashboard**: `/ai-docs-admin` to review and publish

**Complete Guide**: See `docs/reference/documentation-platform.md`

## üìñ Historical Context Review (RECOMMENDED)

**SD-LEO-LEARN-001: Proactive Learning Integration**

**RECOMMENDED**: Run BEFORE approving SD to review historical context.

## Step 0: Historical Context Check

**Run this command before SD approval**:

```bash
node scripts/phase-preflight.js --phase LEAD --sd-id <SD_UUID>
```

## What This Does

Queries historical knowledge base for:
- **Over-engineering patterns** in this SD category
- **Similar past SDs** and their outcomes
- **Complexity indicators** (actual vs estimated time)
- **Scope creep history** (SDs split due to bloat)

## Red Flags to Watch For

### Over-Engineering Indicators
- Pattern shows "over-engineering" occurred 2+ times in this category
- Historical resolution time >5x original estimate
- Past SDs in category were split due to scope bloat
- Complexity score disproportionate to business value

### Strategic Concerns
- Similar SDs had high failure/rework rates
- Category has pattern of expanding beyond initial scope
- Technical approach more complex than necessary
- Dependencies create cascading risks

## How to Use Results

### If Red Flags Found
1. Apply simplicity-first lens more rigorously
2. Challenge technical complexity in strategic validation
3. Request PLAN to simplify approach before approval
4. Consider phased delivery (MVP first, enhancements later)

### Document in Approval
Add to approval notes:

```markdown
## Historical Context Reviewed

Consulted 3 prior retrospectives in [category]:
- SD-SIMILAR-001: Over-engineered auth (8 weeks ‚Üí 3 weeks after simplification)
- SD-SIMILAR-002: Scope expanded 3x during implementation
- PAT-009: Premature abstraction in [category] (40% success rate)

**Decision**: Approved with simplicity constraints:
- MVP scope only (defer advanced features to Phase 2)
- Weekly complexity reviews during PLAN
- Hard cap: 400 LOC per component
```

### If No Red Flags
- Proceed with standard approval process
- Note historical consultation in approval
- Builds confidence in strategic decision

## Why This Matters

- **Prevents strategic mistakes**: Learn from past over-engineering
- **Informed decisions**: Data-driven approval vs intuition
- **Protects team time**: Avoid repeating known pitfalls
- **Builds pattern recognition**: Strategic lens improves over time

## Quick Reference

```bash
# Before SD approval (RECOMMENDED)
node scripts/phase-preflight.js --phase LEAD --sd-id <SD_UUID>

# Review over-engineering patterns
node scripts/search-prior-issues.js --category over_engineering --list

# Check category history
node scripts/search-prior-issues.js "<SD category>" --retrospectives
```

**Time Investment**: 1-2 minutes
**Value**: Strategic foresight, prevents month-long mistakes

## E2E Testing: Dev Mode vs Preview Mode

**E2E Testing Mode**: Default to dev mode (port 5173) for reliable tests.

**Issue**: Preview mode (4173) may have rendering problems
**Solution**: Use dev mode for tests, preview only for production validation
```typescript
baseURL: 'http://localhost:5173'  // Dev mode
```

**Full Guide**: See `docs/reference/e2e-testing-modes.md`

## Handoff Creation: RLS Bypass Pattern

**Handoff RLS Bypass**: Use direct PostgreSQL to bypass RLS policies.

**Issue**: RLS blocks INSERT with ANON_KEY
**Solution**: Direct connection via `createDatabaseClient` helper
```javascript
import { createDatabaseClient } from '../lib/supabase-connection.js';
const client = await createDatabaseClient('engineer', { verify: true });
```

**Full Pattern**: See `docs/reference/handoff-rls-bypass.md`

## Retrospective Table Schema Reference

**Retrospective Schema**: Critical field mappings to prevent constraint errors.

**Quick Reference:**
- `generated_by`: Must be 'MANUAL'
- `status`: Must be 'PUBLISHED'
- `team_satisfaction`: 1-10 scale (NOT 0-100)
- Array fields: Use arrays, NOT JSON.stringify()
- Boolean fields: true/false, NOT integers

**Common Errors**:
- Column "lessons_learned" not found ‚Üí Use `key_learnings`
- Malformed array literal ‚Üí Remove JSON.stringify()
- team_satisfaction_check violation ‚Üí Use 1-10 scale

**Complete Schema**: See `docs/reference/retrospective-schema.md`

## Database Trigger Management for Special Cases

**Database Trigger Management**: Temporary trigger disable for special cases (infrastructure/protocol SDs).

**Safe Pattern**:
```javascript
// Step 1: Disable trigger
await client.query('ALTER TABLE ... DISABLE TRIGGER trigger_name');

// Step 2: Critical operation
await client.query('UPDATE ...');

// Step 3: Re-enable (ALWAYS in finally block)
await client.query('ALTER TABLE ... ENABLE TRIGGER trigger_name');
```

**When to Use**: Legitimate special cases, RLS blocking trigger validation, no other solution available

**Complete Pattern**: See `docs/reference/trigger-management.md`

## Proactive Context Monitoring

**Context Monitoring**: Report context health in EVERY handoff.

**Status Thresholds**:
- HEALTHY ‚úÖ: 0-140K tokens (0-70%)
- WARNING ‚ö†Ô∏è: 140K-180K (70-90%) - Consider compaction
- CRITICAL üî¥: 180K-190K (90-95%) - MUST compact before handoff
- EMERGENCY üö®: >190K (>95%) - BLOCKED

**Handoff Section Required**:
```markdown
## Context Health
**Current Usage**: X tokens (Y% of 200K budget)
**Status**: HEALTHY/WARNING/CRITICAL
**Recommendation**: [action if needed]
```

**Complete Guide**: See `docs/reference/context-monitoring.md`

## Database Query Best Practices

**Database Query Efficiency**: Smart querying saves 5K-10K tokens per SD.

**Quick Rules:**
1. **Select specific columns** only (not `SELECT *`)
2. **Limit results** with `.limit(5)` for summaries
3. **Use Read tool** with offset/limit for large files
4. **Summarize results**, don't dump full objects
5. **Batch related reads** for parallel execution

**Expected Impact**: 90-98% token reduction per query

**Examples & Patterns**: See `docs/reference/database-best-practices.md`

## Sub-Agent Report Compression System

**Sub-Agent Report Compression**: Intelligent tiering preserves critical context while reducing token usage by 70-90%.

**Quick Reference:**
- **TIER 1 (CRITICAL)**: Full detail preserved for blockers/failures
- **TIER 2 (IMPORTANT)**: Structured summary with warnings
- **TIER 3 (INFORMATIONAL)**: One-line summary for passing validations

**Phase Relevance**: Different sub-agents matter more in different phases
**Automatic Retrieval**: Full reports fetched when needed (PLAN supervisor, retrospectives, debugging)

**Full Guide**: See `docs/reference/sub-agent-compression.md`

## Database-First Enforcement - Expanded

**Database-First Enforcement (MANDATORY)**:

**‚ùå NEVER create**: Strategic Directive files, PRD files, Retrospective files, Handoff documents, Verification reports

**‚úÖ REQUIRED**: All data in database tables only
- SDs ‚Üí `strategic_directives_v2`
- PRDs ‚Üí `product_requirements_v2`
- Retrospectives ‚Üí `retrospectives`
- Handoffs ‚Üí `sd_phase_handoffs`

**Why**: Single source of truth, real-time updates, automated tracking, no file sync issues

**Verification**: `find . -name "SD-*.md" -o -name "PRD-*.md"` should return ONLY legacy files

## üõ°Ô∏è LEAD Pre-Approval Strategic Validation Gate

### MANDATORY Before Approving ANY Strategic Directive

LEAD MUST answer these questions BEFORE approval:

1. **Need Validation**: Is this solving a real user problem or perceived problem?
2. **Solution Assessment**: Does the proposed solution align with business objectives?
3. **Existing Tools**: Can we leverage existing tools/infrastructure instead of building new?
4. **Value Analysis**: Does the expected value justify the development effort?
5. **Feasibility Review**: Are there any technical or resource constraints that make this infeasible?
6. **Risk Assessment**: What are the key risks and how are they mitigated?

**Approval Criteria**:
- Real user/business problem identified
- Solution is technically feasible
- Resources are available or can be allocated
- Risks are acceptable and documented
- Expected value justifies effort

**SCOPE LOCK**: Once LEAD approves an SD, the scope is LOCKED. LEAD commits to delivering the approved scope. LEAD may NOT:
- ‚ùå Re-evaluate "do we really need this?" during final approval
- ‚ùå Reduce scope after EXEC phase begins without critical justification
- ‚ùå Defer work unilaterally during verification
- ‚ùå Mark SD complete if PRD requirements not met

**Exception**: LEAD may adjust scope mid-execution ONLY if:
1. Critical technical blocker discovered (true impossibility, not difficulty)
2. External business priorities changed dramatically (documented)
3. Explicit human approval obtained
4. New SD created for all deferred work (no silent scope reduction)


## Pre-Implementation Plan Presentation Template

**SD-PLAN-PRESENT-001** | **Template Type:** plan_presentation | **Phase:** PLAN ‚Üí EXEC

### Purpose

The `plan_presentation` template standardizes PLAN‚ÜíEXEC handoffs by providing structured implementation guidance to the EXEC agent. This template reduces EXEC confusion from 15-20 minutes to <5 minutes by clearly communicating:

- **What** will be implemented (goal_summary)
- **Where** changes will occur (file_scope)
- **How** to implement step-by-step (execution_plan)
- **Dependencies** and impacts (dependency_impacts)
- **Testing approach** (testing_strategy)

### Template Structure

All plan_presentation objects must be included in the `metadata.plan_presentation` field of PLAN‚ÜíEXEC handoffs.

#### Required Fields

1. **goal_summary** (string, ‚â§300 chars, required)
   - Brief 2-3 sentence summary of implementation goals
   - Focus on "what" and "why", not "how"
   - Example: `"Add plan_presentation template to leo_handoff_templates table with JSONB validation structure. Enhance unified-handoff-system.js with validation logic (~50 LOC). Reduce EXEC confusion from 15-20 min to <5 min."`

2. **file_scope** (object, required)
   - Lists files to create, modify, or delete
   - At least one category must have ‚â•1 file
   - Structure:
     ```json
     {
       "create": ["path/to/new-file.js"],
       "modify": ["path/to/existing-file.js"],
       "delete": ["path/to/deprecated-file.js"]
     }
     ```

3. **execution_plan** (array, required, ‚â•1 step)
   - Step-by-step implementation sequence
   - Each step includes: step number, action description, affected files
   - Structure:
     ```json
     [
       {
         "step": 1,
         "action": "Add validatePlanPresentation() method to PlanToExecVerifier class",
         "files": ["scripts/verify-handoff-plan-to-exec.js"]
       },
       {
         "step": 2,
         "action": "Integrate validation into verifyHandoff() method",
         "files": ["scripts/verify-handoff-plan-to-exec.js"]
       }
     ]
     ```

4. **testing_strategy** (object, required)
   - Specifies unit test and E2E test approaches
   - Both unit_tests and e2e_tests fields required
   - Structure:
     ```json
     {
       "unit_tests": "Test validatePlanPresentation() with valid, missing, and invalid structures",
       "e2e_tests": "Create PLAN‚ÜíEXEC handoff and verify validation enforcement",
       "verification_steps": [
         "Run test script with 3 scenarios",
         "Verify validation passes for complete plan_presentation"
       ]
     }
     ```

#### Optional Fields

5. **dependency_impacts** (object, optional)
   - Documents dependencies and their impacts
   - Structure:
     ```json
     {
       "npm_packages": ["react-hook-form", "zod"],
       "internal_modules": ["handoff-validator.js"],
       "database_changes": "None (reads from leo_handoff_templates)"
     }
     ```

### Validation Rules

The `verify-handoff-plan-to-exec.js` script validates plan_presentation structure:

- ‚úÖ `goal_summary` present and ‚â§300 characters
- ‚úÖ `file_scope` has at least one of: create, modify, delete
- ‚úÖ `execution_plan` has ‚â•1 step
- ‚úÖ `testing_strategy` has both `unit_tests` and `e2e_tests` defined

**Validation Enforcement:** PLAN‚ÜíEXEC handoffs are rejected if plan_presentation is missing or invalid.

### Complete Example

```json
{
  "metadata": {
    "plan_presentation": {
      "goal_summary": "Add plan_presentation template to leo_handoff_templates table with JSONB validation structure. Enhance unified-handoff-system.js with validation logic (~50 LOC). Reduce EXEC confusion from 15-20 min to <5 min.",
      "file_scope": {
        "create": [],
        "modify": ["scripts/verify-handoff-plan-to-exec.js"],
        "delete": []
      },
      "execution_plan": [
        {
          "step": 1,
          "action": "Add validatePlanPresentation() method to PlanToExecVerifier class",
          "files": ["scripts/verify-handoff-plan-to-exec.js"]
        },
        {
          "step": 2,
          "action": "Integrate validation into verifyHandoff() method",
          "files": ["scripts/verify-handoff-plan-to-exec.js"]
        },
        {
          "step": 3,
          "action": "Add PLAN_PRESENTATION_INVALID rejection handler",
          "files": ["scripts/verify-handoff-plan-to-exec.js"]
        }
      ],
      "dependency_impacts": {
        "npm_packages": [],
        "internal_modules": ["handoff-validator.js"],
        "database_changes": "None (reads from leo_handoff_templates)"
      },
      "testing_strategy": {
        "unit_tests": "Test validatePlanPresentation() with valid, missing, and invalid structures",
        "e2e_tests": "Create PLAN‚ÜíEXEC handoff and verify validation enforcement",
        "verification_steps": [
          "Run test script with 3 scenarios (TS1, TS2, TS3)",
          "Verify validation passes for complete plan_presentation",
          "Verify validation fails with clear errors for incomplete/invalid structures"
        ]
      }
    }
  }
}
```

### Benefits

- **Reduced Confusion:** EXEC spends <5 min understanding implementation (vs 15-20 min)
- **Consistent Handoffs:** All PLAN‚ÜíEXEC handoffs follow same structure
- **Auditability:** Implementation decisions queryable via metadata
- **Quality Gate:** Invalid handoffs rejected before EXEC phase begins

### Related Documentation

- **Template Definition:** leo_handoff_templates table, handoff_type = 'plan_presentation'
- **Validation Logic:** scripts/verify-handoff-plan-to-exec.js (PlanToExecVerifier.validatePlanPresentation)
- **Test Coverage:** scripts/test-plan-presentation-validation.mjs (5 test scenarios)


## Testing Tier Strategy (Updated)


## Testing Requirements - Dual Test Execution (UPDATED)

**Philosophy**: Comprehensive testing = Unit tests (logic) + E2E tests (user experience)

### Tier 1: Smoke Tests (MANDATORY) ‚úÖ
- **Requirement**: BOTH unit tests AND E2E tests must pass
- **Commands**:
  - Unit: `npm run test:unit` (Vitest - business logic)
  - E2E: `npm run test:e2e` (Playwright - user flows)
- **Approval**: **BOTH test types REQUIRED for PLAN‚ÜíLEAD approval**
- **Execution Time**: Combined <5 minutes for smoke-level tests
- **Coverage**:
  - Unit: Service layer, business logic, utilities
  - E2E: Critical user paths, authentication, navigation

### Tier 2: Comprehensive Testing (RECOMMENDED) üìã
- **Requirement**: Full test suite with deep coverage
- **Commands**:
  - Unit: `npm run test:unit:coverage` (50%+ coverage target)
  - E2E: All Playwright tests (30-50 scenarios)
  - Integration: `npm run test:integration`
  - A11y: `npm run test:a11y`
- **Approval**: Nice to have, **NOT blocking** but highly recommended
- **Timing**: Can be refined post-deployment

### Tier 3: Manual Testing (SITUATIONAL) üîç
- **UI changes**: Visual regression testing
- **Complex flows**: Multi-step wizards, payment flows
- **Edge cases**: Rare scenarios not covered by automation

### ‚ö†Ô∏è What Changed (From Protocol Enhancement)
**Before**: "Tier 1 = 3-5 tests, <60s" (ambiguous - which tests?)
**After**: "Tier 1 = Unit tests + E2E tests (explicit frameworks, explicit commands)"

**Lesson Learned**: SD-AGENT-ADMIN-002 testing oversight (ran E2E only, missed unit test failures)


## Database Schema Documentation Access

## üìä Database Schema Documentation Access

**Auto-Generated Schema Docs** - Reference documentation from live Supabase databases

### Available Schema Documentation

**EHG_Engineer Database** (Management Dashboard):
- **Quick Reference**: `docs/reference/schema/engineer/database-schema-overview.md` (~15-20KB)
- **Detailed Tables**: `docs/reference/schema/engineer/tables/[table_name].md` (2-5KB each)
- **Coverage**: 159 tables documented
- **Purpose**: Strategic Directives, PRDs, retrospectives, LEO Protocol configuration
- **Repository**: /mnt/c/_EHG/EHG_Engineer/
- **Database**: dedlbzhpgkmetvhbkyzq

**EHG Application Database** (Customer-Facing):
- **Quick Reference**: `docs/reference/schema/ehg/database-schema-overview.md` (~15-20KB)
- **Detailed Tables**: `docs/reference/schema/ehg/tables/[table_name].md` (2-5KB each)
- **Coverage**: ~200 tables (requires pooler credentials to generate)
- **Purpose**: Customer features, business logic, user-facing functionality
- **Repository**: /mnt/c/_EHG/ehg/
- **Database**: liapbndqlqxdcgpwntbv

### When to Use Schema Docs

**MANDATORY during PLAN phase**:
- Creating PRDs with database changes
- Validating technical approach
- Identifying table dependencies
- Preventing schema conflicts

**PRD Database Integration**:
PRDs are stored in `product_requirements_v2` table (NOT markdown files). The `add-prd-to-database.js` script prompts for schema review and guides you to populate these fields with schema insights:
- `technical_approach`: Reference existing tables/columns
- `database_changes`: List affected tables with schema context
- `dependencies`: Note table relationships from schema docs

### Regenerating Schema Docs

**Automatic**:
- CI/CD workflow runs on migration changes (see `.github/workflows/schema-docs-update.yml`)
- Weekly scheduled runs (Sunday midnight)

**Manual**:
```bash
# Engineer database (EHG_Engineer)
npm run schema:docs:engineer

# EHG application database (requires pooler credentials)
npm run schema:docs:ehg

# Both databases
npm run schema:docs:all

# Single table (verbose output)
npm run schema:docs:table <table_name>
```

### Integration with PRD Creation Workflow

**Step 1: Review Schema Before PRD**
```bash
# Quick check if tables exist
less docs/reference/schema/engineer/database-schema-overview.md | grep -A 5 "table_name"

# Detailed table review
cat docs/reference/schema/engineer/tables/strategic_directives_v2.md
```

**Step 2: Create PRD with Schema Context**
```bash
# Script automatically prompts for schema review
node scripts/add-prd-to-database.js SD-EXAMPLE-001
# ‚Üí Detects table names from SD description
# ‚Üí Asks: "Have you reviewed schema docs for: strategic_directives_v2, user_stories?"
# ‚Üí Guides you to populate technical_approach and database_changes fields
```

**Step 3: PLAN Agent Validates Schema Awareness**
- PRD must reference specific tables/columns in `technical_approach`
- `database_changes` field must list affected tables
- PLAN‚ÜíEXEC handoff checks for schema validation

### Critical Reminders

‚ö†Ô∏è **Schema Docs are REFERENCE ONLY**
- Always query database directly for validation
- Schema docs may lag behind recent migrations
- Use as starting point, not source of truth

‚ö†Ô∏è **Application Context Matters**
- Each schema doc header clearly states application and database
- NEVER confuse EHG_Engineer tables with EHG tables
- Check `**Repository**` field to confirm where code changes go

‚ö†Ô∏è **PRD Workflow**
- PRDs are database records (product_requirements_v2 table)
- Use `add-prd-to-database.js` script (triggers STORIES sub-agent)
- Schema insights go in database fields, not markdown

---

*Schema docs generated by: `scripts/generate-schema-docs-from-db.js`*
*Auto-update workflow: `.github/workflows/schema-docs-update.yml`*


## Database Migration Validation - Two-Phase Approach

**Database Migration Validation - Two-Phase Approach (MANDATORY)**:

**Phase 1: Static File Validation** (always runs):
- Migration files exist for SD-ID
- SQL syntax is valid
- Required patterns present (CREATE TABLE, ALTER TABLE)
- Cross-schema foreign keys detected

**Phase 2: Database Verification** (optional, via `--verify-db`):
- Tables mentioned in migration actually exist
- Tables are accessible (RLS policies)
- Seed data was inserted (with `--check-seed-data`)

**Commands**:
```bash
# Basic validation (file-only)
node scripts/validate-migration-files.js <SD-ID>

# Full validation (file + database + seed data)
node scripts/validate-migration-files.js <SD-ID> --verify-db --check-seed-data
```

**Complete Guide**: See `docs/database-migration-validation-guide.md`

## Playwright MCP Integration

## üé≠ Playwright MCP Integration

**Status**: ‚úÖ READY (Installed 2025-10-12)

### Overview
Playwright MCP (Model Context Protocol) provides browser automation capabilities for testing, scraping, and UI verification.

### Installed Components
- **Chrome**: Google Chrome browser for MCP operations
- **Chromium**: Chromium 141.0.7390.37 (build 1194) for standard Playwright tests
- **Chromium Headless Shell**: Headless browser for CI/CD pipelines
- **System Dependencies**: All required Linux libraries installed

### Available MCP Tools

#### Navigation
- `mcp__playwright__browser_navigate` - Navigate to URL
- `mcp__playwright__browser_navigate_back` - Go back to previous page

#### Interaction
- `mcp__playwright__browser_click` - Click elements
- `mcp__playwright__browser_fill` - Fill form fields
- `mcp__playwright__browser_select` - Select dropdown options
- `mcp__playwright__browser_hover` - Hover over elements
- `mcp__playwright__browser_type` - Type text into elements

#### Verification
- `mcp__playwright__browser_snapshot` - Capture accessibility snapshot
- `mcp__playwright__browser_take_screenshot` - Take screenshots
- `mcp__playwright__browser_evaluate` - Execute JavaScript

#### Management
- `mcp__playwright__browser_close` - Close browser
- `mcp__playwright__browser_tabs` - Manage tabs

### Testing Integration

**When to Use Playwright MCP**:
1. ‚úÖ Visual regression testing
2. ‚úÖ UI component verification
3. ‚úÖ Screenshot capture for evidence
4. ‚úÖ Accessibility tree validation
5. ‚úÖ Cross-browser testing

**When to Use Standard Playwright**:
1. ‚úÖ E2E test suites (`npm run test:e2e`)
2. ‚úÖ CI/CD pipeline tests
3. ‚úÖ Automated test runs
4. ‚úÖ User story validation

### Usage Example

```javascript
// Using Playwright MCP for visual verification
await mcp__playwright__browser_navigate({ url: 'http://localhost:3000/dashboard' });
await mcp__playwright__browser_snapshot(); // Get accessibility tree
await mcp__playwright__browser_take_screenshot({ name: 'dashboard-state' });
await mcp__playwright__browser_click({ element: 'Submit button', ref: 'e5' });
```

### QA Director Integration

The QA Engineering Director sub-agent now has access to:
- Playwright MCP for visual testing
- Standard Playwright for E2E automation
- Both Chrome (MCP) and Chromium (tests) browsers

**Complete Guide**: See `docs/reference/playwright-mcp-guide.md`

## Edge Case Testing Checklist

When implementing tests, ensure coverage for:

### Input Validation Edge Cases
- [ ] Empty strings, null values, undefined
- [ ] Maximum length inputs (overflow testing)
- [ ] Special characters (SQL injection, XSS vectors)
- [ ] Unicode and emoji inputs
- [ ] Whitespace-only inputs

### Boundary Conditions
- [ ] Zero, negative, and maximum numeric values
- [ ] Array min/max lengths (empty, single item, very large)
- [ ] Date boundaries (leap years, timezone edge cases)

### Concurrent Operations
- [ ] Race conditions (simultaneous updates)
- [ ] Database transaction rollbacks
- [ ] Cache invalidation timing

### Error Scenarios
- [ ] Network failures (timeout, disconnect)
- [ ] Database connection errors
- [ ] Invalid authentication tokens
- [ ] Permission denied scenarios

### State Transitions
- [ ] Idempotency (repeated operations)
- [ ] State rollback on error
- [ ] Partial success scenarios

## Playwright Server Management Best Practice

### Best Practice: Playwright-Managed Dev Server

**Evidence**: SD-AGENT-MIGRATION-001 - Always let Playwright manage the dev server lifecycle for consistent port and automated testing workflows.

**DO NOT** manually start dev servers before E2E tests. Let Playwright manage it.

#### Configuration (playwright.config.ts)
```typescript
webServer: {
  command: 'npm run dev -- --port 8080',
  port: 8080,
  reuseExistingServer: true,  // Reuse if already running
  timeout: 120_000,            // 2 min startup timeout
}
```

#### Why This Works
- **Consistent Port**: All tests use same port (8080)
- **Auto-Lifecycle**: Server starts before tests, stops after
- **CI/CD Compatible**: Works in automated environments
- **Local Dev Friendly**: `reuseExistingServer` prevents killing your dev server

#### Anti-Patterns
- ‚ùå Starting dev server manually on inconsistent ports
- ‚ùå Forgetting to stop old servers (port conflicts)
- ‚ùå Hardcoding URLs without using `baseURL` from config
- ‚ùå Running tests while manually managing server lifecycle

#### Example Test Run
```bash
# Playwright handles everything
npm run test:e2e

# Playwright:
# 1. Checks if server already running on 8080
# 2. Starts server if needed: npm run dev -- --port 8080
# 3. Waits for server to be ready
# 4. Runs tests
# 5. Keeps server running (reuseExistingServer: true)
```

#### Manual Server Check (if needed)
```bash
# Kill old servers
lsof -i :8080 | grep LISTEN | awk '{print $2}' | xargs kill -9

# Let Playwright manage
npm run test:e2e
```

## Knowledge Retrieval Commands

## üîç Knowledge Retrieval (Proactive Learning)

**SD-LEO-LEARN-001: Added 2025-10-25**

```bash
# Before starting any phase (MANDATORY for EXEC/PLAN, RECOMMENDED for LEAD)
node scripts/phase-preflight.js --phase <LEAD|PLAN|EXEC> --sd-id <UUID>

# Search for specific issues
node scripts/search-prior-issues.js "<issue description>"

# Generate fresh knowledge summaries (weekly)
node scripts/generate-knowledge-summary.js --category <category>
node scripts/generate-knowledge-summary.js --category all

# View existing summaries
ls docs/summaries/lessons/*.md
cat docs/summaries/lessons/database-lessons.md
```

**Philosophy**: Consult lessons BEFORE encountering issues, not after.

## Test Section

Test content

## Visual Documentation Best Practices

When creating PRDs and technical specifications, consider adding:

### Architecture Diagrams (Mermaid)
```mermaid
graph TD
    A[User Request] --> B[Validation Layer]
    B --> C{Valid?}
    C -->|Yes| D[Business Logic]
    C -->|No| E[Error Response]
    D --> F[Database]
    F --> G[Success Response]
```

### State Flow Diagrams
```mermaid
stateDiagram-v2
    [*] --> Draft
    Draft --> Review
    Review --> Approved
    Review --> Rejected
    Rejected --> Draft
    Approved --> [*]
```

### Sequence Diagrams (Complex Interactions)
```mermaid
sequenceDiagram
    User->>+Frontend: Submit Form
    Frontend->>+API: POST /api/submit
    API->>+Database: INSERT data
    Database-->>-API: Success
    API->>+Queue: Enqueue job
    Queue-->>-API: Acknowledged
    API-->>-Frontend: 202 Accepted
    Frontend-->>-User: Show success
```

**When to Use**:
- Complex workflows with multiple decision points ‚Üí Flowchart
- Multi-component interactions ‚Üí Sequence diagram
- State transitions ‚Üí State diagram
- System architecture ‚Üí Component diagram

## Database Migration Pre-Flight Checklist

**Database Migration Pre-Flight Checklist (MANDATORY)**:

**Before attempting ANY migration**:
1. Read established pattern: `scripts/lib/supabase-connection.js`
2. Verify connection: Region aws-1, Port 5432, SSL config
3. Use helper functions: `createDatabaseClient`, `splitPostgreSQLStatements`
4. Validate migration file: No cross-schema FKs, correct RLS syntax
5. Handle conflicts: Check existing tables, use CASCADE carefully

**Anti-Patterns to AVOID**:
- Using psql without understanding connection format
- Trial-and-error with regions/ports/SSL
- Not handling "already exists" errors

**Complete Guide**: See `docs/reference/migration-preflight.md`

## Native Claude Code Sub-Agent Integration

## ü§ñ Native Claude Code Sub-Agent Integration

**Status**: ‚úÖ TESTED & DOCUMENTED (2025-10-12)

### Overview
Claude Code supports native sub-agents via the Task tool. These sub-agents work alongside the database-driven LEO Protocol orchestration system in a hybrid architecture.

### Critical Dependency: ripgrep
**REQUIRED**: `ripgrep` (command: `rg`) must be installed for agent discovery.
```bash
# Check if installed
which rg

# Install on Ubuntu/Debian WSL2
sudo apt update && sudo apt install ripgrep -y
```

**Without ripgrep**: Agent discovery fails silently (no error messages, agents simply won't be found).

### Discovery Mechanism
1. Claude Code uses ripgrep to scan `.claude/agents/*.md` files
2. YAML frontmatter is parsed for agent configuration
3. Successfully discovered agents appear in `/agents` menu
4. Verify with: `/agents` command

### Five Sub-Agent Invocation Patterns

#### Pattern 1: Advisory Mode ‚úÖ (RECOMMENDED for guidance)

**Use Case**: General architecture questions, no SD context

**Example**:
```
User: "What's the best way to structure a many-to-many relationship?"
Main Agent ‚Üí Task(database-agent) ‚Üí Expert Guidance
```

**Performance**: ~3 seconds, 0 database records
**Best For**: Design exploration, best practices, architectural guidance

---

#### Pattern 2: Direct Orchestration ‚úÖ (PRODUCTION-READY)

**Use Case**: Explicit phase-based validation, multiple sub-agents, production workflows

**Example**:
```bash
node scripts/orchestrate-phase-subagents.js PLAN_VERIFY SD-MONITORING-001
```

**Performance**: ~2 seconds (parallel execution), 4 database records
**Best For**: Phase validation, multi-agent orchestration, audit trails, when user explicitly requests validation

---

#### Pattern 3: Automatic SD Detection & Execution ‚úÖ (SMART ORCHESTRATION)

**Use Case**: Automatically detect SD-related requests and execute appropriate orchestration

**How It Works**:
Main agent detects patterns in user requests and automatically executes Pattern 2 (Direct Orchestration) without requiring explicit script syntax.

**Detection Patterns**:

1. **SD-ID Detection** (Primary Trigger):
   - Regex: `SD-[A-Z0-9]+-[A-Z0-9-]+` or `SD-[A-Z0-9]+`
   - Examples: SD-MONITORING-001, SD-UAT-020, SD-EXPORT-001

2. **Validation Keywords** (Secondary Trigger):
   - validate, check, verify, review, assess, evaluate, test, run, execute
   - Example: "validate SD-XXX", "check SD-XXX status", "run verification for SD-XXX"

3. **Phase Keywords** (Context Qualifier):
   - PLAN_VERIFY, LEAD_PRE_APPROVAL, PLAN_PRD, EXEC_IMPL, LEAD_FINAL
   - LEAD, PLAN, EXEC phases
   - pre-approval, verification, final approval
   - Example: "run PLAN_VERIFY for SD-XXX", "pre-approval check for SD-XXX"

**Automatic Execution Logic**:

```
IF user message contains SD-ID pattern (SD-XXX)
  AND (validation keyword OR phase keyword)
THEN
  Determine phase:
    - "pre-approval" OR "LEAD_PRE_APPROVAL" ‚Üí LEAD_PRE_APPROVAL
    - "PRD" OR "PLAN_PRD" ‚Üí PLAN_PRD
    - "verify" OR "verification" OR "PLAN_VERIFY" ‚Üí PLAN_VERIFY
    - "final" OR "LEAD_FINAL" ‚Üí LEAD_FINAL
    - Default: PLAN_VERIFY (most common verification)

  Execute: node scripts/orchestrate-phase-subagents.js <PHASE> <SD-ID>

  Report results to user
END IF
```

**Examples of Automatic Detection**:

| User Request | Detected | Auto-Executes |
|--------------|----------|---------------|
| "Validate SD-MONITORING-001" | ‚úÖ SD-ID + "validate" | `node scripts/orchestrate-phase-subagents.js PLAN_VERIFY SD-MONITORING-001` |
| "Run pre-approval for SD-AUTH-003" | ‚úÖ SD-ID + "pre-approval" | `node scripts/orchestrate-phase-subagents.js LEAD_PRE_APPROVAL SD-AUTH-003` |
| "Check SD-EXPORT-001 status" | ‚úÖ SD-ID + "check" | `node scripts/orchestrate-phase-subagents.js PLAN_VERIFY SD-EXPORT-001` |
| "PLAN_VERIFY SD-UAT-020" | ‚úÖ Phase keyword + SD-ID | `node scripts/orchestrate-phase-subagents.js PLAN_VERIFY SD-UAT-020` |
| "Is SD-TEST-001 ready?" | ‚úÖ SD-ID + implied check | `node scripts/orchestrate-phase-subagents.js PLAN_VERIFY SD-TEST-001` |
| "What is SD-XXX about?" | ‚ùå No validation keyword | Query database, no orchestration |

**Performance**: Same as Pattern 2 (~2 seconds), but triggered automatically
**Best For**: User convenience, reducing syntax burden, natural language SD validation

**User Benefits**:
- No need to remember orchestrator script syntax
- Natural language requests work automatically
- Correct phase selected based on context
- All Pattern 2 benefits (parallel execution, database storage) automatically applied

---

#### Pattern 4: Context-Aware Sub-Agent Selection (COMING SOON)

**Use Case**: Intelligently select relevant sub-agents based on SD content analysis

**Status**: In development (Phase 2 of execution plan)

**Planned Features**:
- Compound keyword matching (require 2+ matches to reduce false positives)
- Context-aware weighting (title matches > description matches)
- Domain coordination (DATABASE + SECURITY for auth features)
- Exclusion patterns ("HTML table" ‚â† database table trigger)

**Expected Release**: 2-3 weeks

---

#### Pattern 5: Error-Triggered Sub-Agent Invocation (COMING SOON)

**Use Case**: Automatically invoke specialist sub-agents when errors occur

**Status**: In development (Phase 3 of execution plan)

**Planned Features**:
- Error pattern library (database errors, authentication failures, build errors)
- Automatic diagnosis & recovery workflows
- Circuit breakers to prevent infinite loops
- Learning from resolved errors

**Expected Release**: 1-2 months

### Decision Matrix

| Scenario | Pattern | Command |
|----------|---------|---------|
| "What's the best way to...?" | 1 (Advisory) | Natural language query |
| "How should I structure...?" | 1 (Advisory) | Natural language query |
| "Validate SD-XXX" | 3 (Auto-Detect) | Detected automatically |
| "Run PLAN_VERIFY for SD-XXX" | 3 (Auto-Detect) | Detected automatically |
| Explicit script execution | 2 (Direct Script) | `node scripts/orchestrate-phase-subagents.js PLAN_VERIFY SD-XXX` |

### Invocation Mechanism (Task Tool)

**What WORKS** ‚úÖ:
- **Task tool**: Main agent uses Task tool to delegate to sub-agents
- From user perspective: Natural language (transparent delegation)
- Behind the scenes: `Task(subagent_type: "database-agent", description: "...", prompt: "...")`
- **Pattern 3 Auto-Detection**: Main agent recognizes SD-ID patterns and executes orchestrator automatically

**What DOESN'T WORK** ‚ùå:
- Automatic delegation (typing keywords alone)
- @-mention syntax (`@database-agent` or `@agent-database-agent`)

### Integration with LEO Protocol 5-Phase Workflow

**LEAD Pre-Approval**:
- Pattern 1 for design questions
- Pattern 3 for validation: "Run pre-approval for SD-XXX" (auto-detects)
- Pattern 2 for explicit: `node scripts/orchestrate-phase-subagents.js LEAD_PRE_APPROVAL SD-XXX`

**PLAN PRD Creation**:
- Pattern 1 for architecture guidance
- Pattern 3 for validation: "Validate PRD for SD-XXX" (auto-detects)
- Pattern 2 for explicit: `node scripts/orchestrate-phase-subagents.js PLAN_PRD SD-XXX`

**EXEC Implementation**:
- Pattern 1 for implementation questions
- Pattern 3 for validation: "Check SD-XXX implementation" (auto-detects)
- Pattern 2 for explicit: `node scripts/orchestrate-phase-subagents.js EXEC_IMPL SD-XXX`

**PLAN Verification**:
- Pattern 3 for validation: "Verify SD-XXX" (auto-detects PLAN_VERIFY phase)
- Pattern 2 for explicit: `node scripts/orchestrate-phase-subagents.js PLAN_VERIFY SD-XXX`

**LEAD Final Approval**:
- Pattern 3 for validation: "Run final approval for SD-XXX" (auto-detects)
- Pattern 2 for explicit: `node scripts/orchestrate-phase-subagents.js LEAD_FINAL SD-XXX`

### Active Native Sub-Agents

**Currently Available**:
- `database-agent` - Principal Database Architect (tested, working)
- `validation-agent` - Principal Systems Analyst (tested, working)
- `test-agent` - Test agent for diagnostics (tested, working)

**Agent File Location**: `.claude/agents/*.md`

**Example Agent Structure**:
```yaml
---
name: database-agent
description: "MUST BE USED PROACTIVELY for all database tasks. Handles schema design, Supabase migrations, RLS policies, SQL validation, and architecture. Trigger on keywords: database, migration, schema, table, RLS, SQL, Postgres."
tools: Bash, Read, Write
model: inherit
---
```

### Performance Metrics

| Operation | Pattern 1 | Pattern 2 | Pattern 3 |
|-----------|-----------|-----------|-----------|
| Invocation | <1s | <1s | <1s |
| Execution | 2-5s | 1-3s | 1-3s (same as P2) |
| Database Writes | 0 | 1-6 | 1-6 (same as P2) |
| Token Usage | Medium | Low | Low |
| Best For | Guidance | Explicit | Natural language |

### Troubleshooting

**Agent not appearing in /agents menu**:
1. Check ripgrep installed: `which rg`
2. Verify file location: `.claude/agents/*.md`
3. Validate YAML frontmatter
4. Restart Claude Code

**Pattern 3 not auto-detecting**:
- Ensure SD-ID format is correct (SD-XXX-XXX or SD-XXX)
- Include validation keyword (validate, check, verify, etc.)
- Check that main agent has Pattern 3 logic in context

**Sub-agent not executing scripts** (Legacy Pattern 2 issue):
- Use Pattern 2 or 3 instead
- Main agent invokes scripts directly via Bash tool

### Complete Documentation

**Detailed Guides**:
- `docs/reference/native-sub-agent-invocation.md` - Discovery, invocation, troubleshooting (420 lines)
- `docs/guides/hybrid-sub-agent-workflow.md` - Decision matrix, patterns, integration (450 lines)

**Test Results**: Patterns 1-2 comprehensively tested (2025-10-12), Pattern 3 in deployment
**Production Status**: Patterns 1 & 2 ready, Pattern 3 active deployment, Patterns 4 & 5 in development


## Test Execution Timeout Handling

## üïê Test Execution Timeout Handling

**Problem**: Test suites timing out in WSL2/resource-constrained environments
**Solution**: 4-step fallback strategy with clear escalation path

### Quick Reference

**Timeout Thresholds**:
- Unit Tests: 2 min (native) / 3 min (WSL2)
- E2E Tests: 5 min (native) / 7 min (WSL2)

**4-Step Fallback Strategy**:
1. **Quick Validation** (60s): `vitest run --no-coverage`
2. **Focused Testing** (30s): `vitest run --grep="ComponentName"`
3. **Manual Smoke Test** (5 min): Navigate + test critical paths
4. **CI/CD-Only** (7-10 min): Push to branch, document GitHub Actions URL

**When to Escalate**: All 4 steps timeout ‚Üí LEAD investigation

**Complete Guide**: `docs/reference/test-timeout-handling.md` (200 lines)

**Evidence**: SD-SETTINGS-2025-10-12 - Unit tests timed out after 2 min in WSL2
**Impact**: Prevents 30-60 min of blocked time per timeout occurrence

## Checkpoint Pattern for Large SDs

## üìç Checkpoint Pattern for Large SDs

**Problem**: Large SDs (12+ user stories) consume excessive context, high rework risk
**Solution**: Break into 3-4 checkpoints with interim validation

### Quick Reference

**When to Use**:
- 9+ user stories ‚Üí Recommended (3 checkpoints)
- 13+ user stories ‚Üí Mandatory (4+ checkpoints)
- >1500 LOC ‚Üí Recommended
- >8 hours estimated ‚Üí Recommended

**Checkpoint Structure** (Example: SD with 12 US):
- **Checkpoint 1**: US-001 to US-004 (Component creation, 2-3 hours)
- **Checkpoint 2**: US-005 to US-008 (Feature implementation, 2-3 hours)
- **Checkpoint 3**: US-009 to US-012 (Testing + docs, 2-3 hours)

**Benefits**:
- 30-40% reduction in context consumption
- 50% faster debugging (smaller change sets)
- Incremental progress visibility
- Pause/resume flexibility

**Complete Guide**: `docs/reference/checkpoint-pattern.md` (150 lines)

**Evidence**: SD-SETTINGS-2025-10-12 analysis - Would have reduced context from 85K to 60K tokens
**Impact**: Saves 2-4 hours per large SD through early error detection

## Session Continuation Best Practices

## üîÑ Session Continuation Best Practices

**Problem**: Context limits require session handoffs, risking progress loss
**Solution**: Proven patterns from successful SD continuation

### Quick Reference

**Before Ending Session**:
1. Update TodoWrite with current task marked "in_progress"
2. Document exact resume point (file, line, next step)
3. Create checkpoint commit if mid-implementation
4. Report context health (usage %, status, recommendation)

**When Resuming**:
1. Read continuation summary
2. Verify application state: `cd /path && pwd`, `git status`
3. Read current files mentioned in summary
4. Check build status: `npm run type-check && npm run lint`
5. Confirm resume point with user

**Key Patterns**:
- **Comprehensive Summary**: 9 sections (request, concepts, files, errors, solutions, messages, tasks, current work, next step)
- **Todo Maintenance**: Update after EACH milestone, not in batches
- **Incremental Implementation**: One component at a time with verification
- **Pre-Verification Checklist**: App check, GitHub remote, URL, component path

**Complete Guide**: `docs/reference/claude-code-session-continuation.md` (100 lines)

**Evidence**: SD-SETTINGS-2025-10-12 - Zero "wrong directory" errors, seamless continuation
**Impact**: 90% reduction in resume confusion, 95% accuracy in state reconstruction

## Parallel Execution Optimization

## ‚ö° Parallel Execution Optimization

**Problem**: Sequential execution wastes time when operations are independent
**Solution**: Guidelines for safe parallel tool execution

### Quick Reference

**Safe for Parallel** ‚úÖ:
- Reading multiple independent files
- Multiple read-only Git commands (`git status`, `git log`, `git remote -v`)
- Database queries from different tables (read-only)
- Sub-agent execution (independent assessments)

**NOT Safe for Parallel** ‚ùå:
- Write operations (Edit, Write tools)
- Database mutations (INSERT, UPDATE, DELETE)
- Sequential dependencies (build before test)
- Git operations that modify state

**Time Savings Examples**:
- File reading: 2-3s saved per file after first (parallel vs sequential)
- Line count: 3-6s saved (`wc -l file1 file2 file3` vs 3 separate commands)
- Sub-agents: 1-2 min saved (4 sub-agents in 30s vs 2min sequential)

**Decision Rule**:
- Independent operations + >2s saved + <30K combined output ‚Üí Use parallel
- Any dependencies or order requirements ‚Üí Use sequential

**Complete Guide**: `docs/reference/parallel-execution-opportunities.md` (80 lines)

**Evidence**: SD-SETTINGS-2025-10-12 - Identified missed opportunities (6-9s in file reads)
**Impact**: 2-5 min saved per SD through parallelization

## Progressive Testing Strategy

## üß™ Progressive Testing Strategy

**Problem**: End-of-phase testing causes late discovery of errors
**Solution**: Test after each user story or major component

### Quick Reference

**After Each User Story**:
```bash
vitest run --no-coverage --grep="US-001"  # Quick validation
```

**After Each Component**:
```bash
npm run type-check  # TypeScript validation
npm run lint        # Code quality check
npm run build:skip-checks  # Build validation
```

**Before EXEC‚ÜíPLAN Handoff**:
```bash
npm run test:unit   # Full unit suite
npm run test:e2e    # Full E2E suite
```

**Benefits**:
- Early error detection (smaller blast radius)
- Faster feedback loop
- Less context consumed by debugging
- Can proceed with partial completion if blocked

**Testing Decision Matrix**:
| Scenario | Command | Timeout | When |
|----------|---------|---------|------|
| Quick validation | `vitest --no-coverage` | 60s | After each component |
| Smoke tests | `vitest --grep="US-"` | 90s | Handoff requirement |
| Full suite | `npm run test:unit` | 120s | PLAN verification |

**Complete Guide**: See `docs/reference/test-timeout-handling.md` (Section: Progressive Testing)

**Evidence**: Pattern from successful SDs - Early testing catches 80% of issues before handoff
**Impact**: 50% reduction in late-stage debugging time

## Database Agent Error-Triggered Invocation

## üö® Database Agent Error-Triggered Invocation

**Problem**: Agents attempt workarounds when encountering database errors instead of using database agent
**Solution**: Immediate database agent invocation on ANY database error

### Error Patterns That MUST Trigger Database Agent

**PostgreSQL Errors** (immediate database agent call):
- `column "X" does not exist` ‚Üí Database agent (schema validation)
- `relation "X" does not exist` ‚Üí Database agent (table validation)
- `table "X" already exists` ‚Üí Database agent (migration conflict)
- `foreign key constraint` errors ‚Üí Database agent (relationship validation)
- `permission denied for table` ‚Üí Database agent (RLS policy issue)
- `syntax error at or near` (in SQL) ‚Üí Database agent (SQL validation)
- `trigger function` errors ‚Üí Database agent (function schema mismatch)
- `duplicate key value violates unique constraint` ‚Üí Database agent (data/schema issue)

**Supabase-Specific Errors**:
- RLS policy failures ‚Üí Database agent (security architecture)
- Connection string issues ‚Üí Database agent (connection helper)
- Cross-schema foreign key warnings ‚Üí Database agent (architecture violation)
- `row level security` errors ‚Üí Database agent (policy design)

**Migration Errors**:
- ANY migration file execution failure ‚Üí Database agent (don't retry manually)
- `CREATE TABLE IF NOT EXISTS` silent failures ‚Üí Database agent (conflict detection)
- Schema version mismatches ‚Üí Database agent (version management)

### Error Response Protocol

**When ANY database error occurs**:

‚ùå **DO NOT**:
- Attempt manual fixes
- Try workarounds
- Modify SQL without validation
- Skip table/column verification
- Use trial-and-error debugging

‚úÖ **DO IMMEDIATELY**:
1. STOP current approach
2. Document the exact error message
3. Invoke database agent:
   ```bash
   node lib/sub-agent-executor.js DATABASE <SD-ID>
   ```
4. Provide error context to database agent
5. Implement database agent's solution

**Pattern**: Database error detected ‚Üí Invoke database agent ‚Üí Wait for diagnosis ‚Üí Implement solution

**Evidence**: 74 retrospectives analyzed, 3 failure patterns from workaround attempts
**Impact**: Eliminates technical debt from band-aid solutions, saves 2-4 hours per database issue

## Database Workaround Anti-Patterns (NEVER DO THIS)

## ‚õî Database Workaround Anti-Patterns (NEVER DO THIS)

**Problem**: Common workarounds create technical debt and mask root causes
**Solution**: Block these patterns, use database agent instead

### Anti-Pattern Catalog

**‚ùå Anti-Pattern 1: Table Rename Workarounds**
```sql
-- WRONG: Renaming table to avoid conflict
CREATE TABLE webhook_events_new ...

-- RIGHT: Use database agent to diagnose why table exists
node lib/sub-agent-executor.js DATABASE <SD-ID>
```

**‚ùå Anti-Pattern 2: Column Existence Guards**
```sql
-- WRONG: Adding columns conditionally without knowing schema
ALTER TABLE ... ADD COLUMN IF NOT EXISTS ...

-- RIGHT: Database agent validates schema FIRST
```

**‚ùå Anti-Pattern 3: RLS Policy Bypassing**
```typescript
// WRONG: Using service role key to bypass RLS
const supabase = createClient(url, SERVICE_ROLE_KEY)

// RIGHT: Database agent designs proper RLS policies
```

**‚ùå Anti-Pattern 4: Manual SQL Trial-and-Error**
```bash
# WRONG: Trying different SQL variations manually
psql -c "CREATE TABLE ..." # fails
psql -c "CREATE TABLE IF NOT EXISTS ..." # fails
psql -c "DROP TABLE ... CASCADE; CREATE TABLE ..." # dangerous

# RIGHT: Database agent analyzes schema state FIRST
```

**‚ùå Anti-Pattern 5: Skipping Migration Validation**
```javascript
// WRONG: Executing migration without validation
await executeMigration(sql) // Hope it works

// RIGHT: Database agent validates migration safety
```

**‚ùå Anti-Pattern 6: Connection String Trial-and-Error**
```javascript
// WRONG: Trying different regions/ports/SSL configs
postgresql://postgres.PROJECT:PASSWORD@aws-0... // fails
postgresql://postgres.PROJECT:PASSWORD@aws-1... // try this?

// RIGHT: Database agent provides correct connection pattern
// Uses: scripts/lib/supabase-connection.js
```

**‚ùå Anti-Pattern 7: Ignoring Schema Conflicts**
```javascript
// WRONG: Proceeding despite "table exists" warnings
// "It says it already exists, let me just use it"

// RIGHT: Database agent investigates conflict and validates schema match
```

### Detection Rules

**BLOCKED PATTERNS** (must use database agent instead):
- Renaming tables to avoid conflicts
- Adding IF NOT EXISTS without schema knowledge
- Using SERVICE_ROLE_KEY to bypass RLS
- Trial-and-error with connection strings
- Multiple psql attempts without diagnosis
- Modifying migrations after first failure
- Proceeding with "table exists" warnings without validation

**Evidence**: SD-AGENT-ADMIN-003 (schema mismatch), SD-1A (multiple schema issues), SD-041C (table conflict)
**Impact**: Prevents 100% of workaround-related technical debt

## Database Agent First-Responder Checklist

## ‚úÖ Database Agent First-Responder Checklist

**Problem**: Database work attempted without validation, leading to errors
**Solution**: Proactive database agent invocation BEFORE attempting database work

### BEFORE Attempting ANY Database Work

**Pre-Database-Work Checklist** (MANDATORY):

**Before PLANNING database work**:
- [ ] Invoke database agent for schema review
- [ ] Verify tables mentioned in PRD exist
- [ ] Check for naming conflicts (existing tables)
- [ ] Validate RLS policy requirements
- [ ] Confirm correct database target (EHG vs EHG_Engineer)

**Before EXECUTING database migrations**:
- [ ] Database agent validated migration file
- [ ] Schema conflicts identified and resolved
- [ ] Connection helper pattern confirmed (`scripts/lib/supabase-connection.js`)
- [ ] Rollback plan documented
- [ ] Test environment validated

**Before WRITING database queries**:
- [ ] Database agent confirmed table schema
- [ ] Column names verified (not assumed)
- [ ] RLS policies understood
- [ ] Query performance considerations reviewed

**When in doubt**: ALWAYS invoke database agent FIRST

### Integration Points

**PLAN Phase (PRD Creation)**:
```markdown
## PLAN Pre-EXEC Checklist (ENHANCED)

### Database Dependencies ‚úÖ
- [ ] **FIRST**: Invoke database agent for schema validation
- [ ] Identify all data dependencies in PRD
- [ ] Verify tables/columns exist OR create migration plan
- [ ] Document database agent findings in PLAN‚ÜíEXEC handoff
- [ ] If ANY issues found: Escalate to LEAD with database agent report
```

**EXEC Phase (Implementation)**:
```markdown
## EXEC Pre-Implementation Checklist (NEW)

### Database Operations ‚úÖ
- [ ] If SD involves database work: Database agent invoked? YES/NO
- [ ] Schema validation complete: YES/NO
- [ ] Migration safety confirmed: YES/NO
- [ ] Connection pattern verified: YES/NO
- [ ] RLS policies designed: YES/NO (if needed)
```

**Success Pattern Examples**:
- SD-041C: Database agent identified table conflict early, proper rename implemented
- SD-BACKEND-002C: Database agent provided migration pattern, 45-minute execution success
- SD-AGENT-ADMIN-003: Database agent caught trigger function schema mismatch before deployment

**Evidence**: 12 success patterns from proactive database agent usage
**Impact**: Zero schema conflicts, 100% migration success rate when database agent used first

## Database Agent Integration Requirements

## üîß Database Agent Integration Requirements

**Problem**: Database agent treated as last resort instead of first responder
**Solution**: Mandatory integration at key workflow checkpoints

### Mandatory Invocation Points

**LEAD Pre-Approval Phase**:
- IF SD mentions: database, migration, schema, table, RLS, SQL, Postgres
- THEN: Database agent included in parallel sub-agent execution
- ```bash
  node lib/sub-agent-executor.js DATABASE <SD-ID>
  ```

**PLAN PRD Creation Phase**:
- Database agent runs FIRST for any SD with data dependencies
- Validates schema before creating PRD
- Documents table existence, RLS requirements, migration needs
- BLOCKS PRD creation if critical database issues found

**EXEC Implementation Phase**:
- Database agent validates schema BEFORE implementation starts
- Consulted for ANY database error encountered
- Provides migration patterns and connection helpers
- Reviews database changes before commit

**PLAN Verification Phase**:
- Database agent verifies migrations executed correctly
- Validates schema matches documentation
- Confirms RLS policies working as designed

### Behavior Change Summary

**Before (Anti-Pattern)**:
1. Agent encounters database error
2. Agent tries manual fix / workaround
3. Fix fails or creates technical debt
4. User intervenes: "Use database agent!"
5. Database agent called
6. Proper solution found (finally)

**After (First-Responder Pattern)**:
1. Agent encounters database task OR database error
2. Agent IMMEDIATELY invokes database agent
3. Database agent diagnoses root cause
4. Proper solution implemented (first try)
5. No workarounds, no technical debt

### Success Metrics

- **Zero workaround attempts** when database errors occur
- **100% database agent usage** for migration work
- **90% reduction** in user reminders to use database agent
- **Zero schema mismatch errors** through proactive validation
- **Faster database operations** (no trial-and-error)

### Key Principle

**DATABASE-FIRST CULTURE**: Database agent is a FIRST RESPONDER, not a LAST RESORT.

**Evidence**: User feedback: "I constantly have to remind that we should use the database subagent"
**Impact**: Eliminates need for manual reminders, establishes proactive database expertise

## Validation Agent Mandatory Gates

## üõ°Ô∏è Validation Agent Mandatory Gates

**Problem**: Validation skipped or deferred, causing late-stage rework (4-6 hours per SD)
**Solution**: Mandatory validation gates at key workflow checkpoints with blocking enforcement

### Four Mandatory Validation Gates

**GATE 1: LEAD Pre-Approval** (BLOCKING)
- [ ] **Duplicate Check**: Does this already exist in codebase?
- [ ] **Infrastructure Check**: Can we reuse existing components/patterns?
- [ ] **Backlog Validation**: Are user requirements documented? (‚â•1 backlog item required)
- [ ] **Claims Verification**: For UI/UX SDs, verify issues actually exist (code review)

**Command**:
```bash
node scripts/systems-analyst-codebase-audit.js <SD-ID>
# OR via orchestration
node scripts/orchestrate-phase-subagents.js LEAD_PRE_APPROVAL <SD-ID>
```

**Blocks**: Cannot mark SD as 'active' until validation passes
**Evidence**: SD-EXPORT-001 approved with 0 backlog items ‚Üí scope creep risk

---

**GATE 2: PLAN PRD Creation** (BLOCKING)
- [ ] **Schema Validation**: Do tables exist? Any conflicts?
- [ ] **Route Validation**: Are routes available? Any conflicts?
- [ ] **Test Infrastructure Validation**: Is test environment ready?
- [ ] **Form Validation**: Are validation attributes needed for forms?
- [ ] **Build Validation**: Do dependencies exist? Can project build?

**Command**:
```bash
node lib/sub-agent-executor.js VALIDATION <SD-ID>
```

**Blocks**: Cannot create PLAN‚ÜíEXEC handoff until validation passes
**Evidence**: SD-AGENT-ADMIN-002 - Missing pre-flight checks caused test failures

---

**GATE 3: EXEC Pre-Implementation** (BLOCKING)
- [ ] **Application Verification**: Correct app? (`/mnt/c/_EHG/ehg/` vs `/mnt/c/_EHG/EHG_Engineer/`)
- [ ] **Build Validation**: Does `npm run build` succeed?
- [ ] **Environment Validation**: Correct database connection?
- [ ] **Protocol Compliance**: Following LEO 5-phase workflow?
- [ ] **Dependencies Validation**: All `npm install` complete?

**Command**:
```bash
# Automated during EXEC pre-implementation checklist
npm run type-check && npm run build:skip-checks
```

**Blocks**: Cannot start implementation until environment validated
**Evidence**: Multiple "wrong directory" errors before pre-verification checklist

---

**GATE 4: PLAN Verification** (BLOCKING)
- [ ] **Handoff Completeness**: All 7 handoff elements present?
- [ ] **Test Validation**: Unit tests AND E2E tests both passing?
- [ ] **Documentation Validation**: Generated docs exist?
- [ ] **Protocol Compliance**: All phases followed correctly?
- [ ] **CI/CD Validation**: GitHub Actions green?

**Command**:
```bash
node scripts/orchestrate-phase-subagents.js PLAN_VERIFY <SD-ID>
```

**Blocks**: Cannot create PLAN‚ÜíLEAD handoff until validation passes
**Evidence**: SD-EVA-MEETING-001 - No user story validation enforcement

---

### Enforcement Mechanism

**Database Constraint Example**:
```sql
-- Cannot mark SD active without backlog items
ALTER TABLE strategic_directives_v2
ADD CONSTRAINT require_backlog_for_active
CHECK (status != 'active' OR (
  SELECT COUNT(*) FROM sd_backlog_map WHERE sd_id = id
) > 0);
```

**Auto-Trigger Pattern**:
- Phase transition detected ‚Üí Validation agent runs automatically
- Validation fails ‚Üí Progress BLOCKED, escalate to LEAD
- Validation passes ‚Üí Proceed to next phase

**Manual Override** (Last Resort):
- Requires LEAD approval
- Must document justification
- Creates technical debt ticket

**Evidence**: 74 retrospectives, 12 improvement areas where validation missing
**Impact**: Prevents 4-6 hours rework per SD through early validation

## Validation Enforcement Patterns

## üîí Validation Enforcement Patterns

**Problem**: Validation is optional, can be bypassed, leading to late discovery
**Solution**: Automated enforcement mechanisms that BLOCK progress on validation failures

### Three Enforcement Layers

**Layer 1: Database Constraints** (Cannot Bypass)
```sql
-- Example 1: Require backlog items before active status
ALTER TABLE strategic_directives_v2
ADD CONSTRAINT require_backlog_for_active
CHECK (status != 'active' OR EXISTS (
  SELECT 1 FROM sd_backlog_map WHERE sd_id = strategic_directives_v2.id
));

-- Example 2: Require PRD before implementation
ALTER TABLE strategic_directives_v2
ADD CONSTRAINT require_prd_before_implementation
CHECK (status NOT IN ('in_progress', 'completed') OR EXISTS (
  SELECT 1 FROM product_requirements_v2 WHERE strategic_directive_id = strategic_directives_v2.id
));

-- Example 3: Require retrospective before completion
ALTER TABLE strategic_directives_v2
ADD CONSTRAINT require_retrospective_for_completion
CHECK (status != 'completed' OR EXISTS (
  SELECT 1 FROM retrospectives WHERE sd_id = strategic_directives_v2.id
));
```

**Benefit**: Database prevents invalid state transitions, no workarounds possible

---

**Layer 2: Auto-Trigger Validation** (Automatic Execution)

**Phase Transition Triggers**:
```javascript
// Example: When SD status changes to 'active'
CREATE TRIGGER validate_on_active
BEFORE UPDATE ON strategic_directives_v2
FOR EACH ROW
WHEN (OLD.status != 'active' AND NEW.status = 'active')
EXECUTE FUNCTION run_lead_pre_approval_validation();

// Function executes validation agent automatically
CREATE FUNCTION run_lead_pre_approval_validation()
RETURNS TRIGGER AS $$
BEGIN
  -- Check backlog exists
  IF NOT EXISTS (SELECT 1 FROM sd_backlog_map WHERE sd_id = NEW.id) THEN
    RAISE EXCEPTION 'Cannot activate SD: No backlog items found. Add requirements first.';
  END IF;

  -- Log validation execution
  INSERT INTO sub_agent_execution_results (sd_id, sub_agent_code, verdict)
  VALUES (NEW.id, 'VALIDATION', 'PASS');

  RETURN NEW;
END;
$$ LANGUAGE plpgsql;
```

**Benefit**: Validation runs automatically, humans don't need to remember

---

**Layer 3: Script-Level Gate Blocking** (Orchestration)

**Handoff Creation Scripts**:
```javascript
// Example: scripts/unified-handoff-system.js

async function createHandoff(type, sd_id) {
  // MANDATORY: Run validation before creating handoff
  if (type === 'PLAN-to-EXEC') {
    console.log('Running schema validation before handoff...');
    const validation = await executeSubAgent('VALIDATION', sd_id);

    if (validation.verdict !== 'PASS') {
      console.error('‚ùå BLOCKED: Schema validation failed');
      console.error('Issues:', validation.issues);
      console.error('Cannot create PLAN‚ÜíEXEC handoff until resolved');
      process.exit(1); // BLOCK
    }
  }

  // Validation passed, proceed with handoff creation
  await createHandoffRecord(type, sd_id);
}
```

**Benefit**: Scripts enforce validation at key integration points

---

### Validation Failure Response Protocol

**When Validation Fails**:

1. **STOP**: Do not proceed with current action
2. **LOG**: Record validation failure in `sub_agent_execution_results`
3. **NOTIFY**: Alert user with specific failure details
4. **DOCUMENT**: Create issue in tracking system
5. **ESCALATE**: If critical, escalate to LEAD for decision

**Example Failure Message**:
```
‚ùå VALIDATION FAILED: Cannot mark SD-EXPORT-001 as active

Reason: No backlog items found
Expected: ‚â•1 backlog item documenting user requirements
Found: 0 backlog items

Action Required:
1. Review SD scope and identify user requirements
2. Add backlog items to sd_backlog_map table
3. Retry status change

Validation Agent: node scripts/systems-analyst-codebase-audit.js SD-EXPORT-001
```

---

### Manual Override Process (Exception Handling)

**When Override Needed**:
- Exceptional circumstances only
- Infrastructure/protocol SDs where normal rules don't apply
- Emergency production fixes

**Override Steps**:
1. Document justification in SD description
2. Get LEAD approval (recorded in comments)
3. Create technical debt ticket
4. Add to retrospective for pattern review

**Override Example**:
```sql
-- Temporarily disable constraint for infrastructure SD
ALTER TABLE strategic_directives_v2 DISABLE TRIGGER validate_on_active;

-- Perform operation
UPDATE strategic_directives_v2 SET status = 'active' WHERE id = 'SD-INFRA-001';

-- Re-enable constraint (MANDATORY)
ALTER TABLE strategic_directives_v2 ENABLE TRIGGER validate_on_active;

-- Document override
INSERT INTO sd_comments (sd_id, comment_type, content)
VALUES ('SD-INFRA-001', 'override', 'Manual override: Infrastructure SD, no user-facing requirements');
```

**Caution**: Overrides create precedent. Use sparingly, document thoroughly.

---

### Success Metrics

**From Validation Enforcement**:
- **Zero SDs approved without backlog** (constraint prevents it)
- **100% duplicate check rate** (auto-trigger on status change)
- **50% reduction in late-stage rework** (caught at gates)
- **4-6 hours saved per SD** (early validation vs late discovery)

**Evidence**: SD-EXPORT-001 had 0 backlog items, proceeded anyway ‚Üí scope creep risk
**Solution**: Database constraint would have BLOCKED this
**Impact**: Prevents moving forward without requirements

## Validation Agent Proactive Invocation Checklist

## ‚úÖ Validation Agent Proactive Invocation Checklist

**Problem**: Validation remembered only after problems discovered
**Solution**: Comprehensive checklist for each phase with MANDATORY items

### LEAD Phase Checklist (Pre-Approval)

**Before Approving ANY SD** (MANDATORY):

**Duplicate Check** ‚úÖ:
```bash
# Search for existing implementations
node scripts/systems-analyst-codebase-audit.js <SD-ID>

# Manual verification if needed
grep -r "feature name" /mnt/c/_EHG/ehg/src
find /mnt/c/_EHG/ehg/src -name "*ComponentName*"
```

**Infrastructure Check** ‚úÖ:
- [ ] Similar feature exists? (can reuse 8-10 hours saved)
- [ ] Existing auth patterns? (Supabase Auth vs custom)
- [ ] Existing database patterns? (tables, migrations, RLS)
- [ ] Existing UI components? (shadcn, shared components)

**Backlog Validation** ‚úÖ:
```sql
-- Check backlog items exist
SELECT COUNT(*) FROM sd_backlog_map WHERE sd_id = 'SD-XXX';
-- Must be > 0 before marking active
```

**Claims Verification** ‚úÖ (For UI/UX SDs):
```bash
# Read actual source code, don't trust claims
# Example from SD-UAT-002: 3/5 claimed issues didn't exist
grep -A 10 -B 10 "claimed issue" /mnt/c/_EHG/ehg/src/component.tsx
```

**Evidence**: SD-UAT-002 - Code review saved 3-4 hours by rejecting false claims

---

### PLAN Phase Checklist (PRD Creation)

**Before Creating PRD** (MANDATORY):

**Schema Validation** ‚úÖ:
```bash
# If PRD mentions tables/columns, validate they exist
node lib/sub-agent-executor.js DATABASE <SD-ID>

# Or query directly
node -e "
const { createDatabaseClient } = require('./scripts/lib/supabase-connection.js');
(async () => {
  const client = await createDatabaseClient('ehg');
  const { rows } = await client.query(\"SELECT tablename FROM pg_tables WHERE schemaname = 'public' AND tablename LIKE '%keyword%'\");
  console.log('Tables found:', rows.length);
})();
"
```

**Route Validation** ‚úÖ:
- [ ] Routes mentioned in PRD exist in routing config?
- [ ] No conflicts with existing routes?
- [ ] Authentication requirements clear?

**Test Infrastructure Validation** ‚úÖ:
```bash
# Verify test environment ready
npm run test:unit --version
npm run test:e2e -- --version

# Check test databases accessible
node -e "require('dotenv').config(); console.log('Test DB:', process.env.TEST_DATABASE_URL ? 'Configured' : 'Missing');"
```

**Form Validation** ‚úÖ (If forms involved):
- [ ] Validation rules documented in PRD?
- [ ] Required vs optional fields clear?
- [ ] Error message patterns defined?

**Build Validation** ‚úÖ:
```bash
# Ensure project builds before implementation starts
npm run type-check
npm run lint
npm run build:skip-checks
```

**Evidence**: SD-AGENT-ADMIN-002 - Missing pre-flight checks caused test failures

---

### EXEC Phase Checklist (Pre-Implementation)

**Before Writing ANY Code** (MANDATORY):

**Application Verification** ‚úÖ:
```bash
# Confirm correct application
cd /mnt/c/_EHG/ehg && pwd
# Expected: /mnt/c/_EHG/ehg (NOT EHG_Engineer!)

# Confirm correct repository
git remote -v
# Expected: origin  https://github.com/rickfelix/ehg.git
```

**Build Validation** ‚úÖ:
```bash
# Verify build works before making changes
npm run build:skip-checks
# If fails: Fix build issues before implementing new features
```

**Environment Validation** ‚úÖ:
```bash
# Verify database connection
node -e "
const { createClient } = require('@supabase/supabase-js');
require('dotenv').config();
const supabase = createClient(process.env.EHG_SUPABASE_URL, process.env.EHG_SUPABASE_ANON_KEY);
supabase.from('users').select('count').limit(1).then(r => console.log('DB:', r.error ? 'FAIL' : 'OK'));
"

# Verify dev server port available
lsof -i :5173 || echo "Port 5173 available"
```

**Protocol Compliance** ‚úÖ:
- [ ] Following LEO 5-phase workflow?
- [ ] PLAN‚ÜíEXEC handoff reviewed?
- [ ] PRD requirements understood?
- [ ] User stories mapped to tests?

**Dependencies Validation** ‚úÖ:
```bash
# Verify node_modules up to date
npm ci  # Use ci for clean install
npm audit  # Check for vulnerabilities
```

**Evidence**: Pre-verification checklist eliminated "wrong directory" errors

---

### PLAN Verification Phase Checklist

**Before Creating PLAN‚ÜíLEAD Handoff** (MANDATORY):

**Handoff Completeness** ‚úÖ:
- [ ] All 7 handoff elements present?
  1. Executive Summary
  2. Completeness Report
  3. Deliverables Manifest
  4. Key Decisions & Rationale
  5. Known Issues & Risks
  6. Resource Utilization
  7. Action Items for Receiver

**Test Validation** ‚úÖ:
```bash
# Both test types MANDATORY
npm run test:unit  # Business logic
npm run test:e2e   # User flows

# Verify 100% user story coverage
# Every US-XXX must have ‚â•1 E2E test
```

**Documentation Validation** ‚úÖ:
```bash
# Check generated documentation exists
ls -la generated_docs/<SD-ID>-*.md
# If missing: Run documentation generator
```

**Protocol Compliance** ‚úÖ:
- [ ] All phases completed in order?
- [ ] All sub-agents executed?
- [ ] All handoffs created?

**CI/CD Validation** ‚úÖ:
```bash
# Verify GitHub Actions green
gh run list --limit 5
gh run view <run-id>  # If any failed
```

**Evidence**: SD-EVA-MEETING-001 - No user story validation enforcement led to mismatches

---

### Quick Reference

| Phase | Validation Type | Command | Blocking? |
|-------|----------------|---------|-----------|
| LEAD | Duplicate Check | `systems-analyst-codebase-audit.js` | ‚úÖ YES |
| LEAD | Backlog Validation | `SELECT COUNT FROM sd_backlog_map` | ‚úÖ YES |
| PLAN | Schema Validation | `sub-agent-executor.js DATABASE` | ‚úÖ YES |
| PLAN | Build Validation | `npm run build:skip-checks` | ‚úÖ YES |
| EXEC | App Verification | `pwd && git remote -v` | ‚úÖ YES |
| PLAN | Test Validation | `npm run test:unit && test:e2e` | ‚úÖ YES |

**Remember**: Validation is MANDATORY, not optional. Gates BLOCK progress on failures.

## Validation Failure Patterns to Avoid

## ‚ö†Ô∏è Validation Failure Patterns to Avoid

**Problem**: Common anti-patterns where validation skipped or ignored
**Solution**: Recognize these patterns and invoke validation agent instead

### Anti-Pattern 1: "We'll Validate Later"

**What It Looks Like**:
```
LEAD: "Let's approve the SD, we can check for duplicates during PLAN phase"
PLAN: "Let's create the PRD, we can validate schema during EXEC"
EXEC: "Let's implement, we can validate during testing"
PLAN Verify: "Tests failing, now discovering issues that should have been caught earlier"
```

**Why It's Wrong**:
- Validation delayed = issues discovered late
- 4-6 hours rework required
- Scope creep risk increases
- Technical debt accumulates

**Right Approach**:
```
LEAD: "Before approval, let's run validation agent"
‚Üí node scripts/systems-analyst-codebase-audit.js <SD-ID>
‚Üí Discover duplicate implementation exists
‚Üí Reject SD or pivot to enhancement of existing feature
‚Üí 8-10 hours saved
```

**Evidence**: SD-UAT-020 - Discovered existing Supabase Auth during implementation, should have caught during LEAD approval

---

### Anti-Pattern 2: "Assume It Doesn't Exist"

**What It Looks Like**:
```
User: "We need authentication for this feature"
Agent: "I'll build a custom auth system"
[2 days later]
User: "Why didn't you use existing Supabase Auth?"
Agent: "I didn't know it existed"
```

**Why It's Wrong**:
- Duplicates existing functionality
- Wastes 8-10 hours
- Creates maintenance burden (two auth systems)
- Increases security risk (custom auth = more vulnerabilities)

**Right Approach**:
```bash
# BEFORE designing solution, search for existing
node scripts/systems-analyst-codebase-audit.js <SD-ID>

# Manual search if needed
grep -r "authentication|auth|login" /mnt/c/_EHG/ehg/src
find /mnt/c/_EHG/ehg/src -name "*auth*"

# Check both applications
grep -r "authentication" /mnt/c/_EHG/EHG_Engineer/src
```

**Evidence**: SD-UAT-020 retrospective explicitly mentions this pattern

---

### Anti-Pattern 3: "Approve Without Backlog"

**What It Looks Like**:
```sql
-- SD marked as 'active'
SELECT * FROM strategic_directives_v2 WHERE id = 'SD-EXPORT-001';
-- status: active

-- Check backlog items
SELECT COUNT(*) FROM sd_backlog_map WHERE sd_id = 'SD-EXPORT-001';
-- Result: 0

-- Risk: Moving forward without user requirements = scope creep
```

**Why It's Wrong**:
- No documented user requirements
- Implementation based on assumptions
- Scope creep highly likely
- Cannot validate against actual needs

**Right Approach**:
```sql
-- Database constraint prevents this
ALTER TABLE strategic_directives_v2
ADD CONSTRAINT require_backlog_for_active
CHECK (status != 'active' OR EXISTS (
  SELECT 1 FROM sd_backlog_map WHERE sd_id = strategic_directives_v2.id
));

-- Now attempting to mark active without backlog:
UPDATE strategic_directives_v2 SET status = 'active' WHERE id = 'SD-XXX';
-- ERROR: new row violates check constraint "require_backlog_for_active"
-- BLOCKED until backlog items added
```

**Evidence**: SD-EXPORT-001 had 0 backlog items when approved (failure pattern)

---

### Anti-Pattern 4: "Trust Claims Without Verification"

**What It Looks Like**:
```
SD Description: "Dashboard has 5 critical UI issues:
1. Issue A (doesn't work)
2. Issue B (broken)
3. Issue C (missing feature)
4. Issue D (wrong behavior)
5. Issue E (performance problem)"

LEAD: "Sounds reasonable, approved"

[EXEC reads actual code]
EXEC: "Issues A, C, E don't exist in the code. Only B and D are real."
```

**Why It's Wrong**:
- 3/5 claims false = 60% wasted effort
- Implementation addresses non-existent issues
- Real issues might be missed
- 3-4 hours wasted on unnecessary work

**Right Approach**:
```bash
# LEAD code review for UI/UX SDs (MANDATORY)
# Read actual source code
cat /mnt/c/_EHG/ehg/src/components/Dashboard.tsx | grep -A 10 "Issue A description"

# Verify each claim
for issue in A B C D E; do
  echo "Verifying Issue $issue:"
  grep -n "relevant code pattern" /path/to/component.tsx
done
```

**Evidence**: SD-UAT-002 - LEAD code review rejected 3/5 false claims, saved 3-4 hours

---

### Anti-Pattern 5: "Skip Test Environment Validation"

**What It Looks Like**:
```bash
# EXEC starts implementation
npm run test:unit
# Error: Test database not configured

# Or
npm run test:e2e
# Error: Playwright not installed

# Or
npm run build
# Error: Missing dependency
```

**Why It's Wrong**:
- Discovers environment issues during implementation
- Blocks progress unexpectedly
- Wastes time troubleshooting environment
- Should have been caught during PLAN phase

**Right Approach**:
```bash
# PLAN phase pre-flight checks (MANDATORY)

# Check test databases
node -e "require('dotenv').config(); console.log('Unit Test DB:', process.env.TEST_DATABASE_URL ? 'OK' : 'MISSING');"

# Check test frameworks
npm run test:unit -- --version || echo "Unit tests not configured"
npm run test:e2e -- --version || echo "E2E tests not configured"

# Check build
npm run build:skip-checks || echo "Build fails, fix before EXEC"

# BLOCK PLAN‚ÜíEXEC handoff if any fail
```

**Evidence**: SD-AGENT-ADMIN-002 - Missing pre-flight checks caused test failures

---

### Anti-Pattern 6: "No User Story Validation"

**What It Looks Like**:
```
PRD: "12 user stories defined"

[EXEC implements features]

PLAN Verify: "Running E2E tests"
E2E Tests: "0 tests found matching user story pattern"

Issue: User stories not mapped to tests
Result: Cannot verify implementation meets requirements
```

**Why It's Wrong**:
- User stories disconnected from tests
- Cannot prove requirements met
- Manual verification required (time-consuming)
- Acceptance criteria unclear

**Right Approach**:
```bash
# PLAN phase validation (MANDATORY)
# Check user story ‚Üí E2E test mapping

# Query user stories
node -e "
const { createClient } = require('@supabase/supabase-js');
const supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_ANON_KEY);
supabase.from('user_stories').select('id').eq('strategic_directive_id', 'SD-XXX')
  .then(r => console.log('User stories:', r.data.length));
"

# Check E2E tests
grep -r "US-[0-9]\+" /mnt/c/_EHG/ehg/tests/e2e/*.spec.ts | wc -l

# Validate 100% coverage
# Every user story MUST have ‚â•1 E2E test
```

**Evidence**: SD-EVA-MEETING-001 - No enforcement of user story validation

---

### Detection Rules

**If you see these patterns, STOP and validate**:

1. **"Let's skip validation for now"** ‚Üí NO, validate immediately
2. **"I'll search for duplicates later"** ‚Üí NO, search now
3. **"We can add backlog items later"** ‚Üí NO, add before approval
4. **"Claims sound reasonable"** ‚Üí NO, verify with code review
5. **"Environment probably works"** ‚Üí NO, validate pre-flight
6. **"Tests cover the features"** ‚Üí NO, verify US-XXX mapping
7. **"Schema probably exists"** ‚Üí NO, query database to confirm

---

### Success Stories (When Validation Used Properly)

**Success 1: Early Duplicate Detection** (SD-UAT-020)
- Validation agent found existing Supabase Auth during LEAD approval
- Pivoted from "build custom auth" to "use existing"
- **8-10 hours saved**

**Success 2: Code Review Catches False Claims** (SD-UAT-002)
- LEAD code review validated 5 claimed UI issues
- Found 3/5 didn't exist in actual code
- Rejected false claims, focused on real issues
- **3-4 hours saved**

**Success 3: Three-Checkpoint Validation** (SD-EVA-MEETING-001)
- QA validation + Handoff validation + Auto-trigger
- Caught issues at multiple gates
- **Early error detection**

---

### Quick Reference

| Anti-Pattern | Right Approach | Evidence |
|--------------|---------------|----------|
| "Validate later" | Validate at gate | 4-6 hrs saved |
| "Assume doesn't exist" | Search first | 8-10 hrs saved (SD-UAT-020) |
| "Approve without backlog" | Enforce constraint | SD-EXPORT-001 failure |
| "Trust claims" | Code review | 3-4 hrs saved (SD-UAT-002) |
| "Skip environment check" | Pre-flight validation | SD-AGENT-ADMIN-002 |
| "No US validation" | 100% mapping | SD-EVA-MEETING-001 |

**Remember**: Validation failures are caught cheaply at gates, expensively during implementation.

## Mandatory Handoff Requirements

Every handoff MUST include these 7 elements:
(Loading from database...)

Missing ANY element = AUTOMATIC REJECTION

## üîÑ Unified Handoff System (Database-First)

**Unified Handoff System**: Database-first handoffs via `node scripts/unified-handoff-system.js execute <TYPE> <SD-ID>`

**Types**: LEAD-to-PLAN, PLAN-to-EXEC, EXEC-to-PLAN, PLAN-to-LEAD
**7 Mandatory Elements**: Executive Summary, Completeness Report, Deliverables Manifest, Key Decisions, Known Issues, Resource Utilization, Action Items
**Tables**: `leo_handoff_templates` (structure), `sd_phase_handoffs` (instances)

**Complete Guide**: See `docs/reference/unified-handoff-system.md`


## Sub-Agent System (Database-Driven)

**Active Sub-Agents**: 0 specialist agents for validation, testing, security, and quality

| Code | Name | Priority | Auto-Trigger |
|------|------|----------|--------------|


**Quick Reference**:
- **High Priority** (90+): DOCMON, GITHUB, UAT
- **Quality Gates** (70-85): RETRO, DESIGN
- **Validation** (0-10): SECURITY, DATABASE, TESTING, PERFORMANCE, VALIDATION

**Activation**: Sub-agents trigger automatically on keywords/events. Query `leo_sub_agent_triggers` for complete trigger list.

**Complete Documentation**: See `docs/reference/sub-agent-system.md` for full details, triggers, and activation patterns

### Handoff Templates

No templates in database

## Validation Rules (From Database)

No validation rules in database

## Database Schema Overview

### Core Tables
- `leo_protocols` - Protocol versions and content
- `leo_protocol_sections` - Modular protocol sections
- `leo_agents` - Agent definitions and percentages
- `leo_handoff_templates` - Standardized handoffs
- `leo_sub_agents` - Sub-agent definitions
- `leo_sub_agent_triggers` - Activation rules
- `leo_validation_rules` - Protocol validation

### Key Queries

**Get Current Protocol**:
```sql
SELECT * FROM leo_protocols WHERE status = 'active';
```

**Check Sub-Agent Triggers**:
```sql
SELECT sa.*, t.*
FROM leo_sub_agents sa
JOIN leo_sub_agent_triggers t ON sa.id = t.sub_agent_id
WHERE t.trigger_phrase ILIKE '%keyword%';
```

**Get Handoff Template**:
```sql
SELECT * FROM leo_handoff_templates
WHERE from_agent = 'EXEC' AND to_agent = 'PLAN';
```

## API Endpoints (Database-Backed)

- `GET /api/leo/current` - Current active protocol
- `GET /api/leo/agents` - All agents with percentages
- `GET /api/leo/sub-agents` - Active sub-agents with triggers
- `GET /api/leo/handoffs/:from/:to` - Handoff template
- `POST /api/leo/validate` - Validate against rules

## Key Scripts (Database-Aware)

- `get-latest-leo-protocol-from-db.js` - Get version from database
- `generate-claude-md-from-db.js` - Generate this file
- `migrate-leo-protocols-to-database.js` - Migration tool
- `activate-sub-agents-from-db.js` - Check database triggers

## Compliance Tools

All tools now query database instead of files:

### 1. Version Check
```bash
node scripts/get-latest-leo-protocol-from-db.js
```

### 2. Update CLAUDE.md
```bash
node scripts/generate-claude-md-from-db.js
```

### 3. Validate Handoff
```bash
node scripts/leo-checklist-db.js [agent-name]
```

## üîç PLAN Supervisor Verification

### Overview
PLAN agent now includes supervisor capabilities for final "done done" verification:
- Queries ALL sub-agents for their verification results
- Ensures all requirements are truly met
- Resolves conflicts between sub-agent reports
- Provides confidence scoring and clear pass/fail verdict

### Activation
Trigger PLAN supervisor verification via:
- **Command**: `/leo-verify [what to check]`
- **Script**: `node scripts/plan-supervisor-verification.js --prd PRD-ID`
- **Automatic**: When testing phase completes

### Verification Process
1. **Read-Only Access**: Queries existing sub-agent results (no re-execution)
2. **Summary-First**: Prevents context explosion with tiered reporting
3. **Conflict Resolution**: Priority-based rules (Security > Database > Testing)
4. **Circuit Breakers**: Graceful handling of sub-agent failures
5. **Maximum 3 Iterations**: Prevents infinite verification loops

### Verdicts
- **PASS**: All requirements met, high confidence (‚â•85%)
- **FAIL**: Critical issues or unmet requirements
- **CONDITIONAL_PASS**: Minor issues, needs LEAD review
- **ESCALATE**: Cannot reach consensus, needs LEAD intervention

## Dashboard Integration

Dashboard automatically connects to database:
- Real-time protocol updates via Supabase subscriptions
- Version detection from `leo_protocols` table
- Sub-agent status from `leo_sub_agents` table
- PLAN supervisor verification status
- No file scanning needed

## Important Notes

1. **Database is Source of Truth** - Files are deprecated
2. **Real-time Updates** - Changes reflect immediately
3. **No Version Conflicts** - Single active version enforced
4. **Audit Trail** - All changes tracked in database
5. **WebSocket Updates** - Dashboard stays synchronized
6. **PLAN Supervisor** - Final verification before LEAD approval


## üóÑÔ∏è Supabase Database Operations

### Connection Details
- **Project URL**: https://dedlbzhpgkmetvhbkyzq.supabase.co
- **Project ID**: dedlbzhpgkmetvhbkyzq
- **Connection**: Via Supabase client using environment variables

### Environment Variables Required
```bash
# For EHG application (liapbndqlqxdcgpwntbv)
EHG_SUPABASE_URL=https://liapbndqlqxdcgpwntbv.supabase.co
EHG_SUPABASE_ANON_KEY=[anon-key]
EHG_POOLER_URL=postgresql://postgres.liapbndqlqxdcgpwntbv:[password]@aws-0-us-east-1.pooler.supabase.com:5432/postgres?sslmode=require

# For EHG_Engineer (dedlbzhpgkmetvhbkyzq)
SUPABASE_URL=https://dedlbzhpgkmetvhbkyzq.supabase.co
SUPABASE_ANON_KEY=[anon-key]
SUPABASE_POOLER_URL=postgresql://postgres.dedlbzhpgkmetvhbkyzq:[password]@aws-1-us-east-1.pooler.supabase.com:5432/postgres?sslmode=require
SUPABASE_DB_PASSWORD=Fl!M32DaM00n!1
```


## üîß CRITICAL DEVELOPMENT WORKFLOW

**Development Workflow**: MANDATORY server restart after ANY changes

**Steps**: Kill server ‚Üí Build client (`npm run build:client`) ‚Üí Restart server ‚Üí Hard refresh browser
**Why**: No hot-reloading configured, dist/ serves compiled files
**Commands**: `pkill -f "node server.js" && npm run build:client && PORT=3000 node server.js`

**Complete Guide**: See `docs/reference/development-workflow.md`


## Sub-Agent Parallel Execution

**Overview**: Sub-agents are independent specialists. When multiple sub-agents provide non-overlapping assessments, call them in parallel to reduce latency.

**When Parallel Execution is Beneficial**:

1. **LEAD Initial Assessment**
   - Parallel: Security Architect + Database Architect + Business Analyst
   - Why: Each evaluates different aspects of an SD (security posture, data model feasibility, business alignment)
   - Context sharing: Not required - each has independent assessment criteria

2. **PLAN Supervisor Verification**
   - Parallel: QA Director + Security Architect + Performance Lead + Database Architect
   - Why: Final "done done" check across all quality dimensions simultaneously
   - Context sharing: Not required - each validates their domain independently

3. **EXEC Pre-Implementation Checks**
   - Parallel: Systems Analyst (duplicate check) + Security Architect (auth requirements) + Database Architect (schema changes)
   - Why: Gather all constraints before coding begins
   - Context sharing: Not required - each identifies risks independently

**When Sequential Execution is Required**:

- ‚ùå One sub-agent's output feeds another's input
- ‚ùå Database schema must be reviewed before security assessment
- ‚ùå Any workflow where order creates dependencies

**Implementation Pattern**:

```javascript
// ‚úÖ Parallel - Independent assessments
const results = await Promise.all([
  callSubAgent('security-architect', sd_id),
  callSubAgent('database-architect', sd_id),
  callSubAgent('qa-director', sd_id)
]);

// ‚ùå Sequential - One depends on another
const schema = await callSubAgent('database-architect', sd_id);
const securityReview = await callSubAgent('security-architect', schema); // Needs schema first
```

**Critical Constraints**:
- Each sub-agent receives the same initial context
- Sub-agents cannot see each other's results until all complete
- Aggregate results AFTER all sub-agents finish
- If any sub-agent fails, gracefully handle in aggregation phase

**Benefits**:
- Reduces total verification time (4 sub-agents in 30s vs. 2min sequential)
- No context sharing limitations since assessments are independent
- Each specialist works from fresh context without bias from others


---

*Generated from Database: 2025-10-29*
*Protocol Version: vv4.2.0_story_gates*
*Database-First Architecture: ACTIVE*
