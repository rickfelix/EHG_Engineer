# CLAUDE.md - LEO Protocol Workflow Guide for AI Agents

## ‚ö†Ô∏è DO NOT EDIT THIS FILE DIRECTLY

**This file is AUTO-GENERATED from the database.**

## To Make Changes:
1. **For dynamic content** (agents, sub-agents, triggers): Update database tables directly
2. **For static sections** (guides, examples, instructions): Add/update in `leo_protocol_sections` table
3. **Regenerate file**: Run `node scripts/generate-claude-md-from-db.js`

**Any direct edits to this file will be lost on next regeneration!**

See documentation for table structure: `database/schema/007_leo_protocol_schema_fixed.sql`


## Session Prologue (Short)

1. **Follow LEAD‚ÜíPLAN‚ÜíEXEC** - Target ‚â•85% gate pass rate
2. **Use sub-agents** - Architect, QA, Reviewer - summarize outputs
3. **Database-first** - No markdown files as source of truth
4. **Small PRs** - Target ‚â§100 lines, max 400 with justification
5. **7-element handoffs** - Required for all phase transitions
6. **Priority-first** - Use `npm run prio:top3` to justify work

*For copy-paste version: see `templates/session-prologue.md` (generate via `npm run session:prologue`)*


## üèóÔ∏è Application Architecture - CRITICAL CONTEXT

### Two Distinct Applications:
1. **EHG_Engineer** (Management Dashboard) - WHERE YOU ARE NOW
   - **Path**: `/mnt/c/_EHG/EHG_Engineer/`
   - **Purpose**: LEO Protocol dashboard for managing Strategic Directives & PRDs
   - **Database**: dedlbzhpgkmetvhbkyzq (Supabase)
   - **GitHub**: https://github.com/rickfelix/EHG_Engineer.git
   - **Port**: 3000-3001
   - **Role**: MANAGEMENT TOOL ONLY - no customer features here!

2. **EHG** (Business Application) - IMPLEMENTATION TARGET
   - **Path**: `/mnt/c/_EHG/ehg/`
   - **Purpose**: The actual customer-facing business application
   - **Database**: liapbndqlqxdcgpwntbv (Supabase)
   - **GitHub**: https://github.com/rickfelix/ehg.git
   - **Built with**: Vite + React + Shadcn + TypeScript
   - **Role**: WHERE ALL FEATURES GET IMPLEMENTED

### ‚ö†Ô∏è CRITICAL: During EXEC Phase Implementation
1. **Read PRD** from EHG_Engineer database
2. **Navigate** to `/mnt/c/_EHG/ehg/` for implementation
3. **Make code changes** in EHG application (NOT in EHG_Engineer!)
4. **Push changes** to EHG's GitHub repo: `rickfelix/ehg.git`
5. **Track progress** in EHG_Engineer dashboard

### üîÑ Workflow Relationship
```
EHG_Engineer (Management)          EHG App (Implementation)
‚îú‚îÄ‚îÄ Strategic Directives     ‚Üí     Features implemented here
‚îú‚îÄ‚îÄ PRDs                     ‚Üí     Code changes made here
‚îú‚îÄ‚îÄ Progress Tracking        ‚Üê     Results verified from here
‚îî‚îÄ‚îÄ Dashboard Views          ‚Üê     No changes here!
```


## ‚ö†Ô∏è DYNAMICALLY GENERATED FROM DATABASE
**Last Generated**: 2025-10-12 2:43:47 PM
**Source**: Supabase Database (not files)
**Auto-Update**: Run `node scripts/generate-claude-md-from-db.js` anytime

## üü¢ CURRENT LEO PROTOCOL VERSION: vv4.2.0_story_gates

**CRITICAL**: This is the ACTIVE version from database
**ID**: leo-v4-2-0-story-gates
**Status**: ACTIVE
**Title**: LEO Protocol v4.2.0 - Story Gates & Automated Release Control

### üìÖ Protocol Management

**Database-First Architecture**:
- Protocol stored in `leo_protocols` table
- Sub-agents in `leo_sub_agents` table
- Handoffs in `leo_handoff_templates` table
- Single source of truth - no file conflicts

**To update protocol version**:
```sql
-- Only via database operations
UPDATE leo_protocols SET status = 'active' WHERE version = 'new_version';
UPDATE leo_protocols SET status = 'superseded' WHERE version != 'new_version';
```

## Agent Responsibilities

| Agent | Code | Responsibilities | % Split |
|-------|------|------------------|----------|
| Implementation Agent | EXEC | Implementation based on PRD. **CRITICAL: Implementations happen in /mnt/c/_EHG/e... | I:30 = 30% |
| Strategic Leadership Agent | LEAD | Strategic planning, business objectives, final approval. **SIMPLICITY FIRST (PRE... | P:20 A:15 = 35% |
| Technical Planning Agent | PLAN | Technical design, PRD creation with comprehensive test plans, pre-automation val... | P:20 V:15 = 35% |

**Legend**: P=Planning, I=Implementation, V=Verification, A=Approval
**Total**: EXEC (30%) + LEAD (35%) + PLAN (35%) = 100%

## üö® EXEC Agent Implementation Requirements

### MANDATORY Pre-Implementation Verification
Before writing ANY code, EXEC MUST:

0. **APPLICATION CHECK** ‚ö†Ô∏è CRITICAL FIRST STEP
   - Confirm target app: `/mnt/c/_EHG/ehg/` (NOT EHG_Engineer!)
   - Verify: `cd /mnt/c/_EHG/ehg && pwd` should show `/mnt/c/_EHG/ehg`
   - Check GitHub: `git remote -v` should show `rickfelix/ehg.git`
   - If you're in EHG_Engineer, you're in the WRONG place for implementation!

1. **URL Verification** ‚úÖ
   - Navigate to the EXACT URL specified in the PRD
   - Confirm the page loads and is accessible
   - Take a screenshot for evidence
   - Document: "Verified: [URL] is accessible"

2. **Component Identification** üéØ
   - Identify the exact file path of the target component
   - Confirm component exists at specified location
   - Document: "Target component: [full/path/to/component.tsx]"

3. **Application Context** üìÅ
   - Verify correct application directory
   - Confirm port number matches PRD
   - Document: "Application: [/path/to/app] on port [XXXX]"

4. **Visual Confirmation** üì∏
   - Screenshot current state BEFORE changes
   - Identify exact location for new features
   - Document: "Current state captured, changes will go at [location]"

### Implementation Checklist Template
```markdown
## EXEC Pre-Implementation Checklist
- [ ] URL verified: [exact URL from PRD]
- [ ] Page accessible: [YES/NO]
- [ ] Component identified: [path/to/component]
- [ ] Application path: [/full/path/to/app]
- [ ] Port confirmed: [port number]
- [ ] Screenshot taken: [timestamp]
- [ ] Target location confirmed: [where changes go]
```

### Common Mistakes to AVOID
- ‚ùå Assuming component location based on naming similarity
- ‚ùå Implementing without navigating to the URL first
- ‚ùå Ignoring port numbers in URLs
- ‚ùå Pattern matching without verification
- ‚ùå Starting to code before completing checklist
- ‚ùå Not restarting dev servers after changes
- ‚ùå **CRITICAL**: Creating files for PRDs, handoffs, or documentation


## üîÑ Git Commit Guidelines

**Git Commit Guidelines**: `<type>(<SD-ID>): <subject>` format MANDATORY

**Required**: Type (feat/fix/docs/etc), SD-ID scope, imperative subject, AI attribution in footer
**Timing**: After checklist items, before context switches, at logical breakpoints
**Branch Strategy**: `eng/` prefix for EHG_Engineer, standard prefixes for EHG app features
**Size**: <100 lines ideal, <200 max

**Full Guidelines**: See `docs/03_protocols_and_standards/leo_git_commit_guidelines_v4.2.0.md`


## PR Size Guidelines

**Philosophy**: Balance AI capability with human review capacity. Modern AI can handle larger changes, but humans still need to review them.

**Three Tiers**:

1. **‚â§100 lines (Sweet Spot)** - No justification needed
   - Simple bug fixes
   - Single feature additions
   - Configuration changes
   - Documentation updates

2. **101-200 lines (Acceptable)** - Brief justification in PR description
   - Multi-component features
   - Refactoring with tests
   - Database migrations with updates
   - Example: "Adds authentication UI (3 components) + tests"

3. **201-400 lines (Requires Strong Justification)** - Detailed rationale required
   - Complex features that cannot be reasonably split
   - Large refactorings with extensive test coverage
   - Third-party integrations with configuration
   - Must explain why splitting would create more risk/complexity
   - Example: "OAuth integration requires provider config, UI flows, session management, and error handling as atomic unit"

**Over 400 lines**: Generally prohibited. Split into multiple PRs unless exceptional circumstances (emergency hotfix, external dependency forcing bundled changes).

**Key Principle**: If you can split it without creating incomplete/broken intermediate states, you should split it.


## üìä Communication & Context

### Context Economy Rules

**Core Principles**:
- **Response Budget**: ‚â§500 tokens default (unless complexity requires more)
- **Summarize > Paste**: Reference paths/links instead of full content
- **Fetch-on-Demand**: Name files first, retrieve only needed parts
- **Running Summaries**: Keep condensed handoff/PR descriptions

### Best Practices

**Efficient Context Usage**:
- **Quote selectively**: Show only relevant lines with context
- **Use file:line references**: `src/component.js:42-58` instead of full file
- **Batch related reads**: Minimize round-trips when exploring
- **Archive verbosity**: Move details to handoffs/database, not conversation

### Examples

| ‚ùå Inefficient | ‚úÖ Efficient |
|----------------|--------------|
| Paste entire 500-line file | Quote lines 42-58 with `...` markers |
| Read file multiple times | Batch read relevant sections once |
| Repeat full error in response | Summarize error + reference line |
| Include all test output | Show failed tests + counts only |

### üîÑ MANDATORY: Server Restart Protocol
After ANY code changes:
1. **Kill the dev server**: `kill [PID]` or Ctrl+C
2. **Restart the server**: `npm run dev` or appropriate command
3. **Wait for ready message**: Confirm server is fully started
4. **Hard refresh browser**: Ctrl+Shift+R / Cmd+Shift+R
5. **Verify changes are live**: Test the new functionality

**WHY**: Dev servers may cache components, especially new files. Hot reload is NOT always reliable.


## Parallel Execution

**When to Use**: Modern AI supports parallel tool execution for independent operations. Use conservatively.

**Safe for Parallel Execution**:
- ‚úÖ Reading multiple independent files for analysis
- ‚úÖ Running multiple independent database queries
- ‚úÖ Executing multiple read-only Git commands (status, log, diff)
- ‚úÖ Multiple WebFetch calls to different URLs
- ‚úÖ Batch file searches (multiple Glob operations)

**NOT Safe for Parallel Execution**:
- ‚ùå Write operations (Edit, Write tools)
- ‚ùå Database mutations (INSERT, UPDATE, DELETE)
- ‚ùå Any operations where order matters
- ‚ùå Operations that depend on each other's results
- ‚ùå Git operations that modify state (commit, push, merge)

**Critical Constraint**: Context sharing between parallel operations is limited. Each operation receives the same initial context but cannot see other parallel operations' results until they all complete.

**Example Use Case**:
```
"Read the following 3 files for analysis:"
- Read src/component.tsx
- Read src/types.ts
- Read tests/component.test.tsx
```

**Anti-Pattern**:
```
"Read file A, then based on what you find, read file B"
(Must be sequential - second read depends on first)
```


## Progress Calculation

```
Total = EXEC: 30% + LEAD: 35% + PLAN: 35% = 100%
```

## üéØ LEAD Agent Operations

**LEAD Agent Operations**: Strategic planning, business objectives, final approval.

**Finding Active SDs**: `node scripts/query-active-sds.js` or query `strategic_directives_v2` table directly

**Decision Matrix**:
- Draft ‚Üí Review & approve
- Pending Approval ‚Üí Final review  
- Active ‚Üí Create LEAD‚ÜíPLAN handoff
- In Progress ‚Üí Monitor execution

**Key Responsibilities**: Strategic direction, priority setting (CRITICAL: 90+, HIGH: 70-89, MEDIUM: 50-69, LOW: 30-49), handoff creation, progress monitoring

**Complete Guide**: See `docs/reference/lead-operations.md`


## üìã Directive Submission Review Process

**Directive Submission Review**: Review submissions before creating SDs.

**Quick Review**:
```bash
node scripts/lead-review-submissions.js
```

**Review Checklist**:
- Chairman input (original intent)
- Intent clarity & strategic alignment
- Priority assessment & scope validation
- Duplicate check & gate progression

**Decision Matrix**:
- Completed + No SD ‚Üí Create SD
- Completed + SD exists ‚Üí Verify & handoff
- Pending ‚Üí Monitor
- Failed ‚Üí Archive/remediate

**Complete Process**: See `docs/reference/directive-submission-review.md`




## Strategic Directive Execution Protocol

# STRATEGIC DIRECTIVE EXECUTION PROTOCOL

**When executing a Strategic Directive, follow this structured 5-phase workflow.**

## Target Application Selection

**CRITICAL FIRST STEP**: Determine which application this SD targets:

- **EHG** (`/mnt/c/_EHG/ehg/`) - Customer-facing features (MOST IMPLEMENTATIONS)
  - Database: liapbndqlqxdcgpwntbv (Supabase)
  - GitHub: rickfelix/ehg.git
  - Stack: Vite + React + Shadcn + TypeScript

- **EHG_Engineer** (`/mnt/c/_EHG/EHG_Engineer/`) - LEO Protocol dashboard/tooling ONLY
  - Database: dedlbzhpgkmetvhbkyzq (Supabase)
  - GitHub: rickfelix/EHG_Engineer.git
  - Role: Management tool, no customer features

## Priority Tiers

- **CRITICAL** (90+): Business-critical, immediate action required
- **HIGH** (70-89): Important features, near-term priority
- **MEDIUM** (50-69): Standard enhancements, planned work
- **LOW** (30-49): Nice-to-have improvements

## Workflow Overview

Execute in order: **LEAD PRE-APPROVAL ‚Üí PLAN PRD ‚Üí EXEC IMPLEMENTATION ‚Üí PLAN VERIFICATION ‚Üí LEAD FINAL APPROVAL**

Each phase has:
- Assigned agent (LEAD/PLAN/EXEC)
- Percentage allocation
- Required sub-agents
- Exit criteria
- Mandatory handoff

See detailed phase sections below.

## Execution Philosophy

## üß† EXECUTION PHILOSOPHY (Read First!)

These principles override default behavior and must be internalized before starting work:

### Quality-First (PARAMOUNT)
**Get it right, not fast.** Correctness and completeness are MORE IMPORTANT than speed.
- Take the time needed to understand requirements fully
- Verify BEFORE implementing, test BEFORE claiming completion
- 2-4 hours of careful implementation beats 6-12 hours of rework
- If rushing leads to mistakes, you haven't saved time - you've wasted it
- "Done right" > "Done fast" - ALWAYS

### Testing-First (MANDATORY)
**Build confidence through comprehensive testing.**
- E2E testing is MANDATORY, not optional
- 30-60 minute investment saves 4-6 hours of rework
- 100% user story coverage required
- Both unit tests AND E2E tests must pass
- Tests are not overhead - they ARE the work

### Database-First (REQUIRED)
**Zero markdown files.** Database tables are single source of truth.
- SDs ‚Üí `strategic_directives_v2`
- PRDs ‚Üí `product_requirements_v2`
- Handoffs ‚Üí `sd_phase_handoffs`
- Retrospectives ‚Üí `retrospectives`
- Sub-agent results ‚Üí `sub_agent_execution_results`

### Validation-First (GATEKEEPING)
**Thorough validation BEFORE approval, full commitment AFTER.**
- LEAD validates: Real problem? Feasible solution? Resources available?
- After LEAD approval: SCOPE LOCK - deliver what was approved
- Exception: Critical blocker + human approval + new SD for deferred work

### Context-Aware (PROACTIVE)
**Monitor token usage proactively throughout execution.**
- Report context health in EVERY handoff
- HEALTHY (<70%), WARNING (70-90%), CRITICAL (90-95%), EMERGENCY (>95%)
- Use `/context-compact` when approaching WARNING threshold

### Application-Aware (VERIFICATION)
**Verify directory BEFORE writing ANY code.**
- `cd /mnt/c/_EHG/ehg && pwd` for customer features
- `git remote -v` to confirm correct repository
- Wrong directory = STOP immediately

### Evidence-Based (PROOF REQUIRED)
**Screenshot, test, verify. Claims without evidence are rejected.**
- Screenshot BEFORE and AFTER changes
- Test results with pass/fail counts
- CI/CD pipeline status (green checks required)
- Sub-agent verification results in database

**REMEMBER**: The goal is NOT to complete SDs quickly. The goal is to complete SDs CORRECTLY. A properly implemented SD that takes 8 hours is infinitely better than a rushed implementation that takes 4 hours but requires 6 hours of fixes.


## 5-Phase Strategic Directive Workflow

## üéØ 5-PHASE STRATEGIC DIRECTIVE WORKFLOW

Total: 100% = LEAD (35%) + PLAN (35%) + EXEC (30%)

---

### PHASE 1: LEAD PRE-APPROVAL (20% of LEAD allocation)

**Agent**: Strategic Leadership Agent (LEAD)
**Purpose**: Strategic validation, business alignment, feasibility assessment
**Duration**: 1-2 hours

**Mandatory Sub-Agents**:
- Principal Systems Analyst (duplicate check, existing implementation)
- Principal Database Architect (if database keywords in scope)
- Chief Security Architect (if security keywords in scope)
- Senior Design Sub-Agent (if UI/UX keywords in scope)

**Execution**: Run in parallel to save time
```bash
# Parallel execution
node scripts/systems-analyst-codebase-audit.js <SD-ID> &
node scripts/database-architect-schema-review.js <SD-ID> &
node scripts/security-architect-assessment.js <SD-ID> &
node scripts/design-subagent-evaluation.js <SD-ID> &
wait
```

**Deliverables**:
- SD approved or rejected with feedback
- Strategic Validation gate passed
- Over-engineering rubric applied (if needed)
- LEAD‚ÜíPLAN handoff created

**Exit Criteria**:
- SD status = 'active'
- Strategic Validation gate passed (6 questions answered)
- No critical blockers identified
- Handoff stored in `sd_phase_handoffs`

---

### PHASE 2: PLAN PRD CREATION (20% of PLAN allocation)

**Agent**: Technical Planning Agent (PLAN)
**Purpose**: Technical design, PRD creation, test planning
**Duration**: 2-4 hours

**Mandatory Sub-Agents**:
- Principal Database Architect (MANDATORY for ALL SDs - database validation)
- Product Requirements Expert (auto-generates user stories)

**Execution**: Sequential (each informs next)
```bash
# Step 1: Database validation
node scripts/database-architect-schema-review.js <SD-ID>

# Step 2: User story generation (automatic)
# Triggered by PRD creation, stores in user_stories table

# Step 3: Component sizing (if UI/UX SD)
node scripts/design-subagent-evaluation.js <SD-ID>
```

**Deliverables**:
- PRD created in `product_requirements_v2` table
- User stories in `user_stories` table (100% mapped to E2E tests)
- Component architecture defined (300-600 LOC per component)
- Database migrations planned (if needed)
- PLAN‚ÜíEXEC handoff created

**Exit Criteria**:
- PRD exists with comprehensive test plan
- User stories generated and validated
- Database dependencies resolved or escalated
- Handoff stored in `sd_phase_handoffs`

---

### PHASE 3: EXEC IMPLEMENTATION (30% of EXEC allocation)

**Agent**: Implementation Agent (EXEC)
**Purpose**: Code implementation, testing, delivery
**Duration**: 4-8 hours

**Mandatory Sub-Agents**:
- None (EXEC does the work directly)

**Pre-Implementation Checklist**:
```markdown
## EXEC Pre-Implementation Checklist
- [ ] Application: [EHG or EHG_Engineer - VERIFIED via pwd]
- [ ] GitHub remote: [verified via git remote -v]
- [ ] URL: [exact URL from PRD - accessible: YES/NO]
- [ ] Component: [path/to/component]
- [ ] Screenshot: [BEFORE state captured]
```

**Post-Implementation Requirements**:
1. **Server Restart** (MANDATORY for UI changes)
   ```bash
   pkill -f "node server.js"
   npm run build:client  # If UI changes
   PORT=3000 node server.js
   # Hard refresh: Ctrl+Shift+R
   ```

2. **Git Commit** (Conventional Commits with SD-ID)
   ```bash
   git commit -m "feat(<SD-ID>): Brief description

   Detailed explanation.

   ü§ñ Generated with [Claude Code](https://claude.com/claude-code)

   Co-Authored-By: Claude <noreply@anthropic.com>"
   ```

3. **Dual Test Execution** (MANDATORY - BOTH types)
   ```bash
   npm run test:unit      # Business logic
   npm run test:e2e       # User flows
   ```

4. **Wait for CI/CD** (2-3 minutes)
   ```bash
   gh run list --limit 5  # All green ‚úÖ
   ```

**Deliverables**:
- Implementation complete
- Unit tests pass
- E2E tests pass (100% user story coverage)
- CI/CD pipelines green
- Documentation generated
- EXEC‚ÜíPLAN handoff created

**Exit Criteria**:
- All PRD requirements implemented
- Both test types passing
- CI/CD green
- Documentation exists in `generated_docs`
- Handoff stored in `sd_phase_handoffs`

---

### PHASE 4: PLAN SUPERVISOR VERIFICATION (15% of PLAN allocation)

**Agent**: Technical Planning Agent (PLAN) in supervisor mode
**Purpose**: Verification, quality assurance, sub-agent orchestration
**Duration**: 1-2 hours

**Mandatory Sub-Agents**:
- QA Engineering Director (CRITICAL - E2E testing)
- DevOps Platform Architect (CRITICAL - CI/CD verification)
- Principal Database Architect (if database changes)
- Chief Security Architect (if security features)
- Performance Engineering Lead (if performance-critical)
- Senior Design Sub-Agent (if UI components)

**Automated Orchestration**:
```bash
# Orchestrator runs automatically when creating EXEC‚ÜíPLAN handoff
# All required sub-agents execute in parallel
# Results stored in sub_agent_execution_results table
# Handoff BLOCKED if CRITICAL sub-agents fail
```

**Manual Verification** (if needed):
```bash
# QA Director
node scripts/qa-engineering-director-enhanced.js <SD-ID> --full-e2e

# GitHub Actions
gh run list --limit 5
gh run view [run-id]

# Database verification
node scripts/database-architect-schema-review.js <SD-ID>
```

**Deliverables**:
- All sub-agents executed
- E2E tests passed (100% user stories)
- CI/CD pipelines verified green
- Integration verification complete
- PLAN‚ÜíLEAD handoff created

**Exit Criteria**:
- Verdict: PASS or CONDITIONAL_PASS (‚â•85% confidence)
- All CRITICAL sub-agents passed
- E2E test evidence documented
- Handoff stored in `sd_phase_handoffs`

---

### PHASE 5: LEAD FINAL APPROVAL (15% of LEAD allocation)

**Agent**: Strategic Leadership Agent (LEAD)
**Purpose**: Final approval, retrospective, completion
**Duration**: 30-60 minutes

**Mandatory Sub-Agents**:
- Continuous Improvement Coach (RETRO - retrospective generation)

**Automated Orchestration**:
```bash
# Orchestrator runs automatically when creating PLAN‚ÜíLEAD handoff
# RETRO sub-agent executes if not already run
# Handoff BLOCKED if retrospective missing
```

**Approval Checklist**:
- [ ] PLAN‚ÜíLEAD handoff reviewed
- [ ] Verification verdict acceptable (PASS or CONDITIONAL_PASS)
- [ ] All PRD requirements met (SCOPE LOCK validation)
- [ ] CI/CD pipelines green
- [ ] E2E test evidence sufficient (100% user stories)
- [ ] Retrospective generated
- [ ] Sub-agent validation script passed
- [ ] Human approval (if required)

**Deliverables**:
- SD marked as 'completed'
- Progress = 100%
- Retrospective in `retrospectives` table
- All handoffs complete
- Dashboard updated

**Exit Criteria**:
- SD status = 'completed'
- progress_percentage = 100
- completed_at timestamp set
- Retrospective exists with quality_score ‚â• 70


## Context Management Throughout Execution

## üß† CONTEXT MANAGEMENT (Throughout Execution)

**Token Budget**: 200,000 tokens

### Status Thresholds

| Status | Range | Percentage | Action |
|--------|-------|------------|--------|
| üü¢ HEALTHY | 0-140K | 0-70% | Continue normally |
| üü° WARNING | 140K-180K | 70-90% | Consider `/context-compact` |
| üî¥ CRITICAL | 180K-190K | 90-95% | MUST compact before handoff |
| üö® EMERGENCY | >190K | >95% | BLOCKED - force handoff |

### Report in EVERY Handoff

**Mandatory section in all handoffs**:
```markdown
## Context Health
**Current Usage**: X tokens (Y% of 200K budget)
**Status**: HEALTHY/WARNING/CRITICAL
**Recommendation**: [action if needed]
**Compaction Needed**: YES/NO
```

### Efficiency Rules

**Always apply these practices**:

1. **Select specific columns** (not `SELECT *`)
   ```javascript
   // ‚ùå Bad
   .select('*')

   // ‚úÖ Good
   .select('id, title, status, priority')
   ```

2. **Limit results** for large datasets
   ```javascript
   .limit(5)  // For summaries
   .limit(50) // For dashboards
   ```

3. **Summarize, don't dump**
   ```javascript
   // ‚ùå Bad: Full JSON dump
   console.log(results);

   // ‚úÖ Good: Summary
   console.log(`Found ${results.length} tests: ${passed} passed, ${failed} failed`);
   ```

4. **Use Read tool with offset/limit** for large files
   ```javascript
   Read('file.js', { offset: 100, limit: 50 })
   ```

5. **Compress sub-agent reports** (3-tier system)
   - TIER 1 (CRITICAL): Full detail for blockers
   - TIER 2 (IMPORTANT): Structured summary for warnings
   - TIER 3 (INFORMATIONAL): One-line for passing checks

### Expected Impact

Applying these rules: **90-98% token reduction per query**

### Compaction Command

When WARNING or CRITICAL:
```bash
/context-compact [focus area]
```

Example:
```bash
/context-compact database-schema
```

## Database Operations - One Table at a Time

### REQUIRED: Database Operations Only

**‚ö†Ô∏è CRITICAL: One Table at a Time**
- When manipulating Supabase tables, **ALWAYS operate on ONE table at a time**
- Batch operations across multiple tables often fail or cause inconsistencies
- Complete each table operation fully before moving to the next table
- Verify success after each table operation before proceeding

**Strategic Directives**:
- ‚úÖ Create in `strategic_directives_v2` table
- ‚úÖ Use `scripts/create-strategic-directive.js` or dashboard
- ‚úÖ ALL SD data must be in database, not files
- ‚úÖ **One SD insertion at a time** - verify before next

**PRDs (Product Requirements)**:
- ‚úÖ Create in `product_requirements_v2` table
- ‚úÖ Use `scripts/add-prd-to-database.js`
- ‚úÖ Link to SD via `strategic_directive_id` foreign key
- ‚úÖ **One PRD insertion at a time** - verify before next

**Retrospectives**:
- ‚úÖ Create in `retrospectives` table
- ‚úÖ Use `scripts/generate-comprehensive-retrospective.js`
- ‚úÖ Trigger: Continuous Improvement Coach sub-agent
- ‚úÖ Link to SD via `sd_id` foreign key
- ‚úÖ **One retrospective at a time** - verify before next

**Handoffs**:
- ‚úÖ Store in handoff tracking tables
- ‚úÖ 7-element structure required
- ‚úÖ Link to SD and phase
- ‚úÖ **One handoff at a time** - verify before next

**Progress & Verification**:
- ‚úÖ Update database fields directly
- ‚úÖ Store verification results in database
- ‚úÖ Track in real-time via dashboard
- ‚úÖ **One record update at a time** - verify before next

## Multi-Application Testing Architecture

**Multi-App Testing**: Two independent test suites (EHG_Engineer + EHG app).

**CRITICAL**: Determine target app from SD context before running tests
- **EHG_Engineer**: Vitest + Jest (50% coverage)
- **EHG**: Vitest (unit) + Playwright (E2E)

**Full Guide**: See `docs/reference/multi-app-testing.md`

## LEAD Over-Engineering Evaluation Process

### üõ°Ô∏è LEAD Over-Engineering Evaluation Process

**MANDATORY**: LEAD agents MUST use the standardized rubric before making any SD status/priority changes.

#### Step-by-Step Evaluation Process

1. **Execute Rubric Evaluation**:
   ```bash
   node scripts/lead-over-engineering-rubric.js --sd-id [SD_ID]
   ```

2. **Review 6-Dimension Scores** (1-5 scale each):
   - **Technical Complexity vs Business Value**: Complexity-to-value ratio
   - **Resource Intensity vs Urgency**: Development effort vs business urgency  
   - **Strategic Priority Alignment**: Alignment with Stage 1/EVA/GTM priorities
   - **Market Timing & Opportunity Window**: Market opportunity timing
   - **Implementation & Business Risk**: Risk vs reward assessment
   - **Return on Investment Projection**: Expected ROI evaluation

3. **Check Over-Engineering Thresholds**:
   - Total Score ‚â§15/30 = Over-engineered
   - Complexity ‚â§2 = Problematic
   - Strategic Alignment ‚â§2 = Concerning  
   - Risk Assessment ‚â§2 = Dangerous

4. **Present Findings to Human**:
   ```bash
   node scripts/lead-human-approval-system.js --sd-id [SD_ID] --evaluation [RESULTS]
   ```

5. **Request Explicit Approval**: Show scores, reasoning, and consequences

6. **Execute Only After Approval**: NEVER make autonomous changes

#### Available Scripts for LEAD Agents
- `scripts/lead-over-engineering-rubric.js` - Standardized 6-dimension evaluation
- `scripts/lead-human-approval-system.js` - Human approval workflow
- `scripts/enhanced-priority-rubric.js` - Priority rebalancing tools

#### Prohibited Actions
- ‚ùå Autonomous SD status/priority changes  
- ‚ùå Overriding user selections without permission
- ‚ùå Subjective over-engineering calls without rubric
- ‚ùå Making changes before human approval

## Quick Reference

## üìã QUICK REFERENCE

### Component Sizing

| Lines of Code | Action | Rationale |
|---------------|--------|-----------|
| <200 | Consider combining | Too granular |
| **300-600** | ‚úÖ **OPTIMAL** | Sweet spot for testing & maintenance |
| >800 | **MUST split** | Too complex, hard to test |

### Git Commits (Conventional Commits)

**Format**: `<type>(<SD-ID>): <subject>`

```bash
git commit -m "feat(SD-XXX): Brief description

Detailed explanation of changes.

ü§ñ Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>"
```

**Types**: feat, fix, docs, refactor, test, chore, perf

### Server Restart (After ANY Changes)

```bash
# Kill
pkill -f "node server.js"

# Build (if UI changes)
npm run build:client

# Restart
PORT=3000 node server.js

# Hard refresh browser
# Ctrl+Shift+R (Windows) / Cmd+Shift+R (Mac)
```

### Parallel Execution (Save Time)

**When Safe**:
- ‚úÖ Multiple independent file reads
- ‚úÖ Multiple database queries (read-only)
- ‚úÖ Sub-agent execution (different domains)

**NOT Safe**:
- ‚ùå Write operations
- ‚ùå Database mutations
- ‚ùå Sequential dependencies

**Example**:
```bash
# LEAD Pre-Approval: 4 sub-agents in parallel
node scripts/systems-analyst-codebase-audit.js <SD-ID> &
node scripts/database-architect-schema-review.js <SD-ID> &
node scripts/security-architect-assessment.js <SD-ID> &
node scripts/design-subagent-evaluation.js <SD-ID> &
wait

# Reduces time from 2 minutes sequential to 30 seconds parallel
```

### Context Efficiency Patterns

```javascript
// ‚ùå Inefficient
const { data } = await supabase.from('table').select('*');
console.log(data); // Dumps full JSON

// ‚úÖ Efficient
const { data } = await supabase
  .from('table')
  .select('id, title, status')
  .limit(5);
console.log(`Found ${data.length} items`);
```

### Database Operations (One at a Time)

**CRITICAL**: When manipulating Supabase tables, operate on ONE table at a time.

```javascript
// ‚ùå Bad: Batch across tables
await Promise.all([
  supabase.from('table1').insert(data1),
  supabase.from('table2').insert(data2)
]);

// ‚úÖ Good: Sequential, one table at a time
await supabase.from('table1').insert(data1);
// Verify success
await supabase.from('table2').insert(data2);
// Verify success
```

### Sub-Agent Orchestration

**Automated** (preferred):
```bash
# Orchestrator runs all required sub-agents for phase
node scripts/orchestrate-phase-subagents.js <PHASE> <SD-ID>

# Phases: LEAD_PRE_APPROVAL, PLAN_PRD, EXEC_IMPL, PLAN_VERIFY, LEAD_FINAL
```

**Manual** (if needed):
```bash
# QA Director
node scripts/qa-engineering-director-enhanced.js <SD-ID> --full-e2e

# GitHub Actions
node scripts/github-actions-verifier.js <SD-ID>

# Database Architect
node scripts/database-architect-schema-review.js <SD-ID>
```

### Testing Commands

```bash
# Unit tests (business logic)
npm run test:unit

# E2E tests (user flows)
npm run test:e2e

# Both (MANDATORY before EXEC‚ÜíPLAN handoff)
npm run test:unit && npm run test:e2e
```

### Handoff Creation

```bash
# Unified handoff system (with auto sub-agent orchestration)
node scripts/unified-handoff-system.js execute <TYPE> <SD-ID>

# Types:
# - LEAD-to-PLAN
# - PLAN-to-EXEC
# - EXEC-to-PLAN (auto-runs PLAN_VERIFY sub-agents)
# - PLAN-to-LEAD (auto-runs LEAD_FINAL sub-agents)
```

### Progress Verification

```bash
# Check progress breakdown
node -e "
const { createClient } = require('@supabase/supabase-js');
const supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_ANON_KEY);
(async () => {
  const { data } = await supabase.rpc('get_progress_breakdown', { sd_id_param: 'SD-XXX' });
  console.log(JSON.stringify(data, null, 2));
})();
"
```

## 6-Step SD Evaluation Checklist

**6-Step SD Evaluation Checklist (MANDATORY for LEAD & PLAN)**:

1. Query `strategic_directives_v2` for SD metadata
2. Query `product_requirements_v2` for existing PRD
3. **Query `sd_backlog_map` for linked backlog items** ‚Üê CRITICAL
4. Search codebase for existing infrastructure
5. Identify gaps between backlog requirements and existing code
6. **Execute QA smoke tests** ‚Üê NEW (verify tests run before approval)

**Backlog Review Requirements**: Review backlog_title, item_description, extras.Description_1 for each item

**Complete Checklist**: See `docs/reference/sd-evaluation-checklist.md`

## Enhanced QA Engineering Director v2.0 - Testing-First Edition

**Enhanced QA Engineering Director v2.0**: Mission-critical testing automation with comprehensive E2E validation.

**Core Capabilities:**
1. Professional test case generation from user stories
2. Pre-test build validation (saves 2-3 hours)
3. Database migration verification (prevents 1-2 hours debugging)
4. **Mandatory E2E testing via Playwright** (REQUIRED for approval)
5. Test infrastructure discovery and reuse

**5-Phase Workflow**: Pre-flight checks ‚Üí Test generation ‚Üí E2E execution ‚Üí Evidence collection ‚Üí Verdict & learnings

**Activation**: Auto-triggers on `EXEC_IMPLEMENTATION_COMPLETE`, coverage keywords, testing evidence requests

**Full Guide**: See `docs/reference/qa-director-guide.md`

## Quality Validation Examples

**Evidence from Retrospectives**: Thorough validation saves 4-6 hours per SD by catching issues early.

### LEAD Pre-Approval Validation Examples

#### Example 1: Verify Claims Against Reality

**Case** (SD-UAT-002): Code review revealed 3/5 claimed issues didn't exist ‚Üí saved 3-4 hours of unnecessary work

**Lesson**: Always verify claims with actual code inspection, don't trust assumptions

#### Example 2: Leverage Existing Infrastructure

**Case** (SD-UAT-020): Used existing Supabase Auth instead of custom solution ‚Üí saved 8-10 hours

**Lesson**: Check what already exists before approving new development

#### Example 3: Document Blockers Instead of Building Around Them

**Case** (SD-UAT-003): Database blocker identified early ‚Üí documented constraint instead of workaround ‚Üí saved 4-6 hours

**Lesson**: Identify true blockers during approval phase, not during implementation

#### Example 4: Question Necessity vs. Nicety

**Lesson**: Distinguish between "must have" (core requirements) and "nice to have" (future enhancements) during validation

### Quality Gate Benefits

Thorough LEAD pre-approval validation:
- Catches false assumptions early
- Identifies existing solutions
- Documents blockers before implementation starts
- Ensures resource allocation matches real requirements

**Total Time Saved from Examples**: 15-20 hours across validated SDs


## PLAN Pre-EXEC Checklist

## PLAN Agent Pre-EXEC Checklist (MANDATORY)

**Evidence from Retrospectives**: Database verification issues appeared in SD-UAT-003, SD-UAT-020, and SD-008. Early verification saves 2-3 hours per blocker.

Before creating PLAN‚ÜíEXEC handoff, PLAN agent MUST verify:

### Database Dependencies ‚úÖ
- [ ] **Identify all data dependencies** in PRD
- [ ] **Run schema verification script** for data-dependent SDs
- [ ] **Verify tables/columns exist** OR create migration
- [ ] **Document verification results** in PLAN‚ÜíEXEC handoff
- [ ] If tables missing: **Escalate to LEAD** with options

**Success Pattern** (SD-UAT-003):
> "Database Architect verification provided evidence for LEAD decision. Documented instead of implementing ‚Üí saved 4-6 hours"

### Architecture Planning ‚úÖ
- [ ] **Component sizing estimated** (target 300-600 lines per component)
- [ ] **Existing infrastructure identified** (don't rebuild what exists)
- [ ] **Third-party libraries considered** before custom code

**Success Pattern** (SD-UAT-020):
> "Leveraged existing Supabase Auth instead of building custom ‚Üí saved 8-10 hours"

### Testing Strategy ‚úÖ
- [ ] **Smoke tests defined** (3-5 tests minimum)
- [ ] **Test scenarios documented** in PRD

### Quality Validation ‚úÖ
- [ ] **Verified claims with code review** (if UI/UX SD)
- [ ] **Assessed technical feasibility**
- [ ] **Identified potential blockers**

**Success Pattern** (SD-UAT-002):
> "LEAD code review rejected 3/5 false claims ‚Üí saved hours of unnecessary work"


## Testing Tier Strategy

## Testing Requirements - Clear Thresholds

**Evidence from Retrospectives**: Testing confusion appeared in SD-UAT-002, SD-UAT-020, SD-008.

### Three-Tier Testing Strategy

#### Tier 1: Smoke Tests (MANDATORY) ‚úÖ
- **Requirement**: 3-5 tests, <60 seconds execution
- **Approval**: **SUFFICIENT for PLAN‚ÜíLEAD approval**

#### Tier 2: Comprehensive E2E (RECOMMENDED) üìã
- **Requirement**: 30-50 tests covering user flows
- **Approval**: Nice to have, **NOT blocking for LEAD approval**
- **Timing**: Can be refined post-deployment

#### Tier 3: Manual Testing (SITUATIONAL) üîç
- **UI changes**: Single smoke test recommended (+5 min)
- **Logic changes <5 lines**: Optional
- **Logic changes >10 lines**: Required

### Anti-Pattern to Avoid ‚ùå

**DO NOT** create 100+ manual test checklists unless specifically required.

**From SD-UAT-020**:
> "Created 100+ test checklist but didn't execute manually. Time spent on unused documentation."

## Component Sizing Guidelines

**Evidence from Retrospectives**: Proven pattern in SD-UAT-020 and SD-008.

### Optimal Component Size: 300-600 Lines

**Success Pattern** (SD-UAT-020):
> "Split settings into three focused components. Each ~500 lines. Easy to test and maintain."

### Sizing Rules

| Lines of Code | Action | Rationale |
|---------------|--------|-----------|
| **<200** | Consider combining | Too granular |
| **300-600** | ‚úÖ **OPTIMAL** | Sweet spot |
| **>800** | **MUST split** | Too complex |

## TODO Comment Standard

## TODO Comment Standard (When Deferring Work)

**Evidence from Retrospectives**: Proven pattern in SD-UAT-003 saved 4-6 hours.

### Standard TODO Format

```typescript
// TODO (SD-ID): Action required
// Requires: Dependencies, prerequisites
// Estimated effort: X-Y hours
// Current state: Mock/temporary/placeholder
```

**Success Pattern** (SD-UAT-003):
> "Comprehensive TODO comments provided clear future work path. Saved 4-6 hours."

## CI/CD Pipeline Verification

## CI/CD Pipeline Verification (MANDATORY)

**Evidence from Retrospectives**: Gap identified in SD-UAT-002 and SD-LEO-002.

### Verification Process

**After EXEC implementation complete, BEFORE PLAN‚ÜíLEAD handoff**:

1. Wait 2-3 minutes for GitHub Actions to complete
2. Trigger DevOps sub-agent to verify pipeline status
3. Document CI/CD status in PLAN‚ÜíLEAD handoff
4. PLAN‚ÜíLEAD handoff is **BLOCKED** if pipelines failing

## EXEC Dual Test Requirement

### ‚ö†Ô∏è MANDATORY: Dual Test Execution

**CRITICAL**: "Smoke tests" means BOTH test types, not just one!

**Evidence**: SD-EXPORT-001 - Tests existed but weren't executed. 30-minute gap between "complete" and validation. SD-EVA-MEETING-002 - 67% E2E failure rate when finally run.

Before creating EXEC‚ÜíPLAN handoff, EXEC MUST run:

#### 1. Unit Tests (Business Logic Validation)
```bash
cd /mnt/c/_EHG/ehg
npm run test:unit
```
- **What it validates**: Service layer, business logic, data transformations
- **Failure means**: Core functionality is broken
- **Required for**: EXEC‚ÜíPLAN handoff
- **Framework**: Vitest

#### 2. E2E Tests (UI/Integration Validation)
```bash
cd /mnt/c/_EHG/ehg
npm run test:e2e
```
- **What it validates**: User flows, component rendering, integration
- **Failure means**: User-facing features don't work
- **Required for**: EXEC‚ÜíPLAN handoff
- **Framework**: Playwright

#### Verification Checklist
- [ ] Unit tests executed: `npm run test:unit`
- [ ] Unit tests passed: [X/X tests]
- [ ] E2E tests executed: `npm run test:e2e`
- [ ] E2E tests passed: [X/X tests]
- [ ] Both test types documented in EXEC‚ÜíPLAN handoff
- [ ] Screenshots captured for E2E test evidence
- [ ] Test results included in handoff "Deliverables Manifest"

**‚ùå BLOCKING**: Cannot create EXEC‚ÜíPLAN handoff without BOTH test types passing.

**Common Mistakes** (from SD-EXPORT-001):
- ‚ùå "Tests exist" ‚â† "Tests passed"
- ‚ùå Running only E2E tests and claiming "all tests passed"
- ‚ùå Marking SD complete before running any tests
- ‚ùå Creating handoff without test evidence documentation
- ‚úÖ Run BOTH unit AND E2E tests explicitly
- ‚úÖ Document pass/fail counts in handoff
- ‚úÖ Include screenshots for visual evidence

### Why This Matters
- **SD-EXPORT-001**: 30-minute gap between marking "complete" and discovering tests weren't run
- **SD-EVA-MEETING-002**: 67% E2E failure rate revealed only when tests finally executed
- **Impact**: Testing enforcement prevents claiming "done" without proof

## Sub-Agent Auto-Trigger Enforcement (MANDATORY)

**Sub-Agent Auto-Trigger Enforcement**: Sub-agents MUST trigger automatically, not manually.

**EXEC‚ÜíPLAN Handoff Verification**:
```javascript
// MANDATORY: Check for QA execution
const { data: qaResults } = await supabase
  .from('sub_agent_execution_results')
  .select('*')
  .eq('sd_id', sd_id)
  .eq('sub_agent_code', 'TESTING')
  .order('created_at', { ascending: false })
  .limit(1);

if (!qaResults || qaResults.verdict === 'BLOCKED') {
  // BLOCK handoff
  process.exit(1);
}
```

**Complete Pattern**: See `docs/reference/sub-agent-automation.md`

## User Story E2E Test Mapping (MANDATORY)

**User Story E2E Test Mapping (MANDATORY)**: E2E tests MUST map to user stories explicitly.

**Naming Convention**: Every test must reference a user story:
```typescript
test('US-001: User can create new venture', async ({ page }) => {
  // Test implementation
});
```

**Coverage Formula**: (E2E Tests with US-XXX / Total User Stories) √ó 100
**Minimum Requirement**: 100% coverage (every user story MUST have ‚â•1 E2E test)

**QA Director Verification**: Automatically blocks handoff if coverage < 100%

**Examples & Patterns**: See `docs/reference/user-story-e2e-mapping.md`

## LEAD Code Review for UI/UX SDs

## LEAD Code Review Requirement (For UI/UX SDs)

**Evidence from Retrospectives**: Critical pattern from SD-UAT-002 saved hours.

### When Code Review is MANDATORY

**For SDs claiming** UI/UX issues or improvements.

### Why Code Review First?

**Success Story** (SD-UAT-002):
> "LEAD challenged 5 claimed issues, validated only 2. Saved 3-4 hours of unnecessary work."

### Process:
1. Receive SD with UI/UX claims
2. Read actual source code (don't trust claims)
3. Verify each claim against implementation
4. Reject false claims, document findings
5. Update SD scope and priority

## üìö Documentation Platform Integration

**Documentation Platform**: AI Documentation Generation System integrated into LEO Protocol.

**Auto-Triggers**: SD completion, EXEC‚ÜíPLAN handoff, retrospective creation
**EXEC Requirement**: Generate docs before handoff: `node scripts/generate-workflow-docs.js --sd-id <SD-ID>`
**Dashboard**: `/ai-docs-admin` to review and publish

**Complete Guide**: See `docs/reference/documentation-platform.md`

## E2E Testing: Dev Mode vs Preview Mode

**E2E Testing Mode**: Default to dev mode (port 5173) for reliable tests.

**Issue**: Preview mode (4173) may have rendering problems
**Solution**: Use dev mode for tests, preview only for production validation
```typescript
baseURL: 'http://localhost:5173'  // Dev mode
```

**Full Guide**: See `docs/reference/e2e-testing-modes.md`

## Handoff Creation: RLS Bypass Pattern

**Handoff RLS Bypass**: Use direct PostgreSQL to bypass RLS policies.

**Issue**: RLS blocks INSERT with ANON_KEY
**Solution**: Direct connection via `createDatabaseClient` helper
```javascript
import { createDatabaseClient } from '../lib/supabase-connection.js';
const client = await createDatabaseClient('engineer', { verify: true });
```

**Full Pattern**: See `docs/reference/handoff-rls-bypass.md`

## Retrospective Table Schema Reference

**Retrospective Schema**: Critical field mappings to prevent constraint errors.

**Quick Reference:**
- `generated_by`: Must be 'MANUAL'
- `status`: Must be 'PUBLISHED'
- `team_satisfaction`: 1-10 scale (NOT 0-100)
- Array fields: Use arrays, NOT JSON.stringify()
- Boolean fields: true/false, NOT integers

**Common Errors**:
- Column "lessons_learned" not found ‚Üí Use `key_learnings`
- Malformed array literal ‚Üí Remove JSON.stringify()
- team_satisfaction_check violation ‚Üí Use 1-10 scale

**Complete Schema**: See `docs/reference/retrospective-schema.md`

## Database Trigger Management for Special Cases

**Database Trigger Management**: Temporary trigger disable for special cases (infrastructure/protocol SDs).

**Safe Pattern**:
```javascript
// Step 1: Disable trigger
await client.query('ALTER TABLE ... DISABLE TRIGGER trigger_name');

// Step 2: Critical operation
await client.query('UPDATE ...');

// Step 3: Re-enable (ALWAYS in finally block)
await client.query('ALTER TABLE ... ENABLE TRIGGER trigger_name');
```

**When to Use**: Legitimate special cases, RLS blocking trigger validation, no other solution available

**Complete Pattern**: See `docs/reference/trigger-management.md`

## Proactive Context Monitoring

**Context Monitoring**: Report context health in EVERY handoff.

**Status Thresholds**:
- HEALTHY ‚úÖ: 0-140K tokens (0-70%)
- WARNING ‚ö†Ô∏è: 140K-180K (70-90%) - Consider compaction
- CRITICAL üî¥: 180K-190K (90-95%) - MUST compact before handoff
- EMERGENCY üö®: >190K (>95%) - BLOCKED

**Handoff Section Required**:
```markdown
## Context Health
**Current Usage**: X tokens (Y% of 200K budget)
**Status**: HEALTHY/WARNING/CRITICAL
**Recommendation**: [action if needed]
```

**Complete Guide**: See `docs/reference/context-monitoring.md`

## Database Query Best Practices

**Database Query Efficiency**: Smart querying saves 5K-10K tokens per SD.

**Quick Rules:**
1. **Select specific columns** only (not `SELECT *`)
2. **Limit results** with `.limit(5)` for summaries
3. **Use Read tool** with offset/limit for large files
4. **Summarize results**, don't dump full objects
5. **Batch related reads** for parallel execution

**Expected Impact**: 90-98% token reduction per query

**Examples & Patterns**: See `docs/reference/database-best-practices.md`

## Sub-Agent Report Compression System

**Sub-Agent Report Compression**: Intelligent tiering preserves critical context while reducing token usage by 70-90%.

**Quick Reference:**
- **TIER 1 (CRITICAL)**: Full detail preserved for blockers/failures
- **TIER 2 (IMPORTANT)**: Structured summary with warnings
- **TIER 3 (INFORMATIONAL)**: One-line summary for passing validations

**Phase Relevance**: Different sub-agents matter more in different phases
**Automatic Retrieval**: Full reports fetched when needed (PLAN supervisor, retrospectives, debugging)

**Full Guide**: See `docs/reference/sub-agent-compression.md`

## Database-First Enforcement - Expanded

**Database-First Enforcement (MANDATORY)**:

**‚ùå NEVER create**: Strategic Directive files, PRD files, Retrospective files, Handoff documents, Verification reports

**‚úÖ REQUIRED**: All data in database tables only
- SDs ‚Üí `strategic_directives_v2`
- PRDs ‚Üí `product_requirements_v2`
- Retrospectives ‚Üí `retrospectives`
- Handoffs ‚Üí `sd_phase_handoffs`

**Why**: Single source of truth, real-time updates, automated tracking, no file sync issues

**Verification**: `find . -name "SD-*.md" -o -name "PRD-*.md"` should return ONLY legacy files

## üõ°Ô∏è LEAD Pre-Approval Strategic Validation Gate

### MANDATORY Before Approving ANY Strategic Directive

LEAD MUST answer these questions BEFORE approval:

1. **Need Validation**: Is this solving a real user problem or perceived problem?
2. **Solution Assessment**: Does the proposed solution align with business objectives?
3. **Existing Tools**: Can we leverage existing tools/infrastructure instead of building new?
4. **Value Analysis**: Does the expected value justify the development effort?
5. **Feasibility Review**: Are there any technical or resource constraints that make this infeasible?
6. **Risk Assessment**: What are the key risks and how are they mitigated?

**Approval Criteria**:
- Real user/business problem identified
- Solution is technically feasible
- Resources are available or can be allocated
- Risks are acceptable and documented
- Expected value justifies effort

**SCOPE LOCK**: Once LEAD approves an SD, the scope is LOCKED. LEAD commits to delivering the approved scope. LEAD may NOT:
- ‚ùå Re-evaluate "do we really need this?" during final approval
- ‚ùå Reduce scope after EXEC phase begins without critical justification
- ‚ùå Defer work unilaterally during verification
- ‚ùå Mark SD complete if PRD requirements not met

**Exception**: LEAD may adjust scope mid-execution ONLY if:
1. Critical technical blocker discovered (true impossibility, not difficulty)
2. External business priorities changed dramatically (documented)
3. Explicit human approval obtained
4. New SD created for all deferred work (no silent scope reduction)


## Testing Tier Strategy (Updated)


## Testing Requirements - Dual Test Execution (UPDATED)

**Philosophy**: Comprehensive testing = Unit tests (logic) + E2E tests (user experience)

### Tier 1: Smoke Tests (MANDATORY) ‚úÖ
- **Requirement**: BOTH unit tests AND E2E tests must pass
- **Commands**:
  - Unit: `npm run test:unit` (Vitest - business logic)
  - E2E: `npm run test:e2e` (Playwright - user flows)
- **Approval**: **BOTH test types REQUIRED for PLAN‚ÜíLEAD approval**
- **Execution Time**: Combined <5 minutes for smoke-level tests
- **Coverage**:
  - Unit: Service layer, business logic, utilities
  - E2E: Critical user paths, authentication, navigation

### Tier 2: Comprehensive Testing (RECOMMENDED) üìã
- **Requirement**: Full test suite with deep coverage
- **Commands**:
  - Unit: `npm run test:unit:coverage` (50%+ coverage target)
  - E2E: All Playwright tests (30-50 scenarios)
  - Integration: `npm run test:integration`
  - A11y: `npm run test:a11y`
- **Approval**: Nice to have, **NOT blocking** but highly recommended
- **Timing**: Can be refined post-deployment

### Tier 3: Manual Testing (SITUATIONAL) üîç
- **UI changes**: Visual regression testing
- **Complex flows**: Multi-step wizards, payment flows
- **Edge cases**: Rare scenarios not covered by automation

### ‚ö†Ô∏è What Changed (From Protocol Enhancement)
**Before**: "Tier 1 = 3-5 tests, <60s" (ambiguous - which tests?)
**After**: "Tier 1 = Unit tests + E2E tests (explicit frameworks, explicit commands)"

**Lesson Learned**: SD-AGENT-ADMIN-002 testing oversight (ran E2E only, missed unit test failures)


## Database Migration Validation - Two-Phase Approach

**Database Migration Validation - Two-Phase Approach (MANDATORY)**:

**Phase 1: Static File Validation** (always runs):
- Migration files exist for SD-ID
- SQL syntax is valid
- Required patterns present (CREATE TABLE, ALTER TABLE)
- Cross-schema foreign keys detected

**Phase 2: Database Verification** (optional, via `--verify-db`):
- Tables mentioned in migration actually exist
- Tables are accessible (RLS policies)
- Seed data was inserted (with `--check-seed-data`)

**Commands**:
```bash
# Basic validation (file-only)
node scripts/validate-migration-files.js <SD-ID>

# Full validation (file + database + seed data)
node scripts/validate-migration-files.js <SD-ID> --verify-db --check-seed-data
```

**Complete Guide**: See `docs/database-migration-validation-guide.md`

## Playwright MCP Integration

## üé≠ Playwright MCP Integration

**Status**: ‚úÖ READY (Installed 2025-10-12)

### Overview
Playwright MCP (Model Context Protocol) provides browser automation capabilities for testing, scraping, and UI verification.

### Installed Components
- **Chrome**: Google Chrome browser for MCP operations
- **Chromium**: Chromium 141.0.7390.37 (build 1194) for standard Playwright tests
- **Chromium Headless Shell**: Headless browser for CI/CD pipelines
- **System Dependencies**: All required Linux libraries installed

### Available MCP Tools

#### Navigation
- `mcp__playwright__browser_navigate` - Navigate to URL
- `mcp__playwright__browser_navigate_back` - Go back to previous page

#### Interaction
- `mcp__playwright__browser_click` - Click elements
- `mcp__playwright__browser_fill` - Fill form fields
- `mcp__playwright__browser_select` - Select dropdown options
- `mcp__playwright__browser_hover` - Hover over elements
- `mcp__playwright__browser_type` - Type text into elements

#### Verification
- `mcp__playwright__browser_snapshot` - Capture accessibility snapshot
- `mcp__playwright__browser_take_screenshot` - Take screenshots
- `mcp__playwright__browser_evaluate` - Execute JavaScript

#### Management
- `mcp__playwright__browser_close` - Close browser
- `mcp__playwright__browser_tabs` - Manage tabs

### Testing Integration

**When to Use Playwright MCP**:
1. ‚úÖ Visual regression testing
2. ‚úÖ UI component verification
3. ‚úÖ Screenshot capture for evidence
4. ‚úÖ Accessibility tree validation
5. ‚úÖ Cross-browser testing

**When to Use Standard Playwright**:
1. ‚úÖ E2E test suites (`npm run test:e2e`)
2. ‚úÖ CI/CD pipeline tests
3. ‚úÖ Automated test runs
4. ‚úÖ User story validation

### Usage Example

```javascript
// Using Playwright MCP for visual verification
await mcp__playwright__browser_navigate({ url: 'http://localhost:3000/dashboard' });
await mcp__playwright__browser_snapshot(); // Get accessibility tree
await mcp__playwright__browser_take_screenshot({ name: 'dashboard-state' });
await mcp__playwright__browser_click({ element: 'Submit button', ref: 'e5' });
```

### QA Director Integration

The QA Engineering Director sub-agent now has access to:
- Playwright MCP for visual testing
- Standard Playwright for E2E automation
- Both Chrome (MCP) and Chromium (tests) browsers

**Complete Guide**: See `docs/reference/playwright-mcp-guide.md`

## Playwright Server Management Best Practice

### Best Practice: Playwright-Managed Dev Server

**Evidence**: SD-AGENT-MIGRATION-001 - Always let Playwright manage the dev server lifecycle for consistent port and automated testing workflows.

**DO NOT** manually start dev servers before E2E tests. Let Playwright manage it.

#### Configuration (playwright.config.ts)
```typescript
webServer: {
  command: 'npm run dev -- --port 8080',
  port: 8080,
  reuseExistingServer: true,  // Reuse if already running
  timeout: 120_000,            // 2 min startup timeout
}
```

#### Why This Works
- **Consistent Port**: All tests use same port (8080)
- **Auto-Lifecycle**: Server starts before tests, stops after
- **CI/CD Compatible**: Works in automated environments
- **Local Dev Friendly**: `reuseExistingServer` prevents killing your dev server

#### Anti-Patterns
- ‚ùå Starting dev server manually on inconsistent ports
- ‚ùå Forgetting to stop old servers (port conflicts)
- ‚ùå Hardcoding URLs without using `baseURL` from config
- ‚ùå Running tests while manually managing server lifecycle

#### Example Test Run
```bash
# Playwright handles everything
npm run test:e2e

# Playwright:
# 1. Checks if server already running on 8080
# 2. Starts server if needed: npm run dev -- --port 8080
# 3. Waits for server to be ready
# 4. Runs tests
# 5. Keeps server running (reuseExistingServer: true)
```

#### Manual Server Check (if needed)
```bash
# Kill old servers
lsof -i :8080 | grep LISTEN | awk '{print $2}' | xargs kill -9

# Let Playwright manage
npm run test:e2e
```

## Database Migration Pre-Flight Checklist

**Database Migration Pre-Flight Checklist (MANDATORY)**:

**Before attempting ANY migration**:
1. Read established pattern: `scripts/lib/supabase-connection.js`
2. Verify connection: Region aws-1, Port 5432, SSL config
3. Use helper functions: `createDatabaseClient`, `splitPostgreSQLStatements`
4. Validate migration file: No cross-schema FKs, correct RLS syntax
5. Handle conflicts: Check existing tables, use CASCADE carefully

**Anti-Patterns to AVOID**:
- Using psql without understanding connection format
- Trial-and-error with regions/ports/SSL
- Not handling "already exists" errors

**Complete Guide**: See `docs/reference/migration-preflight.md`

## Native Claude Code Sub-Agent Integration

## ü§ñ Native Claude Code Sub-Agent Integration

**Status**: ‚úÖ TESTED & DOCUMENTED (2025-10-12)

### Overview
Claude Code supports native sub-agents via the Task tool. These sub-agents work alongside the database-driven LEO Protocol orchestration system in a hybrid architecture.

### Critical Dependency: ripgrep
**REQUIRED**: `ripgrep` (command: `rg`) must be installed for agent discovery.
```bash
# Check if installed
which rg

# Install on Ubuntu/Debian WSL2
sudo apt update && sudo apt install ripgrep -y
```

**Without ripgrep**: Agent discovery fails silently (no error messages, agents simply won't be found).

### Discovery Mechanism
1. Claude Code uses ripgrep to scan `.claude/agents/*.md` files
2. YAML frontmatter is parsed for agent configuration
3. Successfully discovered agents appear in `/agents` menu
4. Verify with: `/agents` command

### Three Proven Invocation Patterns

#### Pattern 1: Advisory Mode ‚úÖ (RECOMMENDED for guidance)
**Use Case**: General architecture questions, no SD context

**Example**:
```
User: "What's the best way to structure a many-to-many relationship?"
Main Agent ‚Üí Task(database-agent) ‚Üí Expert Guidance
```

**Performance**: ~3 seconds, 0 database records
**Best For**: Design exploration, best practices, architectural guidance

---

#### Pattern 2: Targeted Validation ‚ö†Ô∏è (NOT WORKING - experimental)
**Use Case**: Single sub-agent validation with SD context

**Expected Flow**:
```
Main Agent ‚Üí Task(sub-agent) ‚Üí Bash(script) ‚Üí Database Storage
```

**Current Issue**: Sub-agents provide analysis but don't reliably invoke Bash tools
**Status**: Documented limitation, use Pattern 3 instead

---

#### Pattern 3: Direct Orchestration ‚úÖ (PRODUCTION-READY)
**Use Case**: Phase-based validation, multiple sub-agents, production workflows

**Example**:
```bash
node scripts/orchestrate-phase-subagents.js PLAN_VERIFY SD-MONITORING-001
```

**Performance**: ~2 seconds (parallel execution), 4 database records
**Best For**: Phase validation, multi-agent orchestration, audit trails

### Decision Matrix

| Scenario | Pattern | Command |
|----------|---------|---------|
| "What's the best way to...?" | 1 (Advisory) | Natural language query |
| "How should I structure...?" | 1 (Advisory) | Natural language query |
| "Validate SD-XXX" | 3 (Direct Script) | `node scripts/orchestrate-phase-subagents.js` |
| "Run PLAN_VERIFY for SD-XXX" | 3 (Direct Script) | `node scripts/orchestrate-phase-subagents.js PLAN_VERIFY SD-XXX` |

### Invocation Mechanism (Task Tool)

**What WORKS** ‚úÖ:
- **Task tool**: Main agent uses Task tool to delegate to sub-agents
- From user perspective: Natural language (transparent delegation)
- Behind the scenes: `Task(subagent_type: "database-agent", description: "...", prompt: "...")`

**What DOESN'T WORK** ‚ùå:
- Automatic delegation (typing keywords)
- @-mention syntax (`@database-agent` or `@agent-database-agent`)

### Integration with LEO Protocol 5-Phase Workflow

**LEAD Pre-Approval**:
- Pattern 1 for design questions
- Pattern 3 for validation: `node scripts/orchestrate-phase-subagents.js LEAD_PRE_APPROVAL SD-XXX`

**PLAN PRD Creation**:
- Pattern 1 for architecture guidance
- Pattern 3 for validation: `node scripts/orchestrate-phase-subagents.js PLAN_PRD SD-XXX`

**EXEC Implementation**:
- Pattern 1 for implementation questions
- Pattern 3 for final validation: `node lib/sub-agent-executor.js DATABASE SD-XXX`

**PLAN Verification**:
- Pattern 3 (always): `node scripts/orchestrate-phase-subagents.js PLAN_VERIFY SD-XXX`

**LEAD Final Approval**:
- Pattern 3 for retrospective: `node scripts/orchestrate-phase-subagents.js LEAD_FINAL SD-XXX`

### Active Native Sub-Agents

**Currently Available**:
- `database-agent` - Principal Database Architect (tested, working)
- `test-agent` - Test agent for diagnostics (tested, working)

**Agent File Location**: `.claude/agents/*.md`

**Example Agent Structure**:
```yaml
---
name: database-agent
description: "MUST BE USED PROACTIVELY for all database tasks. Handles schema design, Supabase migrations, RLS policies, SQL validation, and architecture. Trigger on keywords: database, migration, schema, table, RLS, SQL, Postgres."
tools: Bash, Read, Write
model: inherit
---
```

### Performance Metrics

| Operation | Pattern 1 | Pattern 3 |
|-----------|-----------|-----------|
| Invocation | <1s | <1s |
| Execution | 2-5s | 1-3s |
| Database Writes | 0 | 1-6 |
| Token Usage | Medium | Low |
| Best For | Guidance | Production |

### Troubleshooting

**Agent not appearing in /agents menu**:
1. Check ripgrep installed: `which rg`
2. Verify file location: `.claude/agents/*.md`
3. Validate YAML frontmatter
4. Restart Claude Code

**Sub-agent not executing scripts** (Pattern 2 issue):
- Use Pattern 3 (Direct Orchestration) instead
- Main agent invokes scripts directly via Bash tool

### Complete Documentation

**Detailed Guides**:
- `docs/reference/native-sub-agent-invocation.md` - Discovery, invocation, troubleshooting (420 lines)
- `docs/guides/hybrid-sub-agent-workflow.md` - Decision matrix, patterns, integration (450 lines)

**Test Results**: All patterns comprehensively tested (2025-10-12)
**Production Status**: Patterns 1 & 3 ready, Pattern 2 experimental

## Test Execution Timeout Handling

## üïê Test Execution Timeout Handling

**Problem**: Test suites timing out in WSL2/resource-constrained environments
**Solution**: 4-step fallback strategy with clear escalation path

### Quick Reference

**Timeout Thresholds**:
- Unit Tests: 2 min (native) / 3 min (WSL2)
- E2E Tests: 5 min (native) / 7 min (WSL2)

**4-Step Fallback Strategy**:
1. **Quick Validation** (60s): `vitest run --no-coverage`
2. **Focused Testing** (30s): `vitest run --grep="ComponentName"`
3. **Manual Smoke Test** (5 min): Navigate + test critical paths
4. **CI/CD-Only** (7-10 min): Push to branch, document GitHub Actions URL

**When to Escalate**: All 4 steps timeout ‚Üí LEAD investigation

**Complete Guide**: `docs/reference/test-timeout-handling.md` (200 lines)

**Evidence**: SD-SETTINGS-2025-10-12 - Unit tests timed out after 2 min in WSL2
**Impact**: Prevents 30-60 min of blocked time per timeout occurrence

## Checkpoint Pattern for Large SDs

## üìç Checkpoint Pattern for Large SDs

**Problem**: Large SDs (12+ user stories) consume excessive context, high rework risk
**Solution**: Break into 3-4 checkpoints with interim validation

### Quick Reference

**When to Use**:
- 9+ user stories ‚Üí Recommended (3 checkpoints)
- 13+ user stories ‚Üí Mandatory (4+ checkpoints)
- >1500 LOC ‚Üí Recommended
- >8 hours estimated ‚Üí Recommended

**Checkpoint Structure** (Example: SD with 12 US):
- **Checkpoint 1**: US-001 to US-004 (Component creation, 2-3 hours)
- **Checkpoint 2**: US-005 to US-008 (Feature implementation, 2-3 hours)
- **Checkpoint 3**: US-009 to US-012 (Testing + docs, 2-3 hours)

**Benefits**:
- 30-40% reduction in context consumption
- 50% faster debugging (smaller change sets)
- Incremental progress visibility
- Pause/resume flexibility

**Complete Guide**: `docs/reference/checkpoint-pattern.md` (150 lines)

**Evidence**: SD-SETTINGS-2025-10-12 analysis - Would have reduced context from 85K to 60K tokens
**Impact**: Saves 2-4 hours per large SD through early error detection

## Session Continuation Best Practices

## üîÑ Session Continuation Best Practices

**Problem**: Context limits require session handoffs, risking progress loss
**Solution**: Proven patterns from successful SD continuation

### Quick Reference

**Before Ending Session**:
1. Update TodoWrite with current task marked "in_progress"
2. Document exact resume point (file, line, next step)
3. Create checkpoint commit if mid-implementation
4. Report context health (usage %, status, recommendation)

**When Resuming**:
1. Read continuation summary
2. Verify application state: `cd /path && pwd`, `git status`
3. Read current files mentioned in summary
4. Check build status: `npm run type-check && npm run lint`
5. Confirm resume point with user

**Key Patterns**:
- **Comprehensive Summary**: 9 sections (request, concepts, files, errors, solutions, messages, tasks, current work, next step)
- **Todo Maintenance**: Update after EACH milestone, not in batches
- **Incremental Implementation**: One component at a time with verification
- **Pre-Verification Checklist**: App check, GitHub remote, URL, component path

**Complete Guide**: `docs/reference/claude-code-session-continuation.md` (100 lines)

**Evidence**: SD-SETTINGS-2025-10-12 - Zero "wrong directory" errors, seamless continuation
**Impact**: 90% reduction in resume confusion, 95% accuracy in state reconstruction

## Parallel Execution Optimization

## ‚ö° Parallel Execution Optimization

**Problem**: Sequential execution wastes time when operations are independent
**Solution**: Guidelines for safe parallel tool execution

### Quick Reference

**Safe for Parallel** ‚úÖ:
- Reading multiple independent files
- Multiple read-only Git commands (`git status`, `git log`, `git remote -v`)
- Database queries from different tables (read-only)
- Sub-agent execution (independent assessments)

**NOT Safe for Parallel** ‚ùå:
- Write operations (Edit, Write tools)
- Database mutations (INSERT, UPDATE, DELETE)
- Sequential dependencies (build before test)
- Git operations that modify state

**Time Savings Examples**:
- File reading: 2-3s saved per file after first (parallel vs sequential)
- Line count: 3-6s saved (`wc -l file1 file2 file3` vs 3 separate commands)
- Sub-agents: 1-2 min saved (4 sub-agents in 30s vs 2min sequential)

**Decision Rule**:
- Independent operations + >2s saved + <30K combined output ‚Üí Use parallel
- Any dependencies or order requirements ‚Üí Use sequential

**Complete Guide**: `docs/reference/parallel-execution-opportunities.md` (80 lines)

**Evidence**: SD-SETTINGS-2025-10-12 - Identified missed opportunities (6-9s in file reads)
**Impact**: 2-5 min saved per SD through parallelization

## Progressive Testing Strategy

## üß™ Progressive Testing Strategy

**Problem**: End-of-phase testing causes late discovery of errors
**Solution**: Test after each user story or major component

### Quick Reference

**After Each User Story**:
```bash
vitest run --no-coverage --grep="US-001"  # Quick validation
```

**After Each Component**:
```bash
npm run type-check  # TypeScript validation
npm run lint        # Code quality check
npm run build:skip-checks  # Build validation
```

**Before EXEC‚ÜíPLAN Handoff**:
```bash
npm run test:unit   # Full unit suite
npm run test:e2e    # Full E2E suite
```

**Benefits**:
- Early error detection (smaller blast radius)
- Faster feedback loop
- Less context consumed by debugging
- Can proceed with partial completion if blocked

**Testing Decision Matrix**:
| Scenario | Command | Timeout | When |
|----------|---------|---------|------|
| Quick validation | `vitest --no-coverage` | 60s | After each component |
| Smoke tests | `vitest --grep="US-"` | 90s | Handoff requirement |
| Full suite | `npm run test:unit` | 120s | PLAN verification |

**Complete Guide**: See `docs/reference/test-timeout-handling.md` (Section: Progressive Testing)

**Evidence**: Pattern from successful SDs - Early testing catches 80% of issues before handoff
**Impact**: 50% reduction in late-stage debugging time

## Database Agent Error-Triggered Invocation

## üö® Database Agent Error-Triggered Invocation

**Problem**: Agents attempt workarounds when encountering database errors instead of using database agent
**Solution**: Immediate database agent invocation on ANY database error

### Error Patterns That MUST Trigger Database Agent

**PostgreSQL Errors** (immediate database agent call):
- `column "X" does not exist` ‚Üí Database agent (schema validation)
- `relation "X" does not exist` ‚Üí Database agent (table validation)
- `table "X" already exists` ‚Üí Database agent (migration conflict)
- `foreign key constraint` errors ‚Üí Database agent (relationship validation)
- `permission denied for table` ‚Üí Database agent (RLS policy issue)
- `syntax error at or near` (in SQL) ‚Üí Database agent (SQL validation)
- `trigger function` errors ‚Üí Database agent (function schema mismatch)
- `duplicate key value violates unique constraint` ‚Üí Database agent (data/schema issue)

**Supabase-Specific Errors**:
- RLS policy failures ‚Üí Database agent (security architecture)
- Connection string issues ‚Üí Database agent (connection helper)
- Cross-schema foreign key warnings ‚Üí Database agent (architecture violation)
- `row level security` errors ‚Üí Database agent (policy design)

**Migration Errors**:
- ANY migration file execution failure ‚Üí Database agent (don't retry manually)
- `CREATE TABLE IF NOT EXISTS` silent failures ‚Üí Database agent (conflict detection)
- Schema version mismatches ‚Üí Database agent (version management)

### Error Response Protocol

**When ANY database error occurs**:

‚ùå **DO NOT**:
- Attempt manual fixes
- Try workarounds
- Modify SQL without validation
- Skip table/column verification
- Use trial-and-error debugging

‚úÖ **DO IMMEDIATELY**:
1. STOP current approach
2. Document the exact error message
3. Invoke database agent:
   ```bash
   node lib/sub-agent-executor.js DATABASE <SD-ID>
   ```
4. Provide error context to database agent
5. Implement database agent's solution

**Pattern**: Database error detected ‚Üí Invoke database agent ‚Üí Wait for diagnosis ‚Üí Implement solution

**Evidence**: 74 retrospectives analyzed, 3 failure patterns from workaround attempts
**Impact**: Eliminates technical debt from band-aid solutions, saves 2-4 hours per database issue

## Database Workaround Anti-Patterns (NEVER DO THIS)

## ‚õî Database Workaround Anti-Patterns (NEVER DO THIS)

**Problem**: Common workarounds create technical debt and mask root causes
**Solution**: Block these patterns, use database agent instead

### Anti-Pattern Catalog

**‚ùå Anti-Pattern 1: Table Rename Workarounds**
```sql
-- WRONG: Renaming table to avoid conflict
CREATE TABLE webhook_events_new ...

-- RIGHT: Use database agent to diagnose why table exists
node lib/sub-agent-executor.js DATABASE <SD-ID>
```

**‚ùå Anti-Pattern 2: Column Existence Guards**
```sql
-- WRONG: Adding columns conditionally without knowing schema
ALTER TABLE ... ADD COLUMN IF NOT EXISTS ...

-- RIGHT: Database agent validates schema FIRST
```

**‚ùå Anti-Pattern 3: RLS Policy Bypassing**
```typescript
// WRONG: Using service role key to bypass RLS
const supabase = createClient(url, SERVICE_ROLE_KEY)

// RIGHT: Database agent designs proper RLS policies
```

**‚ùå Anti-Pattern 4: Manual SQL Trial-and-Error**
```bash
# WRONG: Trying different SQL variations manually
psql -c "CREATE TABLE ..." # fails
psql -c "CREATE TABLE IF NOT EXISTS ..." # fails
psql -c "DROP TABLE ... CASCADE; CREATE TABLE ..." # dangerous

# RIGHT: Database agent analyzes schema state FIRST
```

**‚ùå Anti-Pattern 5: Skipping Migration Validation**
```javascript
// WRONG: Executing migration without validation
await executeMigration(sql) // Hope it works

// RIGHT: Database agent validates migration safety
```

**‚ùå Anti-Pattern 6: Connection String Trial-and-Error**
```javascript
// WRONG: Trying different regions/ports/SSL configs
postgresql://postgres.PROJECT:PASSWORD@aws-0... // fails
postgresql://postgres.PROJECT:PASSWORD@aws-1... // try this?

// RIGHT: Database agent provides correct connection pattern
// Uses: scripts/lib/supabase-connection.js
```

**‚ùå Anti-Pattern 7: Ignoring Schema Conflicts**
```javascript
// WRONG: Proceeding despite "table exists" warnings
// "It says it already exists, let me just use it"

// RIGHT: Database agent investigates conflict and validates schema match
```

### Detection Rules

**BLOCKED PATTERNS** (must use database agent instead):
- Renaming tables to avoid conflicts
- Adding IF NOT EXISTS without schema knowledge
- Using SERVICE_ROLE_KEY to bypass RLS
- Trial-and-error with connection strings
- Multiple psql attempts without diagnosis
- Modifying migrations after first failure
- Proceeding with "table exists" warnings without validation

**Evidence**: SD-AGENT-ADMIN-003 (schema mismatch), SD-1A (multiple schema issues), SD-041C (table conflict)
**Impact**: Prevents 100% of workaround-related technical debt

## Database Agent First-Responder Checklist

## ‚úÖ Database Agent First-Responder Checklist

**Problem**: Database work attempted without validation, leading to errors
**Solution**: Proactive database agent invocation BEFORE attempting database work

### BEFORE Attempting ANY Database Work

**Pre-Database-Work Checklist** (MANDATORY):

**Before PLANNING database work**:
- [ ] Invoke database agent for schema review
- [ ] Verify tables mentioned in PRD exist
- [ ] Check for naming conflicts (existing tables)
- [ ] Validate RLS policy requirements
- [ ] Confirm correct database target (EHG vs EHG_Engineer)

**Before EXECUTING database migrations**:
- [ ] Database agent validated migration file
- [ ] Schema conflicts identified and resolved
- [ ] Connection helper pattern confirmed (`scripts/lib/supabase-connection.js`)
- [ ] Rollback plan documented
- [ ] Test environment validated

**Before WRITING database queries**:
- [ ] Database agent confirmed table schema
- [ ] Column names verified (not assumed)
- [ ] RLS policies understood
- [ ] Query performance considerations reviewed

**When in doubt**: ALWAYS invoke database agent FIRST

### Integration Points

**PLAN Phase (PRD Creation)**:
```markdown
## PLAN Pre-EXEC Checklist (ENHANCED)

### Database Dependencies ‚úÖ
- [ ] **FIRST**: Invoke database agent for schema validation
- [ ] Identify all data dependencies in PRD
- [ ] Verify tables/columns exist OR create migration plan
- [ ] Document database agent findings in PLAN‚ÜíEXEC handoff
- [ ] If ANY issues found: Escalate to LEAD with database agent report
```

**EXEC Phase (Implementation)**:
```markdown
## EXEC Pre-Implementation Checklist (NEW)

### Database Operations ‚úÖ
- [ ] If SD involves database work: Database agent invoked? YES/NO
- [ ] Schema validation complete: YES/NO
- [ ] Migration safety confirmed: YES/NO
- [ ] Connection pattern verified: YES/NO
- [ ] RLS policies designed: YES/NO (if needed)
```

**Success Pattern Examples**:
- SD-041C: Database agent identified table conflict early, proper rename implemented
- SD-BACKEND-002C: Database agent provided migration pattern, 45-minute execution success
- SD-AGENT-ADMIN-003: Database agent caught trigger function schema mismatch before deployment

**Evidence**: 12 success patterns from proactive database agent usage
**Impact**: Zero schema conflicts, 100% migration success rate when database agent used first

## Database Agent Integration Requirements

## üîß Database Agent Integration Requirements

**Problem**: Database agent treated as last resort instead of first responder
**Solution**: Mandatory integration at key workflow checkpoints

### Mandatory Invocation Points

**LEAD Pre-Approval Phase**:
- IF SD mentions: database, migration, schema, table, RLS, SQL, Postgres
- THEN: Database agent included in parallel sub-agent execution
- ```bash
  node lib/sub-agent-executor.js DATABASE <SD-ID>
  ```

**PLAN PRD Creation Phase**:
- Database agent runs FIRST for any SD with data dependencies
- Validates schema before creating PRD
- Documents table existence, RLS requirements, migration needs
- BLOCKS PRD creation if critical database issues found

**EXEC Implementation Phase**:
- Database agent validates schema BEFORE implementation starts
- Consulted for ANY database error encountered
- Provides migration patterns and connection helpers
- Reviews database changes before commit

**PLAN Verification Phase**:
- Database agent verifies migrations executed correctly
- Validates schema matches documentation
- Confirms RLS policies working as designed

### Behavior Change Summary

**Before (Anti-Pattern)**:
1. Agent encounters database error
2. Agent tries manual fix / workaround
3. Fix fails or creates technical debt
4. User intervenes: "Use database agent!"
5. Database agent called
6. Proper solution found (finally)

**After (First-Responder Pattern)**:
1. Agent encounters database task OR database error
2. Agent IMMEDIATELY invokes database agent
3. Database agent diagnoses root cause
4. Proper solution implemented (first try)
5. No workarounds, no technical debt

### Success Metrics

- **Zero workaround attempts** when database errors occur
- **100% database agent usage** for migration work
- **90% reduction** in user reminders to use database agent
- **Zero schema mismatch errors** through proactive validation
- **Faster database operations** (no trial-and-error)

### Key Principle

**DATABASE-FIRST CULTURE**: Database agent is a FIRST RESPONDER, not a LAST RESORT.

**Evidence**: User feedback: "I constantly have to remind that we should use the database subagent"
**Impact**: Eliminates need for manual reminders, establishes proactive database expertise

## Mandatory Handoff Requirements

Every handoff MUST include these 7 elements:
1. Executive Summary
2. Completeness Report
3. Deliverables Manifest
4. Key Decisions & Rationale
5. Known Issues & Risks
6. Resource Utilization
7. Action Items for Receiver

Missing ANY element = AUTOMATIC REJECTION

## üîÑ Unified Handoff System (Database-First)

**Unified Handoff System**: Database-first handoffs via `node scripts/unified-handoff-system.js execute <TYPE> <SD-ID>`

**Types**: LEAD-to-PLAN, PLAN-to-EXEC, EXEC-to-PLAN, PLAN-to-LEAD
**7 Mandatory Elements**: Executive Summary, Completeness Report, Deliverables Manifest, Key Decisions, Known Issues, Resource Utilization, Action Items
**Tables**: `leo_handoff_templates` (structure), `sd_phase_handoffs` (instances)

**Complete Guide**: See `docs/reference/unified-handoff-system.md`


## Sub-Agent System (Database-Driven)

**Active Sub-Agents**: 10 specialist agents for validation, testing, security, and quality

| Code | Name | Priority | Auto-Trigger |
|------|------|----------|--------------|
| DOCMON | Information Architecture Lead | 95 | ‚úÖ |
| GITHUB | DevOps Platform Architect | 90 | ‚úÖ |
| UAT | UAT Test Executor | 90 | ‚ùå |
| RETRO | Continuous Improvement Coach | 85 | ‚úÖ |
| DESIGN | Senior Design Sub-Agent | 70 | ‚úÖ |
| SECURITY | Chief Security Architect | 7 | ‚úÖ |
| DATABASE | Principal Database Architect | 6 | ‚úÖ |
| TESTING | QA Engineering Director | 5 | ‚úÖ |
| PERFORMANCE | Performance Engineering Lead | 4 | ‚úÖ |
| VALIDATION | Principal Systems Analyst | 0 | ‚úÖ |

**Quick Reference**:
- **High Priority** (90+): DOCMON, GITHUB, UAT
- **Quality Gates** (70-85): RETRO, DESIGN
- **Validation** (0-10): SECURITY, DATABASE, TESTING, PERFORMANCE, VALIDATION

**Activation**: Sub-agents trigger automatically on keywords/events. Query `leo_sub_agent_triggers` for complete trigger list.

**Complete Documentation**: See `docs/reference/sub-agent-system.md` for full details, triggers, and activation patterns

### Handoff Templates


#### PLAN ‚Üí EXEC (technical_to_implementation)
Elements: Executive Summary, Completeness Report, Deliverables Manifest, Key Decisions & Rationale, Known Issues & Risks, Resource Utilization, Action Items for Receiver
Required: [object Object], [object Object], [object Object], [object Object]


#### LEAD ‚Üí PLAN (strategic_to_technical)
Elements: Executive Summary, Completeness Report, Deliverables Manifest, Key Decisions & Rationale, Known Issues & Risks, Resource Utilization, Action Items for Receiver
Required: [object Object], [object Object], [object Object]


#### PLAN ‚Üí LEAD (verification_to_approval)
Elements: Executive Summary, Completeness Report, Deliverables Manifest, Key Decisions & Rationale, Known Issues & Risks, Resource Utilization, Action Items for Receiver
Required: [object Object], [object Object], [object Object]


#### EXEC ‚Üí PLAN (implementation_to_verification)
Elements: Executive Summary, Completeness Report, Deliverables Manifest, Key Decisions & Rationale, Known Issues & Risks, Resource Utilization, Action Items for Receiver
Required: [object Object], [object Object], [object Object], [object Object], [object Object], [object Object]


## Validation Rules (From Database)


- **hasADR** (undefined)
  - Severity: undefined
  - Definition: undefined


- **hasInterfaces** (undefined)
  - Severity: undefined
  - Definition: undefined


- **hasTechDesign** (undefined)
  - Severity: undefined
  - Definition: undefined


- **designArtifacts** (undefined)
  - Severity: undefined
  - Definition: undefined


- **dbSchemaReady** (undefined)
  - Severity: undefined
  - Definition: undefined


- **securityScanClean** (undefined)
  - Severity: undefined
  - Definition: undefined


- **riskSpikesClosed** (undefined)
  - Severity: undefined
  - Definition: undefined


- **nfrBudgetsPresent** (undefined)
  - Severity: undefined
  - Definition: undefined


- **coverageTargetSet** (undefined)
  - Severity: undefined
  - Definition: undefined


- **testPlanMatrices** (undefined)
  - Severity: undefined
  - Definition: undefined


- **supervisorChecklistPass** (undefined)
  - Severity: undefined
  - Definition: undefined


## Database Schema Overview

### Core Tables
- `leo_protocols` - Protocol versions and content
- `leo_protocol_sections` - Modular protocol sections
- `leo_agents` - Agent definitions and percentages
- `leo_handoff_templates` - Standardized handoffs
- `leo_sub_agents` - Sub-agent definitions
- `leo_sub_agent_triggers` - Activation rules
- `leo_validation_rules` - Protocol validation

### Key Queries

**Get Current Protocol**:
```sql
SELECT * FROM leo_protocols WHERE status = 'active';
```

**Check Sub-Agent Triggers**:
```sql
SELECT sa.*, t.*
FROM leo_sub_agents sa
JOIN leo_sub_agent_triggers t ON sa.id = t.sub_agent_id
WHERE t.trigger_phrase ILIKE '%keyword%';
```

**Get Handoff Template**:
```sql
SELECT * FROM leo_handoff_templates
WHERE from_agent = 'EXEC' AND to_agent = 'PLAN';
```

## API Endpoints (Database-Backed)

- `GET /api/leo/current` - Current active protocol
- `GET /api/leo/agents` - All agents with percentages
- `GET /api/leo/sub-agents` - Active sub-agents with triggers
- `GET /api/leo/handoffs/:from/:to` - Handoff template
- `POST /api/leo/validate` - Validate against rules

## Key Scripts (Database-Aware)

- `get-latest-leo-protocol-from-db.js` - Get version from database
- `generate-claude-md-from-db.js` - Generate this file
- `migrate-leo-protocols-to-database.js` - Migration tool
- `activate-sub-agents-from-db.js` - Check database triggers

## Compliance Tools

All tools now query database instead of files:

### 1. Version Check
```bash
node scripts/get-latest-leo-protocol-from-db.js
```

### 2. Update CLAUDE.md
```bash
node scripts/generate-claude-md-from-db.js
```

### 3. Validate Handoff
```bash
node scripts/leo-checklist-db.js [agent-name]
```

## üîç PLAN Supervisor Verification

### Overview
PLAN agent now includes supervisor capabilities for final "done done" verification:
- Queries ALL sub-agents for their verification results
- Ensures all requirements are truly met
- Resolves conflicts between sub-agent reports
- Provides confidence scoring and clear pass/fail verdict

### Activation
Trigger PLAN supervisor verification via:
- **Command**: `/leo-verify [what to check]`
- **Script**: `node scripts/plan-supervisor-verification.js --prd PRD-ID`
- **Automatic**: When testing phase completes

### Verification Process
1. **Read-Only Access**: Queries existing sub-agent results (no re-execution)
2. **Summary-First**: Prevents context explosion with tiered reporting
3. **Conflict Resolution**: Priority-based rules (Security > Database > Testing)
4. **Circuit Breakers**: Graceful handling of sub-agent failures
5. **Maximum 3 Iterations**: Prevents infinite verification loops

### Verdicts
- **PASS**: All requirements met, high confidence (‚â•85%)
- **FAIL**: Critical issues or unmet requirements
- **CONDITIONAL_PASS**: Minor issues, needs LEAD review
- **ESCALATE**: Cannot reach consensus, needs LEAD intervention

## Dashboard Integration

Dashboard automatically connects to database:
- Real-time protocol updates via Supabase subscriptions
- Version detection from `leo_protocols` table
- Sub-agent status from `leo_sub_agents` table
- PLAN supervisor verification status
- No file scanning needed

## Important Notes

1. **Database is Source of Truth** - Files are deprecated
2. **Real-time Updates** - Changes reflect immediately
3. **No Version Conflicts** - Single active version enforced
4. **Audit Trail** - All changes tracked in database
5. **WebSocket Updates** - Dashboard stays synchronized
6. **PLAN Supervisor** - Final verification before LEAD approval


## üóÑÔ∏è Supabase Database Operations

### Connection Details
- **Project URL**: https://dedlbzhpgkmetvhbkyzq.supabase.co
- **Project ID**: dedlbzhpgkmetvhbkyzq
- **Connection**: Via Supabase client using environment variables

### Environment Variables Required
```bash
# For EHG application (liapbndqlqxdcgpwntbv)
EHG_SUPABASE_URL=https://liapbndqlqxdcgpwntbv.supabase.co
EHG_SUPABASE_ANON_KEY=[anon-key]
EHG_POOLER_URL=postgresql://postgres.liapbndqlqxdcgpwntbv:[password]@aws-0-us-east-1.pooler.supabase.com:5432/postgres?sslmode=require

# For EHG_Engineer (dedlbzhpgkmetvhbkyzq)
SUPABASE_URL=https://dedlbzhpgkmetvhbkyzq.supabase.co
SUPABASE_ANON_KEY=[anon-key]
SUPABASE_POOLER_URL=postgresql://postgres.dedlbzhpgkmetvhbkyzq:[password]@aws-1-us-east-1.pooler.supabase.com:5432/postgres?sslmode=require
SUPABASE_DB_PASSWORD=Fl!M32DaM00n!1
```


## üîß CRITICAL DEVELOPMENT WORKFLOW

**Development Workflow**: MANDATORY server restart after ANY changes

**Steps**: Kill server ‚Üí Build client (`npm run build:client`) ‚Üí Restart server ‚Üí Hard refresh browser
**Why**: No hot-reloading configured, dist/ serves compiled files
**Commands**: `pkill -f "node server.js" && npm run build:client && PORT=3000 node server.js`

**Complete Guide**: See `docs/reference/development-workflow.md`


## Sub-Agent Parallel Execution

**Overview**: Sub-agents are independent specialists. When multiple sub-agents provide non-overlapping assessments, call them in parallel to reduce latency.

**When Parallel Execution is Beneficial**:

1. **LEAD Initial Assessment**
   - Parallel: Security Architect + Database Architect + Business Analyst
   - Why: Each evaluates different aspects of an SD (security posture, data model feasibility, business alignment)
   - Context sharing: Not required - each has independent assessment criteria

2. **PLAN Supervisor Verification**
   - Parallel: QA Director + Security Architect + Performance Lead + Database Architect
   - Why: Final "done done" check across all quality dimensions simultaneously
   - Context sharing: Not required - each validates their domain independently

3. **EXEC Pre-Implementation Checks**
   - Parallel: Systems Analyst (duplicate check) + Security Architect (auth requirements) + Database Architect (schema changes)
   - Why: Gather all constraints before coding begins
   - Context sharing: Not required - each identifies risks independently

**When Sequential Execution is Required**:

- ‚ùå One sub-agent's output feeds another's input
- ‚ùå Database schema must be reviewed before security assessment
- ‚ùå Any workflow where order creates dependencies

**Implementation Pattern**:

```javascript
// ‚úÖ Parallel - Independent assessments
const results = await Promise.all([
  callSubAgent('security-architect', sd_id),
  callSubAgent('database-architect', sd_id),
  callSubAgent('qa-director', sd_id)
]);

// ‚ùå Sequential - One depends on another
const schema = await callSubAgent('database-architect', sd_id);
const securityReview = await callSubAgent('security-architect', schema); // Needs schema first
```

**Critical Constraints**:
- Each sub-agent receives the same initial context
- Sub-agents cannot see each other's results until all complete
- Aggregate results AFTER all sub-agents finish
- If any sub-agent fails, gracefully handle in aggregation phase

**Benefits**:
- Reduces total verification time (4 sub-agents in 30s vs. 2min sequential)
- No context sharing limitations since assessments are independent
- Each specialist works from fresh context without bias from others


---

*Generated from Database: 2025-10-12*
*Protocol Version: vv4.2.0_story_gates*
*Database-First Architecture: ACTIVE*
