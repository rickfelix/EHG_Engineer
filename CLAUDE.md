# CLAUDE.md - LEO Protocol Workflow Guide for AI Agents

## ‚ö†Ô∏è DO NOT EDIT THIS FILE DIRECTLY

**This file is AUTO-GENERATED from the database.**

## To Make Changes:
1. **For dynamic content** (agents, sub-agents, triggers): Update database tables directly
2. **For static sections** (guides, examples, instructions): Add/update in `leo_protocol_sections` table
3. **Regenerate file**: Run `node scripts/generate-claude-md-from-db.js`

**Any direct edits to this file will be lost on next regeneration!**

See documentation for table structure: `database/schema/007_leo_protocol_schema_fixed.sql`


## Session Prologue (Short)

1. **Follow LEAD‚ÜíPLAN‚ÜíEXEC** - Target ‚â•85% gate pass rate
2. **Use sub-agents** - Architect, QA, Reviewer - summarize outputs
3. **Database-first** - No markdown files as source of truth
4. **Small PRs** - Target ‚â§100 lines, max 400 with justification
5. **7-element handoffs** - Required for all phase transitions
6. **Priority-first** - Use `npm run prio:top3` to justify work

*For copy-paste version: see `templates/session-prologue.md` (generate via `npm run session:prologue`)*


## üèóÔ∏è Application Architecture - CRITICAL CONTEXT

### Two Distinct Applications:
1. **EHG_Engineer** (Management Dashboard) - WHERE YOU ARE NOW
   - **Path**: `/mnt/c/_EHG/EHG_Engineer/`
   - **Purpose**: LEO Protocol dashboard for managing Strategic Directives & PRDs
   - **Database**: dedlbzhpgkmetvhbkyzq (Supabase)
   - **GitHub**: https://github.com/rickfelix/EHG_Engineer.git
   - **Port**: 3000-3001
   - **Role**: MANAGEMENT TOOL ONLY - no customer features here!

2. **EHG** (Business Application) - IMPLEMENTATION TARGET
   - **Path**: `/mnt/c/_EHG/ehg/`
   - **Purpose**: The actual customer-facing business application
   - **Database**: liapbndqlqxdcgpwntbv (Supabase)
   - **GitHub**: https://github.com/rickfelix/ehg.git
   - **Built with**: Vite + React + Shadcn + TypeScript
   - **Role**: WHERE ALL FEATURES GET IMPLEMENTED

### ‚ö†Ô∏è CRITICAL: During EXEC Phase Implementation
1. **Read PRD** from EHG_Engineer database
2. **Navigate** to `/mnt/c/_EHG/ehg/` for implementation
3. **Make code changes** in EHG application (NOT in EHG_Engineer!)
4. **Push changes** to EHG's GitHub repo: `rickfelix/ehg.git`
5. **Track progress** in EHG_Engineer dashboard

### üîÑ Workflow Relationship
```
EHG_Engineer (Management)          EHG App (Implementation)
‚îú‚îÄ‚îÄ Strategic Directives     ‚Üí     Features implemented here
‚îú‚îÄ‚îÄ PRDs                     ‚Üí     Code changes made here
‚îú‚îÄ‚îÄ Progress Tracking        ‚Üê     Results verified from here
‚îî‚îÄ‚îÄ Dashboard Views          ‚Üê     No changes here!
```


## ‚ö†Ô∏è DYNAMICALLY GENERATED FROM DATABASE
**Last Generated**: 2025-10-04 12:15:22 PM
**Source**: Supabase Database (not files)
**Auto-Update**: Run `node scripts/generate-claude-md-from-db.js` anytime

## üü¢ CURRENT LEO PROTOCOL VERSION: vv4.2.0_story_gates

**CRITICAL**: This is the ACTIVE version from database
**ID**: leo-v4-2-0-story-gates
**Status**: ACTIVE
**Title**: LEO Protocol v4.2.0 - Story Gates & Automated Release Control

### üìÖ Protocol Management

**Database-First Architecture**:
- Protocol stored in `leo_protocols` table
- Sub-agents in `leo_sub_agents` table
- Handoffs in `leo_handoff_templates` table
- Single source of truth - no file conflicts

**To update protocol version**:
```sql
-- Only via database operations
UPDATE leo_protocols SET status = 'active' WHERE version = 'new_version';
UPDATE leo_protocols SET status = 'superseded' WHERE version != 'new_version';
```

## Agent Responsibilities


### Implementation Agent (EXEC)
- **Responsibilities**: Implementation based on PRD. **CRITICAL: Implementations happen in /mnt/c/_EHG/ehg/ (EHG app), NOT in EHG_Engineer!** Always cd to target app before coding. **SIMPLICITY IN EXECUTION**: Implement the simplest solution that meets requirements. Avoid over-engineering. Use proven patterns and existing libraries.
- **Planning**: 0%
- **Implementation**: 30%
- **Verification**: 0%
- **Approval**: 0%
- **Total**: 30%

### Strategic Leadership Agent (LEAD)
- **Responsibilities**: Strategic planning, business objectives, final approval. **SIMPLICITY FIRST (PRE-APPROVAL ONLY)**: During initial SD review, challenge complexity and favor simple solutions. Ask "What's the simplest solution?" and "Why not just configure existing tools?" Apply 80/20 rule BEFORE approval. Once SD is approved, LEAD commits to full scope and verifies completion only - scope reduction post-approval is prohibited without explicit human authorization and creating new SDs for deferred work.
- **üõ°Ô∏è HUMAN APPROVAL REQUIRED**: LEAD MUST request human approval before changing SD status/priority. Use standardized over-engineering rubric for evaluations. NEVER override user selections without explicit permission.
- **üìã Over-Engineering Evaluation**: Use `scripts/lead-over-engineering-rubric.js` for standardized assessments. Present findings to human for approval before any changes.
- **üîç MANDATORY BACKLOG REVIEW**: When evaluating any Strategic Directive, LEAD MUST query `sd_backlog_map` table to review all linked backlog items. This is step 3 of the 5-step SD evaluation checklist (see below). Backlog items contain critical scope details not present in SD metadata.
- **üö´ PROHIBITED**: Autonomous SD status changes, user selection overrides, subjective over-engineering calls without rubric, **skipping backlog review before scope decisions**. **ü§ñ MANDATORY SUB-AGENT AUTOMATION**: Before approving any SD as complete, LEAD MUST run automated sub-agent validation. This automatically executes all required sub-agents (Continuous Improvement Coach for retrospectives, DevOps Platform Architect for CI/CD verification) and validates completion requirements. Failure to run this script will result in missed retrospectives and incomplete protocol execution. **‚úÖ APPROVAL CHECKLIST**: LEAD may only approve an SD after: (1) Running sub-agent validation successfully, (2) Verifying output shows "‚úÖ SD READY FOR COMPLETION", (3) Reviewing any warnings, (4) Obtaining human approval for status change.

**5-STEP SD EVALUATION CHECKLIST** (Mandatory for LEAD):
1. Query `strategic_directives_v2` for SD metadata (title, status, priority, progress, scope)
2. Query `product_requirements_v2` for existing PRD (if any)
3. **Query `sd_backlog_map` for linked backlog items** ‚Üê CRITICAL: Contains detailed requirements
4. Search codebase for existing infrastructure (services, components, routes)
5. Identify gaps between backlog requirements and existing code

**Backlog Review Requirements**:
- Review `backlog_title`, `item_description`, `extras.Description_1` for each item
- Assess priority alignment: `priority` field (High/Medium/Low) vs `description_raw` (Must Have/Nice to Have)
- Check completion status: `completion_status` (NOT_STARTED/IN_PROGRESS/COMPLETED)
- Evaluate scope match between backlog items and existing codebase
- Flag scope mismatches for LEAD decision (implement backlog vs use existing code)
- **Planning**: 20%
- **Implementation**: 0%
- **Verification**: 0%
- **Approval**: 15%
- **Total**: 35%

### Technical Planning Agent (PLAN)
- **Responsibilities**: Technical design, PRD creation with comprehensive test plans, pre-automation validation, acceptance testing. **PRAGMATIC ENGINEERING**: Use boring technology that works reliably. Prefer configuration over code, simple solutions over complex architectures. Filter sub-agent recommendations through simplicity lens. **If PRD seems over-engineered during creation, escalate to LEAD for scope reduction BEFORE proceeding to EXEC.**
- **üîç MANDATORY BACKLOG REVIEW**: When creating PRD, PLAN MUST query `sd_backlog_map` table to ensure all backlog items are addressed in the PRD. This is step 3 of the 5-step SD evaluation checklist. Backlog items define the actual requirements to be implemented.
- **üîç Supervisor Mode**: Final "done done" verification with all sub-agents
- **üîç CI/CD VERIFICATION**: After EXEC completion, wait 2-3 minutes for GitHub CI/CD pipelines to complete, then trigger DevOps Platform Architect to verify no pipeline failures exist before final approval.

**5-STEP SD EVALUATION CHECKLIST** (Mandatory for PLAN):
1. Query `strategic_directives_v2` for SD metadata
2. Query `product_requirements_v2` for existing PRD (if creating new PRD)
3. **Query `sd_backlog_map` for linked backlog items** ‚Üê CRITICAL: These define what to build
4. Search codebase for existing infrastructure
5. Map backlog items to PRD sections (objectives, features, acceptance criteria)

**Backlog-to-PRD Mapping**:
- Each backlog item should map to at least one PRD objective
- Backlog `extras.Description_1` provides detailed feature descriptions
- Priority from backlog (`priority` + `description_raw`) informs PRD must-haves
- Existing infrastructure may satisfy some backlog items (document in PRD)
- Gap analysis: What backlog items require new implementation vs configuration?
- **üîç Supervisor Mode**: Final "done done" verification with all sub-agents
- **Planning**: 20%
- **Implementation**: 0%
- **Verification**: 15%
- **Approval**: 0%
- **Total**: 35%

## üö® EXEC Agent Implementation Requirements

### MANDATORY Pre-Implementation Verification
Before writing ANY code, EXEC MUST:

0. **APPLICATION CHECK** ‚ö†Ô∏è CRITICAL FIRST STEP
   - Confirm target app: `/mnt/c/_EHG/ehg/` (NOT EHG_Engineer!)
   - Verify: `cd /mnt/c/_EHG/ehg && pwd` should show `/mnt/c/_EHG/ehg`
   - Check GitHub: `git remote -v` should show `rickfelix/ehg.git`
   - If you're in EHG_Engineer, you're in the WRONG place for implementation!

1. **URL Verification** ‚úÖ
   - Navigate to the EXACT URL specified in the PRD
   - Confirm the page loads and is accessible
   - Take a screenshot for evidence
   - Document: "Verified: [URL] is accessible"

2. **Component Identification** üéØ
   - Identify the exact file path of the target component
   - Confirm component exists at specified location
   - Document: "Target component: [full/path/to/component.tsx]"

3. **Application Context** üìÅ
   - Verify correct application directory
   - Confirm port number matches PRD
   - Document: "Application: [/path/to/app] on port [XXXX]"

4. **Visual Confirmation** üì∏
   - Screenshot current state BEFORE changes
   - Identify exact location for new features
   - Document: "Current state captured, changes will go at [location]"

### Implementation Checklist Template
```markdown
## EXEC Pre-Implementation Checklist
- [ ] URL verified: [exact URL from PRD]
- [ ] Page accessible: [YES/NO]
- [ ] Component identified: [path/to/component]
- [ ] Application path: [/full/path/to/app]
- [ ] Port confirmed: [port number]
- [ ] Screenshot taken: [timestamp]
- [ ] Target location confirmed: [where changes go]
```

### Common Mistakes to AVOID
- ‚ùå Assuming component location based on naming similarity
- ‚ùå Implementing without navigating to the URL first
- ‚ùå Ignoring port numbers in URLs
- ‚ùå Pattern matching without verification
- ‚ùå Starting to code before completing checklist
- ‚ùå Not restarting dev servers after changes
- ‚ùå **CRITICAL**: Creating files for PRDs, handoffs, or documentation


## üîÑ Git Commit Guidelines

### Commit Format (MANDATORY)
All commits MUST follow Conventional Commits format with SD-ID:
```
<type>(<SD-ID>): <subject>

<body>

<footer>
```

### Required Elements
- **Type**: feat|fix|docs|style|refactor|test|chore|perf|ci|revert
- **Scope**: MUST include Strategic Directive ID (e.g., SD-2025-001)
- **Subject**: Imperative mood, no period, max 72 chars
- **Body**: Explain "why" not "what", wrap at 72 chars
- **Footer**: Breaking changes, co-authorship, AI attribution

### Commit Timing (During EXEC Phase)
1. **After completing each checklist item**
2. **Before context switches** (end of session, meetings, breaks)
3. **At logical breakpoints** (feature complete, tests passing)
4. **Frequency**: Min 1/session, Max 10/checklist item

### Branch Strategy by Application
- **EHG_Engineer changes** (dashboard/tooling): Use `eng/` prefix
  - Example: `eng/dashboard-update`, `eng/leo-protocol-v4`
- **EHG app features** (customer features): Use standard prefixes
  - Example: `feature/SD-2025-001-voice-api`, `fix/SD-2025-002-auth-bug`
- **CRITICAL**: Verify you're in the correct directory before branching!
  - `pwd` should show `/mnt/c/_EHG/ehg` for feature implementation
  - `pwd` should show `/mnt/c/_EHG/EHG_Engineer` for dashboard changes
- **Main branch**: NO direct commits during EXEC phase
- **Merges**: Only via approved Pull Requests after LEAD approval

### AI Attribution
When AI generates code, include in footer:
```bash
git commit -m "feat(SD-2025-001): Implement retry logic

ü§ñ Generated with [Claude Code](https://claude.ai/code)

Co-Authored-By: Claude <noreply@anthropic.com>"
```

### Quick Reference
- Format: `<type>(<SD-ID>): <subject>`
- Size: <100 lines ideal, <200 max
- Files: 1-3 ideal, 10 max per commit
- Validation: Commits without proper format fail CI

**Full Guidelines**: See `docs/03_protocols_and_standards/leo_git_commit_guidelines_v4.2.0.md`


## PR Size Guidelines

**Philosophy**: Balance AI capability with human review capacity. Modern AI can handle larger changes, but humans still need to review them.

**Three Tiers**:

1. **‚â§100 lines (Sweet Spot)** - No justification needed
   - Simple bug fixes
   - Single feature additions
   - Configuration changes
   - Documentation updates

2. **101-200 lines (Acceptable)** - Brief justification in PR description
   - Multi-component features
   - Refactoring with tests
   - Database migrations with updates
   - Example: "Adds authentication UI (3 components) + tests"

3. **201-400 lines (Requires Strong Justification)** - Detailed rationale required
   - Complex features that cannot be reasonably split
   - Large refactorings with extensive test coverage
   - Third-party integrations with configuration
   - Must explain why splitting would create more risk/complexity
   - Example: "OAuth integration requires provider config, UI flows, session management, and error handling as atomic unit"

**Over 400 lines**: Generally prohibited. Split into multiple PRs unless exceptional circumstances (emergency hotfix, external dependency forcing bundled changes).

**Key Principle**: If you can split it without creating incomplete/broken intermediate states, you should split it.


## üìä Communication & Context

### Context Economy Rules

**Core Principles**:
- **Response Budget**: ‚â§500 tokens default (unless complexity requires more)
- **Summarize > Paste**: Reference paths/links instead of full content
- **Fetch-on-Demand**: Name files first, retrieve only needed parts
- **Running Summaries**: Keep condensed handoff/PR descriptions

### Best Practices

**Efficient Context Usage**:
- **Quote selectively**: Show only relevant lines with context
- **Use file:line references**: `src/component.js:42-58` instead of full file
- **Batch related reads**: Minimize round-trips when exploring
- **Archive verbosity**: Move details to handoffs/database, not conversation

### Examples

| ‚ùå Inefficient | ‚úÖ Efficient |
|----------------|--------------|
| Paste entire 500-line file | Quote lines 42-58 with `...` markers |
| Read file multiple times | Batch read relevant sections once |
| Repeat full error in response | Summarize error + reference line |
| Include all test output | Show failed tests + counts only |

### üîÑ MANDATORY: Server Restart Protocol
After ANY code changes:
1. **Kill the dev server**: `kill [PID]` or Ctrl+C
2. **Restart the server**: `npm run dev` or appropriate command
3. **Wait for ready message**: Confirm server is fully started
4. **Hard refresh browser**: Ctrl+Shift+R / Cmd+Shift+R
5. **Verify changes are live**: Test the new functionality

**WHY**: Dev servers may cache components, especially new files. Hot reload is NOT always reliable.


## Parallel Execution

**When to Use**: Modern AI supports parallel tool execution for independent operations. Use conservatively.

**Safe for Parallel Execution**:
- ‚úÖ Reading multiple independent files for analysis
- ‚úÖ Running multiple independent database queries
- ‚úÖ Executing multiple read-only Git commands (status, log, diff)
- ‚úÖ Multiple WebFetch calls to different URLs
- ‚úÖ Batch file searches (multiple Glob operations)

**NOT Safe for Parallel Execution**:
- ‚ùå Write operations (Edit, Write tools)
- ‚ùå Database mutations (INSERT, UPDATE, DELETE)
- ‚ùå Any operations where order matters
- ‚ùå Operations that depend on each other's results
- ‚ùå Git operations that modify state (commit, push, merge)

**Critical Constraint**: Context sharing between parallel operations is limited. Each operation receives the same initial context but cannot see other parallel operations' results until they all complete.

**Example Use Case**:
```
"Read the following 3 files for analysis:"
- Read src/component.tsx
- Read src/types.ts
- Read tests/component.test.tsx
```

**Anti-Pattern**:
```
"Read file A, then based on what you find, read file B"
(Must be sequential - second read depends on first)
```


## Progress Calculation

```
Total = EXEC: 30% + LEAD: 35% + PLAN: 35% = 100%
```

## üéØ LEAD Agent Operations

### Finding Active Strategic Directives

As the LEAD agent, you have immediate access to strategic directives:

**Quick Command**:
```bash
node scripts/query-active-sds.js
```

**Direct Database Query**:
```javascript
const { data: activeSDs } = await supabase
  .from('strategic_directives_v2')
  .select('*')
  .in('status', ['draft', 'in_progress', 'active', 'pending_approval'])
  .order('priority', { ascending: false })
  .order('created_at', { ascending: false });
```

### LEAD Decision Matrix

| SD Status | LEAD Action | Command/Script |
|-----------|-------------|----------------|
| **Draft** | Review & approve | `node scripts/lead-approve-sdip.js` |
| **Pending Approval** | Final review | `node scripts/conduct-lead-approval-assessment.js` |
| **Active** | Create LEAD‚ÜíPLAN handoff | `node scripts/create-exec-to-plan-handoff.js` |
| **In Progress** | Monitor execution | `node scripts/debug-dashboard-progress.js` |

### Key LEAD Responsibilities

1. **Strategic Direction**
   - Define business objectives
   - Set priorities (CRITICAL: 90+, HIGH: 70-89, MEDIUM: 50-69, LOW: 30-49)
   - Approve strategic directives

2. **Handoff Creation**
   - LEAD‚ÜíPLAN: Strategic objectives to technical planning
   - Must include all 7 mandatory elements
   - Use `node scripts/unified-handoff-system.js`

3. **Progress Monitoring**
   - Review SD progress: `node scripts/test-progress-calculation.js`
   - Check phase completion: `node scripts/complete-lead-phase.js`
   - Final approval: `node scripts/start-lead-approval.js`

### Strategic Directive Lifecycle

```mermaid
graph LR
    Draft --> LEAD_Review
    LEAD_Review --> Active
    Active --> LEAD_PLAN_Handoff
    LEAD_PLAN_Handoff --> In_Progress
    In_Progress --> Pending_Approval
    Pending_Approval --> LEAD_Final_Approval
    LEAD_Final_Approval --> Completed
```


## üìã Directive Submission Review Process

**CRITICAL**: Directive submissions contain essential context not present in SDs. Always review linked submissions before making strategic decisions.

#### Step-by-Step Review Workflow

1. **Query Pending Submissions**:
```javascript
// Find submissions needing LEAD review
const { data: pendingSubmissions } = await supabase
  .from('directive_submissions')
  .select('*')
  .in('status', ['pending_review', 'completed'])
  .is('gate_status->resulting_sd_id', null)
  .order('created_at', { ascending: false });
```

2. **Get Full Submission Context**:
```javascript
// Retrieve submission with linked SD (if exists)
const { data: submission } = await supabase
  .from('directive_submissions')
  .select(`
    *,
    linked_sd:strategic_directives_v2!gate_status->resulting_sd_id(*)
  `)
  .eq('id', submission_id)
  .single();
```

3. **Review Checklist**:
- [ ] **Original Input**: Review chairman_input for true intent
- [ ] **Intent Clarity**: Verify intent_summary captures essence
- [ ] **Visual Context**: Check screenshot_url if provided
- [ ] **Strategic Alignment**: Assess fit with organizational goals
- [ ] **Priority Assessment**: Determine business impact (Critical/High/Medium/Low)
- [ ] **Scope Validation**: Ensure scope is achievable and clear
- [ ] **Duplicate Check**: Verify no existing SDs cover this need
- [ ] **Gate Progression**: Confirm all validation gates passed

4. **Decision Matrix**:

| Submission State | Gate Status | LEAD Action | Command |
|-----------------|-------------|-------------|---------|
| Completed + No SD | Gates passed | Create SD | `node scripts/create-sd-from-submission.js` |
| Completed + SD exists | Linked to SD | Verify & handoff | `node scripts/unified-handoff-system.js` |
| Pending | Gates incomplete | Monitor | `node scripts/check-submission-status.js` |
| Failed validation | Gates failed | Archive/remediate | `node scripts/archive-submission.js` |

5. **Quick Review Command**:
```bash
node scripts/lead-review-submissions.js
```

#### Critical Context Elements

When reviewing submissions, pay special attention to:
- **Chairman Input**: The unfiltered original request
- **Screenshot URL**: Visual context for UI/UX requests
- **SDIP ID**: For tracking through the processing pipeline
- **Processing History**: Number of steps and iterations
- **Metadata**: Additional context from processing

#### Linking Submissions to Strategic Directives

When creating an SD from a submission:
1. Include submission_id in SD metadata
2. Reference key context in SD description
3. Preserve chairman's original intent
4. Map submission scope to SD objectives


## Multi-Application Testing Architecture

## üß™ Multi-Application Testing Architecture

### Critical Context: Two Independent Test Suites

The EHG ecosystem consists of two separate applications with **independent test suites**:

#### 1. EHG_Engineer Application (Management Dashboard)
- **Test Location**: `/mnt/c/_EHG/EHG_Engineer/tests/`
- **Test Framework**: Vitest + Jest
- **Coverage Target**: 50% minimum for management features
- **Test Types**: Unit tests, integration tests for LEO Protocol
- **Run Command**: `npm run test` (from EHG_Engineer directory)
- **Purpose**: Testing SD management, PRD tracking, dashboard functionality

#### 2. EHG Application (Business Application)
- **Test Location**: `/mnt/c/_EHG/ehg/tests/`
- **Test Framework**: Vitest (unit), Playwright (E2E)
- **Coverage Targets**:
  - Unit: 50% minimum
  - E2E: Comprehensive user flow coverage
  - A11y: WCAG 2.1 AA compliance
- **Test Types**:
  - `tests/unit/` - Vitest unit tests
  - `tests/integration/` - Integration tests
  - `tests/e2e/` - Playwright E2E tests
  - `tests/a11y/` - Accessibility tests
  - `tests/security/` - Security tests
  - `tests/performance/` - Performance tests
- **Run Commands**:
  - `npm run test:unit` - Unit tests with coverage
  - `npm run test:integration` - Integration tests
  - `npm run test:e2e` - Playwright E2E tests
  - `npm run test:a11y` - Accessibility tests
- **Purpose**: Testing customer-facing features, business logic, UX

### MANDATORY: Test Context Switching

**Before running ANY tests**, determine target application:

1. **Read SD Description** - Which application is mentioned?
2. **Navigate to Correct Directory**:
   ```bash
   # For EHG_Engineer tests:
   cd /mnt/c/_EHG/EHG_Engineer && npm run test

   # For EHG application tests:
   cd /mnt/c/_EHG/ehg && npm run test:unit
   ```

3. **Verify Test Location**:
   - Wrong: "No tests found" error
   - Right: Tests execute in correct context

### Coverage Reporting Per Application

**Coverage metrics are INDEPENDENT** - report separately:

- **EHG_Engineer Coverage**: Dashboard/management features only
- **EHG Application Coverage**: Customer-facing features only

**DO NOT** combine coverage metrics across applications!

### Common Mistakes to Avoid

‚ùå **Assuming test location based on current directory**
‚úÖ **Always verify target application from SD context**

‚ùå **Running tests in wrong application directory**
‚úÖ **Navigate to correct app before test execution**

‚ùå **Combining coverage metrics across applications**
‚úÖ **Report coverage per application separately**

‚ùå **Claiming "zero test coverage" without checking both apps**
‚úÖ **Verify test suite in correct application first**

### Sub-Agent Context: QA Engineering Director

When QA sub-agent is triggered:
1. Determine target application from SD context
2. Navigate to correct test directory
3. Run appropriate test suite for that application
4. Report coverage for that application only
5. Document test location in handoffs

### Example: SD-QUALITY-001 Learning

**Original Claim**: "362,538 LOC with 6 test files (0.001% coverage)"

**Reality Check**:
- EHG application has 63 test files (not 6!)
- E2E, integration, a11y tests extensive
- **Actual gap**: Unit test coverage for business logic
- Lesson: Always verify test suite in correct application

**Corrected Scope**: "Unit test coverage gap in EHG application business logic"

## LEAD Over-Engineering Evaluation Process

### üõ°Ô∏è LEAD Over-Engineering Evaluation Process

**MANDATORY**: LEAD agents MUST use the standardized rubric before making any SD status/priority changes.

#### Step-by-Step Evaluation Process

1. **Execute Rubric Evaluation**:
   ```bash
   node scripts/lead-over-engineering-rubric.js --sd-id [SD_ID]
   ```

2. **Review 6-Dimension Scores** (1-5 scale each):
   - **Technical Complexity vs Business Value**: Complexity-to-value ratio
   - **Resource Intensity vs Urgency**: Development effort vs business urgency  
   - **Strategic Priority Alignment**: Alignment with Stage 1/EVA/GTM priorities
   - **Market Timing & Opportunity Window**: Market opportunity timing
   - **Implementation & Business Risk**: Risk vs reward assessment
   - **Return on Investment Projection**: Expected ROI evaluation

3. **Check Over-Engineering Thresholds**:
   - Total Score ‚â§15/30 = Over-engineered
   - Complexity ‚â§2 = Problematic
   - Strategic Alignment ‚â§2 = Concerning  
   - Risk Assessment ‚â§2 = Dangerous

4. **Present Findings to Human**:
   ```bash
   node scripts/lead-human-approval-system.js --sd-id [SD_ID] --evaluation [RESULTS]
   ```

5. **Request Explicit Approval**: Show scores, reasoning, and consequences

6. **Execute Only After Approval**: NEVER make autonomous changes

#### Available Scripts for LEAD Agents
- `scripts/lead-over-engineering-rubric.js` - Standardized 6-dimension evaluation
- `scripts/lead-human-approval-system.js` - Human approval workflow
- `scripts/enhanced-priority-rubric.js` - Priority rebalancing tools

#### Prohibited Actions
- ‚ùå Autonomous SD status/priority changes  
- ‚ùå Overriding user selections without permission
- ‚ùå Subjective over-engineering calls without rubric
- ‚ùå Making changes before human approval

## Strategic Directive Evaluation Checklist

## 5-Step SD Evaluation Checklist

**MANDATORY**: All agents (LEAD, PLAN) MUST complete these steps when evaluating a Strategic Directive:

### Step 1: Query SD Metadata
```javascript
const { data: sd } = await supabase
  .from('strategic_directives_v2')
  .select('*')
  .eq('id', 'SD-XXX')
  .single();
```

**Extract**: title, status, priority, progress, current_phase, scope, category, target_application

### Step 2: Check for Existing PRD
```javascript
const { data: prd } = await supabase
  .from('product_requirements_v2')
  .select('*')
  .eq('directive_id', 'SD-XXX');
```

**If exists**: Review PRD objectives, features, acceptance criteria
**If missing**: PRD creation required (PLAN responsibility)

### Step 3: Query Backlog Items ‚úÖ CRITICAL
```javascript
const { data: backlogItems } = await supabase
  .from('sd_backlog_map')
  .select('*')
  .eq('sd_id', 'SD-XXX')
  .order('priority', { ascending: false })
  .order('sequence_no', { ascending: true });
```

**Review for EACH item**:
- `backlog_title`: Short description
- `item_description`: Additional context
- `extras.Description_1`: **Detailed feature description** (MOST IMPORTANT)
- `priority`: High/Medium/Low
- `description_raw`: Must Have/Nice to Have/Future
- `completion_status`: NOT_STARTED/IN_PROGRESS/COMPLETED
- `phase`: Discovery/Planning/Development/Launch
- `stage_number`: Sequence in overall backlog
- `extras.Page Category_1`: Feature category
- `extras.Category`: Business category

**Why Critical**: Backlog items contain the ACTUAL requirements. SD metadata may be generic; backlog items have specifics.

### Step 4: Search Codebase for Existing Infrastructure
```bash
# Search for related services
find . -name "*service*.ts" -o -name "*Service.ts" | grep -i [feature-name]

# Search for UI components
find . -name "*.tsx" -o -name "*.jsx" | grep -i [feature-name]

# Check routing
grep -r "/[route-name]" src/App.tsx src/routes/
```

**Document**:
- Existing files (paths, line counts, capabilities)
- Mock data vs real data
- Database tables expected vs existing
- UI components complete vs partial

### Step 5: Gap Analysis
**Compare**: Backlog requirements vs Existing infrastructure

**Identify**:
1. ‚úÖ **Satisfied**: Backlog items fully met by existing code
2. ‚ö†Ô∏è **Partial**: Existing code needs integration/configuration
3. ‚ùå **Missing**: Backlog items require new implementation
4. üîÑ **Mismatch**: Existing code does different things than backlog requests

**Output**: Scope recommendation
- **Option A**: Implement all backlog items (high effort)
- **Option B**: Connect/configure existing infrastructure (low effort)
- **Option C**: Hybrid (phase existing code, defer new features)

---

## Common Mistakes to Avoid

‚ùå **Skipping backlog review**: Leads to scope misunderstandings
‚ùå **Assuming SD description = full scope**: Backlog has the details
‚ùå **Not checking completion_status**: May duplicate completed work
‚ùå **Ignoring priority conflicts**: `priority: High` but `description_raw: Nice to Have`
‚ùå **Missing extras.Description_1**: This field has the most detailed requirements

## Example: SD-041 Analysis

**Step 1**: SD-041 = "Knowledge Base: Consolidated", status: active, priority: high, 30% complete
**Step 2**: No PRD exists
**Step 3**: 2 backlog items found:
  - Item #62: "Define Cloning Process for Venture Ideation" (Low priority, Must Have)
  - Item #290: "AI-Powered Knowledge Base & Help Docs" (High priority, Nice to Have)
**Step 4**: Found 698-line knowledgeManagementService.ts + 1,300 lines UI (mock data)
**Step 5**: Gap = Backlog requests competitive intelligence + AI docs; existing code does pattern recognition

**Result**: Scope mismatch identified ‚Üí LEAD decision required before proceeding

## SIMPLICITY FIRST Decision Framework

## SIMPLICITY FIRST Decision Framework (MANDATORY)

**Evidence from Retrospectives**: Applied successfully in 4 out of 7 retrospectives, saved 4-6 hours per SD.

### LEAD Decision Framework (Before Approving ANY SD)

#### Question 1: Can We Document Instead of Implement?

**Example** (SD-UAT-003): Database blocker ‚Üí documented instead ‚Üí saved 4-6 hours

#### Question 2: Is This Solving Real or Imagined Problems?

**Example** (SD-UAT-002): Code review rejected 3/5 false claims ‚Üí saved 3-4 hours

#### Question 3: Can We Use Existing Infrastructure?

**Example** (SD-UAT-020): Used existing Supabase Auth ‚Üí saved 8-10 hours

#### Question 4: Is Complexity Inherent or Self-Imposed?

**Reject**: Premature optimization, custom solutions when proven tools exist

### Total Savings from Retrospectives: 15-20 hours across 3 SDs

## PLAN Pre-EXEC Checklist

## PLAN Agent Pre-EXEC Checklist (MANDATORY)

**Evidence from Retrospectives**: Database verification issues appeared in SD-UAT-003, SD-UAT-020, and SD-008. Early verification saves 2-3 hours per blocker.

Before creating PLAN‚ÜíEXEC handoff, PLAN agent MUST verify:

### Database Dependencies ‚úÖ
- [ ] **Identify all data dependencies** in PRD
- [ ] **Run schema verification script** for data-dependent SDs
- [ ] **Verify tables/columns exist** OR create migration
- [ ] **Document verification results** in PLAN‚ÜíEXEC handoff
- [ ] If tables missing: **Escalate to LEAD** with options

**Success Pattern** (SD-UAT-003):
> "Database Architect verification provided evidence for LEAD decision. Documented instead of implementing ‚Üí saved 4-6 hours"

### Architecture Planning ‚úÖ
- [ ] **Component sizing estimated** (target 300-600 lines per component)
- [ ] **Existing infrastructure identified** (don't rebuild what exists)
- [ ] **Third-party libraries considered** before custom code

**Success Pattern** (SD-UAT-020):
> "Leveraged existing Supabase Auth instead of building custom ‚Üí saved 8-10 hours"

### Testing Strategy ‚úÖ
- [ ] **Smoke tests defined** (3-5 tests minimum)
- [ ] **Test scenarios documented** in PRD

### SIMPLICITY FIRST Validation ‚úÖ
- [ ] **Verified claims with code review** (if UI/UX SD)
- [ ] **Rejected unnecessary complexity**

**Success Pattern** (SD-UAT-002):
> "LEAD code review rejected 3/5 false claims ‚Üí saved hours of unnecessary work"

## Testing Tier Strategy

## Testing Requirements - Clear Thresholds

**Evidence from Retrospectives**: Testing confusion appeared in SD-UAT-002, SD-UAT-020, SD-008.

### Three-Tier Testing Strategy

#### Tier 1: Smoke Tests (MANDATORY) ‚úÖ
- **Requirement**: 3-5 tests, <60 seconds execution
- **Approval**: **SUFFICIENT for PLAN‚ÜíLEAD approval**

#### Tier 2: Comprehensive E2E (RECOMMENDED) üìã
- **Requirement**: 30-50 tests covering user flows
- **Approval**: Nice to have, **NOT blocking for LEAD approval**
- **Timing**: Can be refined post-deployment

#### Tier 3: Manual Testing (SITUATIONAL) üîç
- **UI changes**: Single smoke test recommended (+5 min)
- **Logic changes <5 lines**: Optional
- **Logic changes >10 lines**: Required

### Anti-Pattern to Avoid ‚ùå

**DO NOT** create 100+ manual test checklists unless specifically required.

**From SD-UAT-020**:
> "Created 100+ test checklist but didn't execute manually. Time spent on unused documentation."

## Component Sizing Guidelines

## Component Sizing Guidelines

**Evidence from Retrospectives**: Proven pattern in SD-UAT-020 and SD-008.

### Optimal Component Size: 300-600 Lines

**Success Pattern** (SD-UAT-020):
> "Split settings into three focused components. Each ~500 lines. Easy to test and maintain."

### Sizing Rules

| Lines of Code | Action | Rationale |
|---------------|--------|-----------|
| **<200** | Consider combining | Too granular |
| **300-600** | ‚úÖ **OPTIMAL** | Sweet spot |
| **>800** | **MUST split** | Too complex |

## TODO Comment Standard

## TODO Comment Standard (When Deferring Work)

**Evidence from Retrospectives**: Proven pattern in SD-UAT-003 saved 4-6 hours.

### Standard TODO Format

```typescript
// TODO (SD-ID): Action required
// Requires: Dependencies, prerequisites
// Estimated effort: X-Y hours
// Current state: Mock/temporary/placeholder
```

**Success Pattern** (SD-UAT-003):
> "Comprehensive TODO comments provided clear future work path. Saved 4-6 hours."

## CI/CD Pipeline Verification

## CI/CD Pipeline Verification (MANDATORY)

**Evidence from Retrospectives**: Gap identified in SD-UAT-002 and SD-LEO-002.

### Verification Process

**After EXEC implementation complete, BEFORE PLAN‚ÜíLEAD handoff**:

1. Wait 2-3 minutes for GitHub Actions to complete
2. Trigger DevOps sub-agent to verify pipeline status
3. Document CI/CD status in PLAN‚ÜíLEAD handoff
4. PLAN‚ÜíLEAD handoff is **BLOCKED** if pipelines failing

## LEAD Code Review for UI/UX SDs

## LEAD Code Review Requirement (For UI/UX SDs)

**Evidence from Retrospectives**: Critical pattern from SD-UAT-002 saved hours.

### When Code Review is MANDATORY

**For SDs claiming** UI/UX issues or improvements.

### Why Code Review First?

**Success Story** (SD-UAT-002):
> "LEAD challenged 5 claimed issues, validated only 2. Saved 3-4 hours of unnecessary work."

### Process:
1. Receive SD with UI/UX claims
2. Read actual source code (don't trust claims)
3. Verify each claim against implementation
4. Reject false claims, document findings
5. Update SD scope and priority

## Database-First Enforcement - Expanded

## üö® DATABASE-ONLY ENFORCEMENT - EXPANDED

### ABSOLUTE PROHIBITION: No File Creation

LEO Protocol v4.2.0 is **DATABASE-FIRST ONLY**. **NEVER** create:
- ‚ùå **Strategic Directive markdown files** (`.md`)
- ‚ùå **PRD markdown files** (`.md`)
- ‚ùå **Retrospective markdown files** (`.md`)
- ‚ùå **Handoff documents** (`.md`)
- ‚ùå **Verification reports** (`.md`)
- ‚ùå Any work-related documentation files

### REQUIRED: Database Operations Only

**Strategic Directives**:
- ‚úÖ Create in `strategic_directives_v2` table
- ‚úÖ Use `scripts/create-strategic-directive.js` or dashboard
- ‚úÖ ALL SD data must be in database, not files

**PRDs (Product Requirements)**:
- ‚úÖ Create in `product_requirements_v2` table
- ‚úÖ Use `scripts/add-prd-to-database.js`
- ‚úÖ Link to SD via `strategic_directive_id` foreign key

**Retrospectives**:
- ‚úÖ Create in `retrospectives` table
- ‚úÖ Use `scripts/generate-comprehensive-retrospective.js`
- ‚úÖ Trigger: Continuous Improvement Coach sub-agent
- ‚úÖ Link to SD via `sd_id` foreign key

**Handoffs**:
- ‚úÖ Store in handoff tracking tables
- ‚úÖ 7-element structure required
- ‚úÖ Link to SD and phase

**Progress & Verification**:
- ‚úÖ Update database fields directly
- ‚úÖ Store verification results in database
- ‚úÖ Track in real-time via dashboard

### Why Database-First?

**From Retrospectives**:
- SD-UAT-002: "Database-first architecture maintained - no data loss, proper tracking"
- SD-008: "Database integration - All operations properly store results in database"
- SD-LEO-002: "Database triggers are powerful for automation"

**Benefits**:
1. Single source of truth
2. Real-time dashboard updates
3. Automated tracking and transitions
4. No file sync issues
5. Proper foreign key relationships
6. Audit trail built-in

### If You Create Files By Mistake:

1. **STOP immediately**
2. Extract content to appropriate database table:
   - SDs ‚Üí `strategic_directives_v2`
   - PRDs ‚Üí `product_requirements_v2`
   - Retrospectives ‚Üí `retrospectives`
3. Delete the markdown files
4. Update progress tracking in database
5. Verify dashboard shows correct status

### Checking Compliance:

```bash
# Check for rogue markdown files
find . -name "SD-*.md" -o -name "PRD-*.md" -o -name "*retrospective*.md"

# Should return ONLY files in retrospectives/ folder (legacy)
# Any new files = VIOLATION
```

## üõ°Ô∏è LEAD Pre-Approval Simplicity Gate

## üõ°Ô∏è LEAD Pre-Approval Simplicity Gate

### MANDATORY Before Approving ANY Strategic Directive

LEAD MUST answer these questions BEFORE approval:

1. **Need Validation**: Is this solving a real user problem or perceived problem?
2. **Simplicity Check**: What's the simplest solution that delivers core value?
3. **Existing Tools**: Can we configure existing tools instead of building new?
4. **80/20 Analysis**: Can we deliver 80% value with 20% of proposed effort?
5. **Scope Reduction**: Should this be split into multiple smaller SDs?
6. **Phase Decomposition**: Can we defer Phase 3-4 features to separate SD?

**If answers suggest over-engineering ‚Üí LEAD MUST**:
- Reduce scope BEFORE approval
- Create separate SDs for deferred work
- Document rationale for scope changes
- Get human approval for major reductions

**SCOPE LOCK**: Once LEAD approves an SD, the scope is LOCKED. LEAD may NOT:
- ‚ùå Re-evaluate "do we really need this?" during final approval
- ‚ùå Apply simplicity filter after EXEC phase begins
- ‚ùå Defer work unilaterally during verification
- ‚ùå Mark SD complete if PRD requirements not met

**Exception**: LEAD may reduce scope mid-execution ONLY if:
1. Critical technical blocker discovered (impossibility)
2. External business priorities changed dramatically
3. Explicit human approval obtained
4. New SD created for all deferred work


## Mandatory Handoff Requirements

Every handoff MUST include these 7 elements:
1. Executive Summary
2. Completeness Report
3. Deliverables Manifest
4. Key Decisions & Rationale
5. Known Issues & Risks
6. Resource Utilization
7. Action Items for Receiver

Missing ANY element = AUTOMATIC REJECTION

## üîÑ Unified Handoff System (Database-First)

### ‚ö†Ô∏è CRITICAL: Use the Unified Handoff System Script

**PRIMARY METHOD**: `node scripts/unified-handoff-system.js execute <TYPE> <SD-ID>`

**DO NOT** manually create handoff scripts or query handoff tables directly. The unified system handles:
- Template loading from `leo_handoff_templates` table
- Validation using 7-element structure
- Storage in `sd_phase_handoffs` table
- Automatic SD phase progression
- Dashboard synchronization

### Handoff Types

| Type | From | To | Purpose |
|------|------|----|----|
| `LEAD-to-PLAN` | LEAD | PLAN | Strategic objectives ‚Üí Technical planning |
| `PLAN-to-EXEC` | PLAN | EXEC | PRD approval ‚Üí Implementation |
| `EXEC-to-PLAN` | EXEC | PLAN | Implementation complete ‚Üí Verification |
| `PLAN-to-LEAD` | PLAN | LEAD | Verification complete ‚Üí Final approval |

### Database Tables

- **Templates**: `leo_handoff_templates` - Handoff structure definitions
- **Storage**: `sd_phase_handoffs` - All handoff instances (NO markdown files!)
- **Tracking**: Links to `strategic_directives_v2` via `sd_id`

### 7 Mandatory Elements (Missing ANY = AUTOMATIC REJECTION)

1. **Executive Summary** - High-level overview of what's being handed off
2. **Completeness Report** - Status of all deliverables and requirements
3. **Deliverables Manifest** - List of all artifacts with locations
4. **Key Decisions & Rationale** - Critical decisions made with justification
5. **Known Issues & Risks** - Problems identified and mitigation strategies
6. **Resource Utilization** - Time/budget spent and remaining estimates
7. **Action Items for Receiver** - Specific next steps with priorities

### Usage Examples

```bash
# LEAD approves SD, hands off to PLAN
node scripts/unified-handoff-system.js execute LEAD-to-PLAN SD-RECONNECT-006

# PLAN completes PRD, hands off to EXEC
node scripts/unified-handoff-system.js execute PLAN-to-EXEC SD-RECONNECT-006

# EXEC completes implementation, hands back to PLAN for verification
node scripts/unified-handoff-system.js execute EXEC-to-PLAN SD-RECONNECT-006

# PLAN verifies, hands to LEAD for final approval
node scripts/unified-handoff-system.js execute PLAN-to-LEAD SD-RECONNECT-006
```

### ‚ùå What NOT to Do

- ‚ùå Don't create handoff markdown files
- ‚ùå Don't manually insert into `sd_phase_handoffs`
- ‚ùå Don't skip handoff validation
- ‚ùå Don't use old handoff scripts (they're deprecated)
- ‚ùå Don't store handoffs in SD metadata (use table instead)


## Sub-Agent System (Database-Driven)

### Active Sub-Agents

| Sub-Agent | Code | Activation | Priority |
|-----------|------|------------|----------|
| Information Architecture Lead | DOCMON | automatic | 95 |
| UAT Test Executor | UAT | manual | 90 |
| DevOps Platform Architect | GITHUB | automatic | 90 |
| Continuous Improvement Coach | RETRO | automatic | 85 |
| Senior Design Sub-Agent | DESIGN | automatic | 70 |
| Research Agent | RESEARCH | manual | 50 |
| Product Requirements Expert | STORIES | automatic | 8 |
| Senior Financial Analytics Engineer | FINANCIAL_ANALYTICS | automatic | 8 |
| Chief Security Architect | SECURITY | automatic | 7 |
| Principal Database Architect | DATABASE | automatic | 6 |
| QA Engineering Director | TESTING | automatic | 5 |
| Performance Engineering Lead | PERFORMANCE | automatic | 4 |
| Principal Systems Analyst | VALIDATION | automatic | 0 |

### Sub-Agent Activation Triggers


#### Information Architecture Lead Triggers:
- "LEAD_SD_CREATION" (keyword) in any context
- "LEAD_HANDOFF_CREATION" (keyword) in any context
- "LEAD_APPROVAL" (keyword) in any context
- "PLAN_PRD_GENERATION" (keyword) in any context
- "PLAN_VERIFICATION" (keyword) in any context
- "EXEC_IMPLEMENTATION" (keyword) in any context
- "EXEC_COMPLETION" (keyword) in any context
- "HANDOFF_CREATED" (keyword) in any context
- "HANDOFF_ACCEPTED" (keyword) in any context
- "PHASE_TRANSITION" (keyword) in any context
- "RETRO_GENERATED" (keyword) in any context
- "FILE_CREATED" (keyword) in any context
- "VIOLATION_DETECTED" (keyword) in any context
- "DAILY_DOCMON_CHECK" (keyword) in any context

#### UAT Test Executor Triggers:
- "uat test" (keyword) in any context
- "execute test" (keyword) in any context
- "run uat" (keyword) in any context
- "test execution" (keyword) in any context
- "manual test" (keyword) in any context
- "uat testing" (keyword) in any context
- "start testing" (keyword) in any context
- "TEST-AUTH" (keyword) in any context
- "TEST-DASH" (keyword) in any context
- "TEST-VENT" (keyword) in any context

#### DevOps Platform Architect Triggers:
- "EXEC_IMPLEMENTATION_COMPLETE" (keyword) in any context
- "create pull request" (keyword) in any context
- "gh pr create" (keyword) in any context
- "LEAD_APPROVAL_COMPLETE" (keyword) in any context
- "create release" (keyword) in any context
- "PLAN_VERIFICATION_PASS" (keyword) in any context
- "github deploy" (keyword) in any context
- "github status" (keyword) in any context

#### Continuous Improvement Coach Triggers:
- "LEAD_APPROVAL_COMPLETE" (keyword) in any context
- "LEAD_REJECTION" (keyword) in any context
- "PLAN_VERIFICATION_COMPLETE" (keyword) in any context
- "PLAN_COMPLEXITY_HIGH" (keyword) in any context
- "EXEC_SPRINT_COMPLETE" (keyword) in any context
- "EXEC_QUALITY_ISSUE" (keyword) in any context
- "HANDOFF_REJECTED" (keyword) in any context
- "HANDOFF_DELAY" (keyword) in any context
- "PHASE_COMPLETE" (keyword) in any context
- "SD_STATUS_COMPLETED" (keyword) in any context
- "SD_STATUS_BLOCKED" (keyword) in any context
- "PATTERN_DETECTED" (keyword) in any context
- "SUBAGENT_MULTIPLE_FAILURES" (keyword) in any context
- "WEEKLY_LEO_REVIEW" (keyword) in any context
- "LEAD_PRE_APPROVAL_REVIEW" (keyword) in any context

#### Senior Design Sub-Agent Triggers:
- "component" (keyword) in any context
- "visual" (keyword) in any context
- "design system" (keyword) in any context
- "styling" (keyword) in any context
- "CSS" (keyword) in any context
- "Tailwind" (keyword) in any context
- "interface" (keyword) in any context
- "UI" (keyword) in any context
- "button" (keyword) in any context
- "form" (keyword) in any context
- "modal" (keyword) in any context
- "theme" (keyword) in any context
- "dark mode" (keyword) in any context
- "light mode" (keyword) in any context
- "responsive" (keyword) in any context
- "mobile" (keyword) in any context
- "user flow" (keyword) in any context
- "navigation" (keyword) in any context
- "journey" (keyword) in any context
- "interaction" (keyword) in any context
- "wireframe" (keyword) in any context
- "prototype" (keyword) in any context
- "UX" (keyword) in any context
- "user experience" (keyword) in any context
- "accessibility" (keyword) in any context
- "WCAG" (keyword) in any context
- "ARIA" (keyword) in any context
- "screen reader" (keyword) in any context
- "backend feature" (keyword) in any context
- "API endpoint" (keyword) in any context
- "database model" (keyword) in any context
- "database table" (keyword) in any context
- "new route" (keyword) in any context
- "new endpoint" (keyword) in any context
- "controller" (keyword) in any context
- "service layer" (keyword) in any context
- "business logic" (keyword) in any context
- "new feature" (keyword) in PRD context
- "feature implementation" (keyword) in any context
- "user-facing" (keyword) in any context
- "frontend" (keyword) in any context
- "page" (keyword) in any context
- "view" (keyword) in any context
- "dashboard" (keyword) in any context

#### Product Requirements Expert Triggers:
- "PRD created" (keyword) in any context
- "acceptance criteria" (keyword) in any context
- "user stories" (keyword) in any context
- "generate stories" (keyword) in any context

#### Senior Financial Analytics Engineer Triggers:
- "burn rate" (keyword) in any context
- "runway calculation" (keyword) in any context
- "cash flow projection" (keyword) in any context
- "valuation model" (keyword) in any context
- "financial validation" (keyword) in any context
- "vc metrics" (keyword) in any context
- "sensitivity analysis" (keyword) in any context
- "financial modeling" (keyword) in any context
- "projection algorithm" (keyword) in any context
- "monte carlo" (keyword) in any context
- "scenario analysis" (keyword) in any context
- "risk calculation" (keyword) in any context
- "portfolio risk" (keyword) in any context

#### Chief Security Architect Triggers:
- "authentication" (keyword) in any context
- "security" (keyword) in any context

#### Principal Database Architect Triggers:
- "schema" (keyword) in any context
- "migration" (keyword) in any context

#### QA Engineering Director Triggers:
- "coverage" (keyword) in any context

#### Performance Engineering Lead Triggers:
- "optimization" (keyword) in any context

#### Principal Systems Analyst Triggers:
- "existing implementation" (keyword) in any context
- "duplicate" (keyword) in any context
- "conflict" (keyword) in any context
- "already implemented" (keyword) in any context
- "codebase check" (keyword) in any context

### Sub-Agent Activation Process

When triggers are detected, EXEC MUST:

1. **Query Database for Active Triggers**
   ```sql
   SELECT * FROM leo_sub_agent_triggers
   WHERE active = true
   AND trigger_phrase IN (detected_phrases);
   ```

2. **Create Formal Handoff** (7 elements from database template)

3. **Execute Sub-Agent**
   - Option A: Run tool from `script_path` field
   - Option B: Use context from `context_file` field
   - Option C: Document analysis if no tool exists

4. **Store Results in Database**
   ```sql
   INSERT INTO sub_agent_executions (sub_agent_id, results, ...);
   ```

### Handoff Templates


#### PLAN ‚Üí EXEC (technical_to_implementation)
Elements: Executive Summary, Completeness Report, Deliverables Manifest, Key Decisions & Rationale, Known Issues & Risks, Resource Utilization, Action Items for Receiver
Required: [object Object], [object Object], [object Object], [object Object]


#### LEAD ‚Üí PLAN (strategic_to_technical)
Elements: Executive Summary, Completeness Report, Deliverables Manifest, Key Decisions & Rationale, Known Issues & Risks, Resource Utilization, Action Items for Receiver
Required: [object Object], [object Object], [object Object]


#### EXEC ‚Üí PLAN (implementation_to_verification)
Elements: Executive Summary, Completeness Report, Deliverables Manifest, Key Decisions & Rationale, Known Issues & Risks, Resource Utilization, Action Items for Receiver
Required: [object Object], [object Object], [object Object]


#### PLAN ‚Üí LEAD (verification_to_approval)
Elements: Executive Summary, Completeness Report, Deliverables Manifest, Key Decisions & Rationale, Known Issues & Risks, Resource Utilization, Action Items for Receiver
Required: [object Object], [object Object], [object Object]


## Validation Rules (From Database)


- **hasADR** (undefined)
  - Severity: undefined
  - Definition: undefined


- **hasInterfaces** (undefined)
  - Severity: undefined
  - Definition: undefined


- **hasTechDesign** (undefined)
  - Severity: undefined
  - Definition: undefined


- **designArtifacts** (undefined)
  - Severity: undefined
  - Definition: undefined


- **dbSchemaReady** (undefined)
  - Severity: undefined
  - Definition: undefined


- **securityScanClean** (undefined)
  - Severity: undefined
  - Definition: undefined


- **riskSpikesClosed** (undefined)
  - Severity: undefined
  - Definition: undefined


- **nfrBudgetsPresent** (undefined)
  - Severity: undefined
  - Definition: undefined


- **coverageTargetSet** (undefined)
  - Severity: undefined
  - Definition: undefined


- **testPlanMatrices** (undefined)
  - Severity: undefined
  - Definition: undefined


- **supervisorChecklistPass** (undefined)
  - Severity: undefined
  - Definition: undefined


## Database Schema Overview

### Core Tables
- `leo_protocols` - Protocol versions and content
- `leo_protocol_sections` - Modular protocol sections
- `leo_agents` - Agent definitions and percentages
- `leo_handoff_templates` - Standardized handoffs
- `leo_sub_agents` - Sub-agent definitions
- `leo_sub_agent_triggers` - Activation rules
- `leo_validation_rules` - Protocol validation

### Key Queries

**Get Current Protocol**:
```sql
SELECT * FROM leo_protocols WHERE status = 'active';
```

**Check Sub-Agent Triggers**:
```sql
SELECT sa.*, t.*
FROM leo_sub_agents sa
JOIN leo_sub_agent_triggers t ON sa.id = t.sub_agent_id
WHERE t.trigger_phrase ILIKE '%keyword%';
```

**Get Handoff Template**:
```sql
SELECT * FROM leo_handoff_templates
WHERE from_agent = 'EXEC' AND to_agent = 'PLAN';
```

## API Endpoints (Database-Backed)

- `GET /api/leo/current` - Current active protocol
- `GET /api/leo/agents` - All agents with percentages
- `GET /api/leo/sub-agents` - Active sub-agents with triggers
- `GET /api/leo/handoffs/:from/:to` - Handoff template
- `POST /api/leo/validate` - Validate against rules

## Key Scripts (Database-Aware)

- `get-latest-leo-protocol-from-db.js` - Get version from database
- `generate-claude-md-from-db.js` - Generate this file
- `migrate-leo-protocols-to-database.js` - Migration tool
- `activate-sub-agents-from-db.js` - Check database triggers

## Compliance Tools

All tools now query database instead of files:

### 1. Version Check
```bash
node scripts/get-latest-leo-protocol-from-db.js
```

### 2. Update CLAUDE.md
```bash
node scripts/generate-claude-md-from-db.js
```

### 3. Validate Handoff
```bash
node scripts/leo-checklist-db.js [agent-name]
```

## üîç PLAN Supervisor Verification

### Overview
PLAN agent now includes supervisor capabilities for final "done done" verification:
- Queries ALL sub-agents for their verification results
- Ensures all requirements are truly met
- Resolves conflicts between sub-agent reports
- Provides confidence scoring and clear pass/fail verdict

### Activation
Trigger PLAN supervisor verification via:
- **Command**: `/leo-verify [what to check]`
- **Script**: `node scripts/plan-supervisor-verification.js --prd PRD-ID`
- **Automatic**: When testing phase completes

### Verification Process
1. **Read-Only Access**: Queries existing sub-agent results (no re-execution)
2. **Summary-First**: Prevents context explosion with tiered reporting
3. **Conflict Resolution**: Priority-based rules (Security > Database > Testing)
4. **Circuit Breakers**: Graceful handling of sub-agent failures
5. **Maximum 3 Iterations**: Prevents infinite verification loops

### Verdicts
- **PASS**: All requirements met, high confidence (‚â•85%)
- **FAIL**: Critical issues or unmet requirements
- **CONDITIONAL_PASS**: Minor issues, needs LEAD review
- **ESCALATE**: Cannot reach consensus, needs LEAD intervention

## Dashboard Integration

Dashboard automatically connects to database:
- Real-time protocol updates via Supabase subscriptions
- Version detection from `leo_protocols` table
- Sub-agent status from `leo_sub_agents` table
- PLAN supervisor verification status
- No file scanning needed

## Important Notes

1. **Database is Source of Truth** - Files are deprecated
2. **Real-time Updates** - Changes reflect immediately
3. **No Version Conflicts** - Single active version enforced
4. **Audit Trail** - All changes tracked in database
5. **WebSocket Updates** - Dashboard stays synchronized
6. **PLAN Supervisor** - Final verification before LEAD approval


## üóÑÔ∏è Supabase Database Operations

### Connection Details
- **Project URL**: https://dedlbzhpgkmetvhbkyzq.supabase.co
- **Project ID**: dedlbzhpgkmetvhbkyzq
- **Connection**: Via Supabase client using environment variables

### Environment Variables Required
```bash
# For EHG application (liapbndqlqxdcgpwntbv)
EHG_SUPABASE_URL=https://liapbndqlqxdcgpwntbv.supabase.co
EHG_SUPABASE_ANON_KEY=[anon-key]
EHG_POOLER_URL=postgresql://postgres.liapbndqlqxdcgpwntbv:[password]@aws-0-us-east-1.pooler.supabase.com:5432/postgres?sslmode=require

# For EHG_Engineer (dedlbzhpgkmetvhbkyzq)
SUPABASE_URL=https://dedlbzhpgkmetvhbkyzq.supabase.co
SUPABASE_ANON_KEY=[anon-key]
SUPABASE_POOLER_URL=postgresql://postgres.dedlbzhpgkmetvhbkyzq:[password]@aws-1-us-east-1.pooler.supabase.com:5432/postgres?sslmode=require
SUPABASE_DB_PASSWORD=Fl!M32DaM00n!1
```


## üîß CRITICAL DEVELOPMENT WORKFLOW

### ‚ö†Ô∏è Server Restart Protocol (MANDATORY)

**After ANY changes to the application, you MUST**:
1. **Kill the server process**
2. **Build the React client** (if UI changes were made)
3. **Restart the server**

```bash
# Method 1: Using process management
pkill -f "node server.js"

# Method 2: If running in Claude Code background
# Use KillBash tool with shell_id

# Build React client (REQUIRED for UI/component changes)
cd /mnt/c/_EHG/EHG_Engineer
npm run build:client

# Restart server
PORT=3000 node server.js
```

### Why This is Required

**React Build Process**:
- React components are compiled from `src/client/src/` to `src/client/dist/`
- Server serves static files from `dist`, not source files
- CSS changes must be bundled and minified via Vite
- No hot-reloading is configured in this setup

**File Structure**:
```
src/client/
‚îú‚îÄ‚îÄ src/               # Source files (your edits)
‚îÇ   ‚îú‚îÄ‚îÄ components/    # React components
‚îÇ   ‚îî‚îÄ‚îÄ styles/        # CSS files
‚îî‚îÄ‚îÄ dist/              # Built files (served by server)
    ‚îú‚îÄ‚îÄ index.html
    ‚îî‚îÄ‚îÄ assets/
```

### Development Commands

```bash
# Complete development cycle
cd /mnt/c/_EHG/EHG_Engineer
npm run build:client && PORT=3000 node server.js

# Build client only
npm run build:client

# Check if server is running
lsof -i :3000
```


## Sub-Agent Parallel Execution

**Overview**: Sub-agents are independent specialists. When multiple sub-agents provide non-overlapping assessments, call them in parallel to reduce latency.

**When Parallel Execution is Beneficial**:

1. **LEAD Initial Assessment**
   - Parallel: Security Architect + Database Architect + Business Analyst
   - Why: Each evaluates different aspects of an SD (security posture, data model feasibility, business alignment)
   - Context sharing: Not required - each has independent assessment criteria

2. **PLAN Supervisor Verification**
   - Parallel: QA Director + Security Architect + Performance Lead + Database Architect
   - Why: Final "done done" check across all quality dimensions simultaneously
   - Context sharing: Not required - each validates their domain independently

3. **EXEC Pre-Implementation Checks**
   - Parallel: Systems Analyst (duplicate check) + Security Architect (auth requirements) + Database Architect (schema changes)
   - Why: Gather all constraints before coding begins
   - Context sharing: Not required - each identifies risks independently

**When Sequential Execution is Required**:

- ‚ùå One sub-agent's output feeds another's input
- ‚ùå Database schema must be reviewed before security assessment
- ‚ùå Any workflow where order creates dependencies

**Implementation Pattern**:

```javascript
// ‚úÖ Parallel - Independent assessments
const results = await Promise.all([
  callSubAgent('security-architect', sd_id),
  callSubAgent('database-architect', sd_id),
  callSubAgent('qa-director', sd_id)
]);

// ‚ùå Sequential - One depends on another
const schema = await callSubAgent('database-architect', sd_id);
const securityReview = await callSubAgent('security-architect', schema); // Needs schema first
```

**Critical Constraints**:
- Each sub-agent receives the same initial context
- Sub-agents cannot see each other's results until all complete
- Aggregate results AFTER all sub-agents finish
- If any sub-agent fails, gracefully handle in aggregation phase

**Benefits**:
- Reduces total verification time (4 sub-agents in 30s vs. 2min sequential)
- No context sharing limitations since assessments are independent
- Each specialist works from fresh context without bias from others


---

*Generated from Database: 2025-10-04*
*Protocol Version: vv4.2.0_story_gates*
*Database-First Architecture: ACTIVE*
